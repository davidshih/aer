# === Cell 5: AER Engine v4.0 (Smart Caching & Reporting) ===
import pandas as pd
import re, time, json, os, requests
import ipywidgets as widgets
from datetime import datetime
from openpyxl import load_workbook
from openpyxl.utils import get_column_letter
from IPython.display import display, HTML, clear_output
from io import BytesIO

# ==========================================
# PART 1: CONFIG & HELPER FUNCTIONS
# ==========================================
CACHE_FILE = "aer_cache.json"
NOTES_FILE = "aer_manual_notes.json"
CACHE_VERSION = 4.0  # Increment to force invalidation of old cache without rows
cache_updated = False
EXCLUDED_FOLDERS = ["forms", "_private", "user listings", "audit logs", "audit"]

# --- Loaders ---
def load_json(file_path):
    if os.path.exists(file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as f: return json.load(f)
        except: return {}
    return {}

def save_json(file_path, data):
    with open(file_path, 'w', encoding='utf-8') as f: json.dump(data, f, indent=2, ensure_ascii=False)

local_cache = load_json(CACHE_FILE)
manual_data_store = load_json(NOTES_FILE)

# --- Excel Parser (Embedded for standalone execution) ---
COL_REVIEWER = "Reviewer"
COL_RESPONSE = "Reviewer's Response"
COL_DETAILS = "Details of Access change"

def read_excel_rows(excel_bytes: bytes, reviewer_name: str, file_name: str, folder_url: str) -> list[dict]:
    wb = load_workbook(BytesIO(excel_bytes), read_only=True)
    
    # Tab Selection Logic
    sheet_name = wb.sheetnames[0]
    for sn in wb.sheetnames:
        if "user listing" in sn.lower(): sheet_name = sn; break
    ws = wb[sheet_name]
    
    # Header Mapping
    rows = list(ws.iter_rows(values_only=True))
    if not rows: return []
    header = rows[0]
    col_map = {str(h).strip(): i for i, h in enumerate(header) if h}
    
    idx_rev = col_map.get(COL_REVIEWER)
    idx_res = col_map.get(COL_RESPONSE)
    idx_det = col_map.get(COL_DETAILS)
    
    if idx_rev is None or idx_res is None: return [] # Skip invalid files
    
    results = []
    # Identify hidden rows if possible (read_only doesn't support row_dimensions well, simplified here)
    # For robust hidden row check, we need read_only=False, but for speed we trust the data mostly.
    
    for i, row in enumerate(rows[1:], start=2):
        r_rev = row[idx_rev] if idx_rev < len(row) else None
        r_res = row[idx_res] if idx_res < len(row) else None
        r_det = row[idx_det] if idx_det is not None and idx_det < len(row) else None
        
        # Filter by Reviewer Name (Case Insensitive)
        if str(r_rev).strip().lower() != reviewer_name.lower(): continue
        
        is_missing = (r_res is None or str(r_res).strip() == "")
        
        results.append({
            "reviewer": reviewer_name, 
            "response": r_res, 
            "details": r_det,
            "is_missing": is_missing,
            "row_number": i, 
            "file_name": file_name, 
            "folder_url": folder_url
        })
    return results

def get_row_stats(txt):
    txt = str(txt).lower().strip() if txt else ""
    kw_appr = ['approv', 'retain', 'keep', 'confirm', 'yes', 'ok', 'active']
    kw_deny = ['denied', 'deny', 'remove', 'delete', 'revok', 'reject', 'no']
    kw_chg  = ['change', 'modif', 'updat', 'correct', 'edit']
    return {
        "is_appr": 1 if any(k in txt for k in kw_appr) else 0,
        "is_deny": 1 if any(k in txt for k in kw_deny) else 0,
        "is_chg":  1 if any(k in txt for k in kw_chg) else 0
    }

# ==========================================
# PART 2: SCANNING ENGINE
# ==========================================
if 'TARGET_APPS' not in globals() or not TARGET_APPS:
    print("‚ö†Ô∏è Please select Apps in Cell 2 first!")
    TARGET_APPS = []

all_responses = []
errors = []

print(f"üöÄ Starting Scan Engine v{CACHE_VERSION}...")

for category, current_app_name, current_path in TARGET_APPS:
    try:
        raw_folders = list_folders_with_count(site_id, current_path) if 'list_folders_with_count' in globals() else []
        # Fallback if cell 2 function missing
        if not raw_folders: raw_folders = [{"name": "Error", "webUrl": "#"}] 
        
        reviewers = [r for r in raw_folders if r['name'].lower() not in EXCLUDED_FOLDERS]
        logger.info(f"üìÇ App: {current_app_name} | Reviewers: {len(reviewers)}")
        
        for folder in reviewers:
            reviewer_name = folder["name"]
            folder_url = folder["webUrl"]
            folder_path = f"{current_path}/{reviewer_name}"
            
            # --- CACHE KEY ---
            cache_key = f"{category}|{current_app_name}|{reviewer_name}"
            
            # 1. List Files
            try:
                files = list_excel_files(site_id, folder_path)
                target_file = None
                
                # Smart Match File
                match_candidates = [f for f in files if reviewer_name.lower() in f["name"].lower()]
                if not match_candidates: 
                    # Fallback: Just take the newest file if folder only has one valid excel
                    if len(files) > 0: target_file = files[0]
                else:
                    target_file = match_candidates[0] # Newest is first
                
                if not target_file:
                    raise FileNotFoundError("No Excel file found")

                remote_mod = target_file.get("lastModifiedDateTime")
                
                # --- CACHE CHECK (v4.0) ---
                cached = local_cache.get(cache_key)
                is_hit = False
                
                # Check Version AND Mod Time AND Data Existence
                if USE_CACHE and cached and cached.get('v') == CACHE_VERSION and cached.get('last_mod') == remote_mod:
                    if 'rows' in cached and len(cached['rows']) > 0:
                        is_hit = True
                        
                if is_hit:
                    logger.info(f"  ‚è≠Ô∏è Cache Hit: {reviewer_name}")
                    # Load rows from JSON, mark as cached
                    audit_snap = cached.get('audit', {})
                    for r in cached['rows']:
                        r_copy = r.copy()
                        r_copy.update({
                            "Category": category, "App_Name": current_app_name,
                            "Last_Modified": remote_mod,
                            "File_Created_Date": audit_snap.get('created_ts'),
                            "Audit_Log": audit_snap.get('log'),
                            "File_Creator": audit_snap.get('creator'),
                            "File_Modifier": audit_snap.get('modifier'),
                            "stats_appr": cached['stats']['Appr'], # Optimization: use pre-calc stats
                            "stats_deny": cached['stats']['Deny'],
                            "stats_chg": cached['stats']['Chg'],
                            "source_is_cache": True 
                        })
                        all_responses.append(r_copy)
                    continue # Skip to next reviewer

                # --- DOWNLOAD & PROCESS ---
                content = download_file(site_id, f"{folder_path}/{target_file['name']}")
                audit_info = get_file_audit_info(site_id, target_file["id"])
                
                rows = read_excel_rows(content, reviewer_name, target_file['name'], folder_url)
                
                # Calc Stats
                s_appr, s_deny, s_chg, miss_cnt = 0, 0, 0, 0
                clean_rows_for_cache = []
                
                final_created = audit_info.get('created_ts') or target_file.get("createdDateTime")
                
                for r in rows:
                    st = get_row_stats(r['response'])
                    s_appr += st['is_appr']; s_deny += st['is_deny']; s_chg += st['is_chg']
                    if r['is_missing']: miss_cnt += 1
                    
                    # Store minimal data for cache
                    clean_rows_for_cache.append({
                        "reviewer": r['reviewer'], "response": r['response'], "details": r['details'],
                        "is_missing": r['is_missing'], "row_number": r['row_number'], 
                        "file_name": r['file_name'], "folder_url": r['folder_url']
                    })
                    
                    # Add to current dataframe
                    r.update({
                        "Category": category, "App_Name": current_app_name,
                        "Last_Modified": remote_mod, "File_Created_Date": final_created,
                        "Audit_Log": audit_info['log'], "File_Creator": audit_info['creator'], "File_Modifier": audit_info['modifier'],
                        "stats_appr": st['is_appr'], "stats_deny": st['is_deny'], "stats_chg": st['is_chg'],
                        "source_is_cache": False
                    })
                
                all_responses.extend(rows)
                logger.info(f"  ‚úÖ Processed: {reviewer_name} (Miss: {miss_cnt})")
                
                # Write to Cache (Only if valid rows exist)
                if rows:
                    local_cache[cache_key] = {
                        "v": CACHE_VERSION,
                        "last_mod": remote_mod,
                        "stats": {"Appr": s_appr, "Deny": s_deny, "Chg": s_chg},
                        "audit": audit_info,
                        "rows": clean_rows_for_cache
                    }
                    cache_updated = True

            except Exception as e:
                logger.error(f"  ‚ùå Error {reviewer_name}: {e}")
                errors.append({"Category": category, "App_Name": current_app_name, "reviewer": reviewer_name, "error": str(e), "folder_url": folder_url})
                
    except Exception as e:
        logger.error(f"‚ùå Critical App Error: {e}")

if cache_updated:
    save_json(CACHE_FILE, local_cache)
    logger.info("üíæ Cache file updated (v4.0 structure).")

# ==========================================
# PART 3: DASHBOARD & EXPORT
# ==========================================
df = pd.DataFrame(all_responses)
widget_store = {}
unified_data = {}
today_str = datetime.now().strftime("%Y-%m-%d")
output_dir = f"output/{today_str}"
os.makedirs(output_dir, exist_ok=True)

# --- Aggregate Data ---
if not df.empty:
    stats = df.groupby(["Category", "App_Name", "reviewer"]).agg(
        missing=("is_missing", "sum"),
        approved=("stats_appr", "sum"), denied=("stats_deny", "sum"), changed=("stats_chg", "sum"),
        f_creator=("File_Creator", "first"), f_modifier=("File_Modifier", "first"), audit=("Audit_Log", "first"),
        is_cached=("source_is_cache", "all") # If all rows are cached
    ).reset_index()

    for _, row in stats.iterrows():
        key = f"{row['Category']} > {row['App_Name']}"
        if key not in unified_data:
            saved_app = manual_data_store.get(key, {})
            unified_data[key] = {
                "Category": row['Category'], "App_Name": row['App_Name'],
                "status_manual": saved_app.get("app_status", "Calculated"), "note_manual": saved_app.get("app_note", ""),
                "reviewers": {}, "stats": {"total_users": 0, "completed_users": 0}
            }
        
        node = unified_data[key]
        node['stats']['total_users'] += 1
        is_done = (row['missing'] == 0)
        if is_done: node['stats']['completed_users'] += 1
        
        # Calculate Status String
        status_calc = f"‚ùå Pending: {row['missing']}"
        if is_done:
            status_calc = "‚úÖ Cached - Completed" if row['is_cached'] else "‚úÖ Completed"
        
        d_style = "color:red;font-weight:bold" if row['denied'] > 0 else "color:#555"
        detail_html = f"Appr:{int(row['approved'])} | <span style='{d_style}'>Deny:{int(row['denied'])}</span> | Chg:{int(row['changed'])}"
        
        node['reviewers'][row['reviewer']] = {
            "status_calc": status_calc, "detail_html": detail_html,
            "missing_cnt": row['missing'], "is_cached": row['is_cached'],
            "audit_info": {"creator": row['f_creator'], "modifier": row['f_modifier'], "log": row['audit']},
            "folder_url": df[(df['App_Name'] == row['App_Name']) & (df['reviewer'] == row['reviewer'])].iloc[0].get('folder_url', '#')
        }

# --- Dashboard UI ---
def build_dashboard():
    container = widgets.VBox()
    btn_export = widgets.Button(description="üíæ Save Reports", button_style='success', icon='file-excel')
    lbl_out = widgets.Label()
    
    app_widgets = []
    for app_key in sorted(unified_data.keys()):
        app_data = unified_data[app_key]
        # Header
        pct = int((app_data['stats']['completed_users'] / app_data['stats']['total_users'] * 100)) if app_data['stats']['total_users'] > 0 else 0
        w_lbl = widgets.HTML(f"<b>üìÇ {app_key}</b> &nbsp; <span style='background:#eee; padding:2px 5px; border-radius:4px'>{pct}% Done</span>", layout=widgets.Layout(width='400px'))
        w_stat = widgets.Dropdown(options=["Calculated", "Force Completed", "Action Required"], value=app_data['status_manual'], layout=widgets.Layout(width='150px'))
        
        widget_store[app_key] = {"data": app_data, "w_stat": w_stat, "revs": {}}
        
        # Reviewer Rows
        rev_rows = []
        for r_name, r_d in app_data['reviewers'].items():
            color = "green" if "Completed" in r_d['status_calc'] else "red"
            w_r = widgets.HTML(f"<span style='color:{color}'>{r_name}</span>", layout=widgets.Layout(width='200px'))
            w_s = widgets.HTML(f"<i>{r_d['status_calc']}</i>", layout=widgets.Layout(width='200px'))
            rev_rows.append(widgets.HBox([w_r, w_s]))
            
        app_widgets.append(widgets.VBox([widgets.HBox([w_lbl, w_stat]), widgets.VBox(rev_rows, layout=widgets.Layout(margin='5px 0 10px 20px'))]))

    def export(b):
        b.disabled=True; b.description="Saving..."
        saved_files = []
        
        for app_key, widget_data in widget_store.items():
            app_name = widget_data['data']['App_Name']
            category = widget_data['data']['Category']
            
            # Get Rows
            app_rows = df[(df['Category'] == category) & (df['App_Name'] == app_name)].to_dict('records')
            
            final_data = []
            for row in app_rows:
                # Logic: Populate real data even if cached
                rev_key = row['reviewer']
                sys_status = widget_data['data']['reviewers'].get(rev_key, {}).get('status_calc', 'Unknown')
                
                # User Requirement: Final Status column shows "Cached"
                final_status = widget_data['w_stat'].value
                if final_status == "Calculated":
                    final_status = sys_status # This already contains "Cached - Completed" from logic above
                
                final_data.append({
                    "Reviewer": rev_key,
                    "File Name": row.get('file_name'),
                    "Reviewer Response": row.get('response'), # Real data from cache or file
                    "Details of Access Change": row.get('details'), # Real data from cache or file
                    "Final Status": final_status,
                    "Row Num": row.get('row_number'),
                    "Audit Creator": row.get('File_Creator'),
                    "Audit Modifier": row.get('File_Modifier'),
                    "Full Audit Log": row.get('Audit_Log')
                })
            
            if final_data:
                safe_name = re.sub(r'[\\/*?:"<>|]', "", app_name)
                f_name = f"{output_dir}/{safe_name}_{int(time.time())}.xlsx"
                pd.DataFrame(final_data).to_excel(f_name, index=False)
                saved_files.append(safe_name)
        
        lbl_out.value = f"Saved {len(saved_files)} files to {output_dir}"
        b.disabled=False; b.description="üíæ Save Reports"

    btn_export.on_click(export)
    container.children = tuple([widgets.HBox([btn_export, lbl_out])] + app_widgets)
    display(container)

if unified_data:
    build_dashboard()
else:
    print("‚ö†Ô∏è No data found.")