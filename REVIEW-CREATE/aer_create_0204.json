{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ°Ô∏è AER - Smart Access Review Generator (v7.0 Three-Stage)\n",
    "\n",
    "**Major Refactoring in v7.0:**\n",
    "- ‚úÖ **Stage 1 (Cell 1)**: AD Authentication & User Download\n",
    "- ‚úÖ **Stage 2 (Cell 2)**: Email/User Validation & AD Status Check\n",
    "- ‚úÖ **Stage 3 (Cell 3)**: Reviewer Assignment & Manual Override\n",
    "- ‚úÖ **Stage 1.5 (Cell 2)**: Org Tree Builder for Dept Heads\n",
    "\n",
    "**New Features:**\n",
    "1. ‚úÖ **Separated Workflow**: Each stage is independent and saves checkpoint files\n",
    "2. ‚úÖ **24-Month Activity**: Attempts to fetch sign-in activity (falls back gracefully)\n",
    "3. ‚úÖ **Manager Info**: Captures manager for every user to build org tree\n",
    "4. ‚úÖ **Org Tree UI**: Select dept heads & generate mapping file\n",
    "3. ‚úÖ **AD Status Column**: Clear visibility of Active/Inactive/Not Found\n",
    "4. ‚úÖ **Email-First Logic**: Email matches require manual approval with pre-fill\n",
    "5. ‚úÖ **Backward Compatible**: Works with legacy files if Cell 1-2 are skipped\n",
    "\n",
    "**Previous Features (v6.5):**\n",
    "- Enhanced Reviewer Mapping\n",
    "- Missing Email Handler with Fuzzy Matching\n",
    "- Smart Column Detection\n",
    "- Branch Support\n",
    "- Visual Enhancements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 1: AD Authentication & User Download (v7.1 Stage 1) ===\n",
    "import os, sys, logging, re, requests, json, glob\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from msal import PublicClientApplication\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# 1. Setup Paths\n",
    "today_str = datetime.now().strftime('%Y-%m-%d')\n",
    "BASE_DIR = os.path.join(\"output\", today_str)\n",
    "AD_CACHE_DIR = os.path.join(BASE_DIR, \"ad_cache\")\n",
    "LOG_DIR = os.path.join(BASE_DIR, \"logs\")\n",
    "USERS_URL = \"https://graph.microsoft.com/v1.0/users\"\n",
    "os.makedirs(AD_CACHE_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "# 2. Logging\n",
    "log_file = os.path.join(LOG_DIR, f\"aer_stage1_{datetime.now().strftime('%Y%m%d_%H%M')}.log\")\n",
    "logger_s1 = logging.getLogger(\"aer_stage1\")\n",
    "logger_s1.handlers.clear()\n",
    "logger_s1.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "fh = logging.FileHandler(log_file, encoding=\"utf-8\")\n",
    "fh.setFormatter(formatter)\n",
    "logger_s1.addHandler(fh)\n",
    "logger_s1.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# 3. Global State\n",
    "stage1_headers = {}\n",
    "stage1_ad_data = None\n",
    "stage1_file_path = None\n",
    "\n",
    "# 4. UI Components\n",
    "s1_btn_login = widgets.Button(\n",
    "    description=\"üîê Login to Azure AD\",\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "s1_btn_download = widgets.Button(\n",
    "    description=\"üì• Download AD Users\",\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px', height='40px'),\n",
    "    disabled=True\n",
    ")\n",
    "s1_btn_refresh = widgets.Button(\n",
    "    description=\"üîÑ Refresh\",\n",
    "    button_style='warning',\n",
    "    layout=widgets.Layout(width='120px', height='40px'),\n",
    "    disabled=True\n",
    ")\n",
    "s1_chk_auditlog = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Include AuditLog.Read.All (sign-in activity)',\n",
    "    indent=False\n",
    ")\n",
    "s1_chk_use_cache = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Use cached AD file if available (skip Graph refresh)',\n",
    "    indent=False\n",
    ")\n",
    "s1_status = widgets.HTML(value=\"<i>Please login to Azure AD first</i>\")\n",
    "s1_output = widgets.Output()\n",
    "\n",
    "# Helpers\n",
    "def load_latest_cache():\n",
    "    files = glob.glob(os.path.join(AD_CACHE_DIR, \"ad_users_*.csv\"))\n",
    "    if not files:\n",
    "        return None, None\n",
    "    latest = max(files, key=os.path.getmtime)\n",
    "    try:\n",
    "        df = pd.read_csv(latest)\n",
    "        return df, latest\n",
    "    except Exception as e:\n",
    "        logger_s1.error(f\"Failed to read cache {latest}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# 5. Authentication Function\n",
    "def do_stage1_login(b):\n",
    "    global stage1_headers\n",
    "    \n",
    "    b.disabled = True\n",
    "    s1_status.value = \"<span style='color:blue;'>üîÑ Authenticating...</span>\"\n",
    "    \n",
    "    try:\n",
    "        load_dotenv()\n",
    "        tid = os.getenv(\"AZURE_TENANT_ID\")\n",
    "        cid = os.getenv(\"AZURE_CLIENT_ID\")\n",
    "        \n",
    "        if not tid or not cid:\n",
    "            s1_status.value = \"<span style='color:red;'>‚ùå Missing AZURE_TENANT_ID or AZURE_CLIENT_ID in .env</span>\"\n",
    "            logger_s1.error(\"Missing Azure credentials in .env\")\n",
    "            b.disabled = False\n",
    "            return\n",
    "        \n",
    "        app = PublicClientApplication(\n",
    "            cid,\n",
    "            authority=f\"https://login.microsoftonline.com/{tid}\"\n",
    "        )\n",
    "        \n",
    "        scopes = [\"User.Read.All\"]\n",
    "        if s1_chk_auditlog.value:\n",
    "            scopes.append(\"AuditLog.Read.All\")\n",
    "        \n",
    "        result = app.acquire_token_interactive(\n",
    "            scopes=scopes,\n",
    "            prompt=\"select_account\"\n",
    "        )\n",
    "        \n",
    "        if \"access_token\" in result:\n",
    "            stage1_headers = {\"Authorization\": f\"Bearer {result['access_token']}\"}\n",
    "            s1_status.value = \"<span style='color:green;'>‚úÖ Authentication Successful</span>\"\n",
    "            s1_btn_download.disabled = False\n",
    "            s1_btn_refresh.disabled = False\n",
    "            logger_s1.info(\"Stage 1: Authentication successful\")\n",
    "        else:\n",
    "            error_msg = result.get('error_description', 'Unknown error')\n",
    "            s1_status.value = f\"<span style='color:red;'>‚ùå Authentication failed: {error_msg}</span>\"\n",
    "            logger_s1.error(f\"Authentication failed: {error_msg}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        s1_status.value = f\"<span style='color:red;'>‚ùå Error: {str(e)}</span>\"\n",
    "        logger_s1.error(f\"Login error: {str(e)}\", exc_info=True)\n",
    "    finally:\n",
    "        b.disabled = False\n",
    "\n",
    "# 6. Download Function\n",
    "def do_stage1_download(b):\n",
    "    global stage1_ad_data, stage1_file_path\n",
    "    \n",
    "    if s1_chk_use_cache.value:\n",
    "        cached_df, cached_path = load_latest_cache()\n",
    "        if cached_df is not None:\n",
    "            stage1_ad_data = cached_df\n",
    "            stage1_file_path = cached_path\n",
    "            s1_status.value = f\"<span style='color:green;'>‚úÖ Loaded cache: {os.path.basename(cached_path)}</span>\"\n",
    "            s1_output.clear_output()\n",
    "            with s1_output:\n",
    "                print(\"Loaded cached AD data ‚Üí\", cached_path)\n",
    "                print(f\"Rows: {len(cached_df)}\")\n",
    "            return\n",
    "    \n",
    "    if not stage1_headers:\n",
    "        s1_status.value = \"<span style='color:red;'>‚ùå Please login first</span>\"\n",
    "        return\n",
    "    \n",
    "    b.disabled = True\n",
    "    s1_btn_refresh.disabled = True\n",
    "    \n",
    "    s1_output.clear_output()\n",
    "    \n",
    "    with s1_output:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üì• Downloading Active Directory Users\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\nFetching active users from Azure AD...\\n\")\n",
    "    \n",
    "    try:\n",
    "        session = requests.Session()\n",
    "        \n",
    "        progress = widgets.IntProgress(\n",
    "            value=0,\n",
    "            min=0,\n",
    "            max=100,\n",
    "            description='Progress:',\n",
    "            bar_style='info',\n",
    "            layout=widgets.Layout(width='80%')\n",
    "        )\n",
    "        status_label = widgets.HTML(value=\"Initializing...\")\n",
    "        progress_box = widgets.VBox([progress, status_label])\n",
    "        \n",
    "        with s1_output:\n",
    "            display(progress_box)\n",
    "        \n",
    "        logger_s1.info(\"Starting AD user download...\")\n",
    "        \n",
    "        requested_signin = s1_chk_auditlog.value\n",
    "        params_base = {\n",
    "            \"$filter\": \"accountEnabled eq true\",\n",
    "            \"$select\": \"id,mail,displayName,department,accountEnabled,jobTitle\",\n",
    "            \"$expand\": \"manager($select=displayName,mail,jobTitle,department)\",\n",
    "            \"$top\": 999\n",
    "        }\n",
    "        params_with_signin = {\n",
    "            \"$filter\": \"accountEnabled eq true\",\n",
    "            \"$select\": \"id,mail,displayName,department,accountEnabled,jobTitle,signInActivity\",\n",
    "            \"$expand\": \"manager($select=displayName,mail,jobTitle,department)\",\n",
    "            \"$top\": 999\n",
    "        }\n",
    "\n",
    "        use_signin_activity = False\n",
    "        manager_available = False\n",
    "\n",
    "        if requested_signin:\n",
    "            status_label.value = \"Attempting to fetch with sign-in activity...\"\n",
    "            progress.value = 10\n",
    "            response = session.get(USERS_URL, headers=stage1_headers, params=params_with_signin, timeout=30)\n",
    "        else:\n",
    "            status_label.value = \"AuditLog scope unchecked; skipping sign-in activity\"\n",
    "            progress.value = 10\n",
    "            response = session.get(USERS_URL, headers=stage1_headers, params=params_base, timeout=30)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            test_data = response.json()\n",
    "            if test_data.get('value'):\n",
    "                first_item = test_data['value'][0]\n",
    "                if requested_signin and 'signInActivity' in first_item:\n",
    "                    use_signin_activity = True\n",
    "                    logger_s1.info(\"‚úÖ signInActivity available\")\n",
    "                    with s1_output:\n",
    "                        print(\"‚úÖ Sign-in activity data available\\n\")\n",
    "                elif requested_signin:\n",
    "                    logger_s1.warning(\"‚ö†Ô∏è signInActivity not available in response\")\n",
    "                    with s1_output:\n",
    "                        print(\"‚ö†Ô∏è Sign-in activity not available (permission issue)\")\n",
    "                        print(\"Continuing without last sign-in data...\\n\")\n",
    "                if 'manager' in first_item:\n",
    "                    manager_available = True\n",
    "                    logger_s1.info(\"‚úÖ Manager info available via $expand\")\n",
    "                    with s1_output:\n",
    "                        print(\"‚úÖ Manager data available from Graph\\n\")\n",
    "        else:\n",
    "            logger_s1.warning(f\"‚ö†Ô∏è initial query failed: {response.status_code}\")\n",
    "            with s1_output:\n",
    "                print(f\"‚ö†Ô∏è Initial query failed (status {response.status_code})\")\n",
    "                print(\"Continuing with basic fields...\\n\")\n",
    "        \n",
    "        params = params_with_signin if use_signin_activity else params_base\n",
    "        \n",
    "        all_users = []\n",
    "        next_link = USERS_URL\n",
    "        page_count = 0\n",
    "        \n",
    "        status_label.value = \"Downloading user data...\"\n",
    "        progress.value = 20\n",
    "        \n",
    "        while next_link:\n",
    "            if page_count == 0:\n",
    "                response = session.get(next_link, headers=stage1_headers, params=params, timeout=30)\n",
    "            else:\n",
    "                response = session.get(next_link, headers=stage1_headers, timeout=30)\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                raise Exception(f\"API Error: {response.status_code} - {response.text}\")\n",
    "            \n",
    "            data = response.json()\n",
    "            users = data.get('value', [])\n",
    "            all_users.extend(users)\n",
    "            \n",
    "            page_count += 1\n",
    "            progress.value = min(20 + (page_count * 15), 80)\n",
    "            status_label.value = f\"Downloaded {len(all_users)} users (page {page_count})...\"\n",
    "            \n",
    "            next_link = data.get('@odata.nextLink')\n",
    "            \n",
    "            if page_count > 10:\n",
    "                break\n",
    "        \n",
    "        logger_s1.info(f\"Downloaded {len(all_users)} users from AD\")\n",
    "\n",
    "        if not manager_available:\n",
    "            status_label.value = \"Fetching managers (fallback)...\"\n",
    "            progress.value = min(progress.value + 5, 85)\n",
    "            for i, user in enumerate(all_users):\n",
    "                uid = user.get('id')\n",
    "                if not uid:\n",
    "                    continue\n",
    "                mgr_resp = session.get(\n",
    "                    f\"{USERS_URL}/{uid}/manager\",\n",
    "                    headers=stage1_headers,\n",
    "                    params={\"$select\": \"displayName,mail,jobTitle,department\"},\n",
    "                    timeout=20\n",
    "                )\n",
    "                if mgr_resp.status_code == 200:\n",
    "                    user['manager'] = mgr_resp.json()\n",
    "                if i % 50 == 0:\n",
    "                    progress.value = min(85, progress.value + 1)\n",
    "                    status_label.value = f\"Managers fetched: {i+1}/{len(all_users)}\"\n",
    "        \n",
    "        status_label.value = \"Processing user data...\"\n",
    "        progress.value = 85\n",
    "        \n",
    "        processed_users = []\n",
    "        \n",
    "        for user in all_users:\n",
    "            email = (user.get('mail') or '').lower().strip()\n",
    "            if not email:\n",
    "                continue\n",
    "            \n",
    "            user_data = {\n",
    "                'email': email,\n",
    "                'displayName': user.get('displayName', 'N/A'),\n",
    "                'department': user.get('department') or 'N/A',\n",
    "                'accountEnabled': user.get('accountEnabled', False),\n",
    "                'jobTitle': user.get('jobTitle') or 'N/A'\n",
    "            }\n",
    "\n",
    "            mgr = user.get('manager', {}) or {}\n",
    "            mgr_email = (mgr.get('mail') or '').lower().strip()\n",
    "            user_data['managerEmail'] = mgr_email if mgr_email else 'N/A'\n",
    "            user_data['managerName'] = mgr.get('displayName', 'N/A')\n",
    "            user_data['managerJobTitle'] = mgr.get('jobTitle', 'N/A')\n",
    "            user_data['managerDepartment'] = mgr.get('department', 'N/A')\n",
    "            \n",
    "            if use_signin_activity and isinstance(user.get('signInActivity'), dict):\n",
    "                signin_data = user.get('signInActivity') or {}\n",
    "                last_signin = signin_data.get('lastSignInDateTime', '')\n",
    "                user_data['lastSignInDateTime'] = last_signin if last_signin else 'Never'\n",
    "                if last_signin and last_signin != 'Never':\n",
    "                    try:\n",
    "                        signin_date = datetime.fromisoformat(last_signin.replace('Z', '+00:00'))\n",
    "                        cutoff_date = datetime.now().astimezone() - timedelta(days=730)\n",
    "                        user_data['activeIn24Months'] = signin_date > cutoff_date\n",
    "                    except:\n",
    "                        user_data['activeIn24Months'] = 'Unknown'\n",
    "                else:\n",
    "                    user_data['activeIn24Months'] = False\n",
    "            else:\n",
    "                user_data['lastSignInDateTime'] = 'N/A'\n",
    "                user_data['activeIn24Months'] = 'N/A'\n",
    "            \n",
    "            processed_users.append(user_data)\n",
    "        \n",
    "        stage1_ad_data = pd.DataFrame(processed_users)\n",
    "        \n",
    "        status_label.value = \"Saving to file...\"\n",
    "        progress.value = 95\n",
    "        \n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "        filename = f\"ad_users_{timestamp}.csv\"\n",
    "        stage1_file_path = os.path.join(AD_CACHE_DIR, filename)\n",
    "        \n",
    "        stage1_ad_data.to_csv(stage1_file_path, index=False)\n",
    "        \n",
    "        progress.value = 100\n",
    "        progress.bar_style = 'success'\n",
    "        status_label.value = \"<span style='color:green;font-weight:bold;'>‚úÖ Complete!</span>\"\n",
    "        \n",
    "        total_users = len(stage1_ad_data)\n",
    "        active_users = stage1_ad_data['accountEnabled'].sum()\n",
    "        manager_known = (stage1_ad_data['managerEmail'] != 'N/A').sum()\n",
    "        \n",
    "        with s1_output:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"üìä Download Complete\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"Total users:        {total_users}\")\n",
    "            print(f\"Active accounts:    {active_users}\")\n",
    "            if use_signin_activity:\n",
    "                active_24m = (stage1_ad_data['activeIn24Months'] == True).sum()\n",
    "                print(f\"Active in 24 months: {active_24m}\")\n",
    "            print(f\"Manager linked:     {manager_known}\")\n",
    "            print(f\"\\nSaved to: {stage1_file_path}\")\n",
    "            print(\"=\"*60)\n",
    "        \n",
    "        s1_status.value = f\"<span style='color:green;'>‚úÖ Downloaded {total_users} users ‚Üí {filename}</span>\"\n",
    "        \n",
    "        logger_s1.info(f\"Stage 1 complete: {total_users} users saved to {stage1_file_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        with s1_output:\n",
    "            print(f\"\\n‚ùå Error: {str(e)}\")\n",
    "        s1_status.value = f\"<span style='color:red;'>‚ùå Error: {str(e)}</span>\"\n",
    "        logger_s1.error(f\"Download error: {str(e)}\", exc_info=True)\n",
    "    finally:\n",
    "        b.disabled = False\n",
    "        s1_btn_refresh.disabled = False\n",
    "\n",
    "# 7. Bind Events\n",
    "s1_btn_login.on_click(do_stage1_login)\n",
    "s1_btn_download.on_click(do_stage1_download)\n",
    "s1_btn_refresh.on_click(do_stage1_download)\n",
    "\n",
    "# 8. UI Layout\n",
    "stage1_ui = widgets.VBox([\n",
    "    widgets.HTML(\"\"\"\n",
    "        <div style='\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            padding: 20px;\n",
    "            border-radius: 8px;\n",
    "            color: white;\n",
    "            margin-bottom: 20px;\n",
    "        '>\n",
    "            <h2 style='margin: 0 0 10px 0;'>üõ°Ô∏è Stage 1: AD User Download</h2>\n",
    "            <p style='margin: 0; opacity: 0.9;'>\n",
    "                Authenticate with Azure AD and download active users for validation\n",
    "            </p>\n",
    "        </div>\n",
    "    \"\"\"),\n",
    "    widgets.HBox([s1_btn_login, s1_btn_download, s1_btn_refresh]),\n",
    "    s1_chk_auditlog,\n",
    "    s1_chk_use_cache,\n",
    "    s1_status,\n",
    "    s1_output\n",
    "])\n",
    "\n",
    "clear_output()\n",
    "display(stage1_ui)\n",
    "\n",
    "logger_s1.info(\"Stage 1 UI initialized\")\n",
    "logger_s1.info(\"=\"*60)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 1.5: Org Tree Builder (v7.3 Stage 1.5) ===\n",
    "import os, glob, logging, io, math\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Constants\n",
    "CORP_PREFIX = \"corporate\"\n",
    "MAX_TREE_DEPTH = 3  # CEO (level 1) + 3 levels down = depth 3 from root\n",
    "TITLE_PRIORITY = [\n",
    "    'chief executive', 'chief', 'ceo', 'president', 'vice president', 'vp',\n",
    "    'director', 'head', 'manager', 'lead'\n",
    "]\n",
    "\n",
    "# Paths\n",
    "today_str = datetime.now().strftime('%Y-%m-%d')\n",
    "BASE_DIR = os.path.join(\"output\", today_str)\n",
    "AD_CACHE_DIR = os.path.join(BASE_DIR, \"ad_cache\")\n",
    "ORG_DIR = os.path.join(BASE_DIR, \"orgchart\")\n",
    "MAP_DIR = os.path.join(\"input\", \"mapping\")\n",
    "LOG_DIR = os.path.join(BASE_DIR, \"logs\")\n",
    "os.makedirs(ORG_DIR, exist_ok=True)\n",
    "os.makedirs(MAP_DIR, exist_ok=True)\n",
    "\n",
    "# Logging\n",
    "log_file = os.path.join(LOG_DIR, f\"aer_stage1_5_{datetime.now().strftime('%Y%m%d_%H%M')}.log\")\n",
    "logger_s15 = logging.getLogger(\"aer_stage1_5\")\n",
    "logger_s15.handlers.clear()\n",
    "logger_s15.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "fh = logging.FileHandler(log_file, encoding=\"utf-8\")\n",
    "fh.setFormatter(formatter)\n",
    "logger_s15.addHandler(fh)\n",
    "logger_s15.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# Globals\n",
    "s15_ad_df = None\n",
    "s15_tree_html = widgets.HTML()\n",
    "s15_status = widgets.HTML(value=\"<i>Load AD cache to build org tree</i>\")\n",
    "s15_output = widgets.Output()\n",
    "drop_head = widgets.Dropdown(description='Dept Head', options=[], layout=widgets.Layout(width='75%'))\n",
    "txt_reviewer_email = widgets.Text(description='Reviewer', placeholder='email@example.com', layout=widgets.Layout(width='50%'))\n",
    "txt_department = widgets.Text(description='Dept', layout=widgets.Layout(width='50%'))\n",
    "btn_add = widgets.Button(description='‚ûï Add/Update Mapping', button_style='warning', layout=widgets.Layout(width='220px'))\n",
    "btn_save = widgets.Button(description='üíæ Save Mapping', button_style='success', layout=widgets.Layout(width='160px'))\n",
    "btn_refresh = widgets.Button(description='üîÑ Rebuild Tree', button_style='info', layout=widgets.Layout(width='140px'))\n",
    "mapping_table = widgets.HTML()\n",
    "\n",
    "s15_mapping_rows = []\n",
    "\n",
    "# Helpers\n",
    "def normalize_department(dept):\n",
    "    if dept is None or (isinstance(dept, float) and math.isnan(dept)):\n",
    "        dept = ''\n",
    "    else:\n",
    "        dept = str(dept).strip()\n",
    "    if dept.lower().startswith('branch'):\n",
    "        return 'Branch'\n",
    "    return dept or 'N/A'\n",
    "\n",
    "def load_latest_ad():\n",
    "    try:\n",
    "        cache_files = glob.glob(os.path.join(AD_CACHE_DIR, \"ad_users_*.csv\"))\n",
    "        if not cache_files:\n",
    "            return None, \"No AD cache found. Run Stage 1 first.\"\n",
    "        latest = max(cache_files, key=os.path.getmtime)\n",
    "        df = pd.read_csv(latest)\n",
    "        df = df[df['department'].fillna('').str.lower().str.startswith(CORP_PREFIX)]\n",
    "        return df, f\"Loaded {len(df)} corporate users from {os.path.basename(latest)}\"\n",
    "    except Exception as e:\n",
    "        return None, f\"Error loading AD cache: {e}\"\n",
    "\n",
    "# Build tree based on manager hierarchy\n",
    "\n",
    "def find_root(df):\n",
    "    names = df['displayName'].str.lower().fillna('').str.strip()\n",
    "    mask_name = names.isin(['steven bush', 'steve bush'])\n",
    "    if mask_name.any():\n",
    "        return df.loc[mask_name, 'email'].iloc[0]\n",
    "    mask_title = df['jobTitle'].str.lower().fillna('').str.contains('chief executive|ceo|president')\n",
    "    if mask_title.any():\n",
    "        return df.loc[mask_title, 'email'].iloc[0]\n",
    "    mask_nomgr = df['managerEmail'].fillna('N/A') == 'N/A'\n",
    "    if mask_nomgr.any():\n",
    "        return df.loc[mask_nomgr, 'email'].iloc[0]\n",
    "    return df.iloc[0]['email'] if len(df) else None\n",
    "\n",
    "def build_org_tree(df):\n",
    "    df = df.copy()\n",
    "    if 'managerEmail' not in df.columns:\n",
    "        df['managerEmail'] = 'N/A'\n",
    "    df['managerEmail'] = df['managerEmail'].fillna('N/A')\n",
    "    root = find_root(df)\n",
    "    nodes = {row['email']: row for _, row in df.iterrows()}\n",
    "    children = {}\n",
    "    for _, row in df.iterrows():\n",
    "        mgr = row.get('managerEmail', 'N/A')\n",
    "        if mgr not in nodes or mgr == 'N/A':\n",
    "            mgr = root\n",
    "        children.setdefault(mgr, []).append(row['email'])\n",
    "    return nodes, children, root\n",
    "\n",
    "def compute_depths(children, root, max_depth=MAX_TREE_DEPTH):\n",
    "    depths = {root: 0}\n",
    "    queue = [root]\n",
    "    while queue:\n",
    "        cur = queue.pop(0)\n",
    "        d = depths[cur]\n",
    "        if d >= max_depth:\n",
    "            continue\n",
    "        for child in children.get(cur, []):\n",
    "            depths[child] = d + 1\n",
    "            queue.append(child)\n",
    "    return depths\n",
    "\n",
    "def tree_html(nodes, children, email, depth, max_depth):\n",
    "    if email not in nodes or depth > max_depth:\n",
    "        return ''\n",
    "    user = nodes[email]\n",
    "    label = f\"<b>{user.get('displayName','N/A')}</b> ‚Äî {user.get('jobTitle','N/A')} ‚Äî {user.get('department','N/A')} ‚Äî {email}\"\n",
    "    parts = [f\"<details {'open' if depth==0 else ''}><summary>{label}</summary>\"]\n",
    "    for child in sorted(children.get(email, []), key=lambda e: nodes[e].get('displayName','').lower()):\n",
    "        parts.append(tree_html(nodes, children, child, depth+1, max_depth))\n",
    "    parts.append(\"</details>\")\n",
    "    return '\\n'.join(parts)\n",
    "\n",
    "def dept_heads_by_title(df, depths):\n",
    "    heads = {}\n",
    "    for dept, grp in df.groupby(df['department'].fillna('N/A')):\n",
    "        grp = grp.copy()\n",
    "        grp['depth'] = grp['email'].map(depths).fillna(99)\n",
    "        def title_score(title):\n",
    "            t = str(title).lower()\n",
    "            for i, kw in enumerate(TITLE_PRIORITY):\n",
    "                if kw in t:\n",
    "                    return i\n",
    "            return len(TITLE_PRIORITY) + 1\n",
    "        grp['title_score'] = grp['jobTitle'].apply(title_score)\n",
    "        head = grp.sort_values(['title_score','depth','displayName']).iloc[0]\n",
    "        heads[dept] = head\n",
    "    return heads\n",
    "\n",
    "# UI render\n",
    "\n",
    "def refresh_tree(_=None):\n",
    "    global s15_ad_df, s15_mapping_rows\n",
    "    s15_output.clear_output()\n",
    "    df, msg = load_latest_ad()\n",
    "    if df is None:\n",
    "        s15_status.value = f\"<span style='color:red;'>‚ùå {msg}</span>\"\n",
    "        return\n",
    "    s15_ad_df = df\n",
    "    nodes, children, root = build_org_tree(df)\n",
    "    if not root:\n",
    "        s15_status.value = '<span style=\"color:red;\">‚ùå Could not locate root (CEO)</span>'\n",
    "        return\n",
    "\n",
    "    depths = compute_depths(children, root)\n",
    "    valid = {e for e,d in depths.items() if d <= MAX_TREE_DEPTH}\n",
    "\n",
    "    # Dropdown options\n",
    "    opts = []\n",
    "    for _, row in df[df['email'].isin(valid)].sort_values(['department','displayName']).iterrows():\n",
    "        label = f\"{row.get('department','N/A')} | {row.get('displayName','N/A')} | {row.get('jobTitle','N/A')} | {row.get('email','')}\"\n",
    "        opts.append((label, row.get('email','')))\n",
    "    drop_head.options = opts\n",
    "\n",
    "    # Determine dept heads by title (not by tree position)\n",
    "    heads = dept_heads_by_title(df[df['email'].isin(valid)], depths)\n",
    "\n",
    "    # Build mapping rows\n",
    "    s15_mapping_rows = []\n",
    "    for dept, head in heads.items():\n",
    "        head_email = head.get('email','')\n",
    "        head_mgr = head.get('managerEmail','') if head.get('managerEmail','N/A') != 'N/A' else ''\n",
    "        branch_val = '' if str(dept).lower().startswith('corporate') else 'Branch'\n",
    "        s15_mapping_rows.append({'email': head_email, 'department': dept, 'reviewer': head_mgr, 'branch': branch_val})\n",
    "        s15_mapping_rows.append({'email': '*', 'department': dept, 'reviewer': head_email, 'branch': branch_val})\n",
    "\n",
    "    render_mapping()\n",
    "\n",
    "    # Tree view: manager hierarchy, limited depth\n",
    "    tree = tree_html(nodes, children, root, 0, MAX_TREE_DEPTH)\n",
    "    s15_tree_html.value = (\n",
    "        \"<div style='max-height:520px;overflow:auto;border:1px solid #ddd;padding:10px;'>\" +\n",
    "        \"<h4>Corporate Org (manager hierarchy, CEO + 3 levels)</h4>\" + tree + \"</div>\"\n",
    "    )\n",
    "    s15_status.value = f\"<span style='color:green;'>‚úÖ {msg}</span>\"\n",
    "    logger_s15.info(msg)\n",
    "\n",
    "# Mapping table render\n",
    "\n",
    "def render_mapping():\n",
    "    if not s15_mapping_rows:\n",
    "        mapping_table.value = \"<i>No mappings added yet</i>\"\n",
    "        return\n",
    "    df = pd.DataFrame(s15_mapping_rows)\n",
    "    cols = ['email','department','reviewer','branch']\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = ''\n",
    "    mapping_table.value = df[cols].to_html(index=False)\n",
    "\n",
    "# Events\n",
    "\n",
    "def on_head_change(change):\n",
    "    if not change['new'] or s15_ad_df is None:\n",
    "        return\n",
    "    row = s15_ad_df.loc[s15_ad_df['email'] == change['new']].iloc[0]\n",
    "    dept = normalize_department(row.get('department'))\n",
    "    txt_department.value = dept\n",
    "    txt_reviewer_email.value = row.get('email', '')\n",
    "\n",
    "def on_add_clicked(_):\n",
    "    if not txt_department.value or not txt_reviewer_email.value:\n",
    "        s15_status.value = \"<span style='color:red;'>‚ùå Department and reviewer email required</span>\"\n",
    "        return\n",
    "    dept = normalize_department(txt_department.value)\n",
    "    reviewer = txt_reviewer_email.value.strip().lower()\n",
    "    email = drop_head.value\n",
    "    branch_val = '' if dept.lower().startswith('corporate') else 'Branch'\n",
    "    new_rows = [\n",
    "        {'email': email or reviewer, 'department': dept, 'reviewer': reviewer, 'branch': branch_val},\n",
    "        {'email': '*', 'department': dept, 'reviewer': email or reviewer, 'branch': branch_val}\n",
    "    ]\n",
    "    s15_mapping_rows[:] = [r for r in s15_mapping_rows if r.get('department','').lower() != dept.lower()]\n",
    "    s15_mapping_rows.extend(new_rows)\n",
    "    s15_status.value = f\"<span style='color:blue;'>‚úÖ Mapping updated for {dept}</span>\"\n",
    "    render_mapping()\n",
    "\n",
    "def on_save_clicked(_):\n",
    "    if not s15_mapping_rows:\n",
    "        s15_status.value = \"<span style='color:red;'>‚ùå No mappings to save</span>\"\n",
    "        return\n",
    "    df = pd.DataFrame(s15_mapping_rows)\n",
    "    ts = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "    path = os.path.join(MAP_DIR, f\"org_mapping_{ts}.csv\")\n",
    "    df.to_csv(path, index=False)\n",
    "    s15_status.value = f\"<span style='color:green;'>üíæ Saved mapping to {path}</span>\"\n",
    "    logger_s15.info(f\"Mapping saved to {path}\")\n",
    "\n",
    "# Bind events\n",
    "drop_head.observe(on_head_change, names='value')\n",
    "btn_add.on_click(on_add_clicked)\n",
    "btn_save.on_click(on_save_clicked)\n",
    "btn_refresh.on_click(refresh_tree)\n",
    "\n",
    "# Layout\n",
    "stage15_ui = widgets.VBox([\n",
    "    widgets.HTML(\"\"\"\n",
    "        <div style='\n",
    "            background: linear-gradient(135deg, #5ee7df 0%, #b490ca 100%);\n",
    "            padding: 20px;\n",
    "            border-radius: 8px;\n",
    "            color: white;\n",
    "            margin-bottom: 20px;\n",
    "        '>\n",
    "            <h2 style='margin: 0 0 10px 0;'>üå≥ Stage 1.5: Org Tree Builder</h2>\n",
    "            <p style='margin: 0; opacity: 0.9;'>\n",
    "                Manager hierarchy from CEO (Steven/Steve Bush) down 3 levels; auto-mapping dept heads by title priority\n",
    "            </p>\n",
    "        </div>\n",
    "    \"\"\"),\n",
    "    widgets.HBox([btn_refresh, s15_status]),\n",
    "    s15_tree_html,\n",
    "    widgets.HTML('<h4>Current Mapping (email, department, reviewer, branch)</h4>'),\n",
    "    mapping_table,\n",
    "    widgets.HBox([drop_head]),\n",
    "    widgets.HBox([txt_department, txt_reviewer_email]),\n",
    "    widgets.HBox([btn_add, btn_save]),\n",
    "    s15_output\n",
    "])\n",
    "\n",
    "clear_output()\n",
    "display(stage15_ui)\n",
    "refresh_tree()\n",
    "logger_s15.info(\"Stage 1.5 UI initialized\")\n",
    "logger_s15.info(\"=\"*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Stage 2: Email/User Validation with Enhanced UI (Jupyter Cell) v8.1\n",
    "\n",
    "Changes from v8.0:\n",
    "1. Fold (collapsible accordion) 100% perfect matches instead of hiding\n",
    "2. Fuzzy matches < 80% require manual selection (no auto-populate)\n",
    "3. Output includes Department and is_AD_active columns from AD cache\n",
    "4. Delete button on each review row ‚Äî removes from UI and output\n",
    "5. All displayed records (even empty inputs) saved unless explicitly deleted\n",
    "\n",
    "Copy and paste this entire cell into Jupyter notebook and run.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import io\n",
    "import glob\n",
    "import unicodedata\n",
    "from typing import Dict, List, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Try import fuzzy matching\n",
    "try:\n",
    "    from rapidfuzz import fuzz, process\n",
    "    FUZZY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    try:\n",
    "        from fuzzywuzzy import fuzz, process\n",
    "        FUZZY_AVAILABLE = True\n",
    "    except ImportError:\n",
    "        FUZZY_AVAILABLE = False\n",
    "        print(\"‚ö†Ô∏è Fuzzy matching unavailable. Install: pip install rapidfuzz\")\n",
    "\n",
    "# ============================================\n",
    "# Setup Paths\n",
    "# ============================================\n",
    "\n",
    "today_str = datetime.now().strftime('%Y-%m-%d')\n",
    "BASE_DIR = os.path.join(\"output\", today_str)\n",
    "AD_CACHE_DIR = os.path.join(BASE_DIR, \"ad_cache\")\n",
    "STAGE2_DIR = os.path.join(BASE_DIR, \"stage2_validated\")\n",
    "LOG_DIR = os.path.join(BASE_DIR, \"logs\")\n",
    "os.makedirs(STAGE2_DIR, exist_ok=True)\n",
    "\n",
    "# ============================================\n",
    "# Validation Status Enum\n",
    "# ============================================\n",
    "\n",
    "class ValidationStatus:\n",
    "    \"\"\"Validation status categories\"\"\"\n",
    "    VALID_PERFECT = \"valid_perfect\"\n",
    "    WARN_NAME_MISMATCH = \"warn_name_mismatch\"\n",
    "    INFO_FUZZY_UNIQUE = \"info_fuzzy_unique\"\n",
    "    ERR_FUZZY_MULTIPLE = \"err_fuzzy_multiple\"\n",
    "    ERR_NOT_FOUND = \"err_not_found\"\n",
    "    ERR_EMAIL_INVALID = \"err_email_invalid\"\n",
    "    ERR_MISSING_DATA = \"err_missing_data\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_display_text(status: str) -> str:\n",
    "        status_map = {\n",
    "            ValidationStatus.VALID_PERFECT: \"‚úÖ Verified (Email & Name Match)\",\n",
    "            ValidationStatus.WARN_NAME_MISMATCH: \"‚ö†Ô∏è Email Valid - Name Mismatch\",\n",
    "            ValidationStatus.INFO_FUZZY_UNIQUE: \"üîµ Auto-Matched by Name (Single Match)\",\n",
    "            ValidationStatus.ERR_FUZZY_MULTIPLE: \"üü† Manual Selection Required (Multiple Matches)\",\n",
    "            ValidationStatus.ERR_NOT_FOUND: \"‚ùå User Not Found in AD\",\n",
    "            ValidationStatus.ERR_EMAIL_INVALID: \"‚ùå Email Not in AD\",\n",
    "            ValidationStatus.ERR_MISSING_DATA: \"‚ö™ Insufficient Data\"\n",
    "        }\n",
    "        return status_map.get(status, \"Unknown Status\")\n",
    "\n",
    "# ============================================\n",
    "# Global State\n",
    "# ============================================\n",
    "\n",
    "stage2_ad_cache = {}\n",
    "stage2_name_index = {}\n",
    "stage2_input_df = None\n",
    "stage2_input_filename = \"\"\n",
    "stage2_categorized = {}\n",
    "stage2_ui_rows = {}\n",
    "\n",
    "# ============================================\n",
    "# Helper Functions\n",
    "# ============================================\n",
    "\n",
    "def is_email_valid(email) -> bool:\n",
    "    \"\"\"Check if email is valid\"\"\"\n",
    "    if pd.isna(email):\n",
    "        return False\n",
    "    email_str = str(email).strip().lower()\n",
    "    if email_str in ['', 'nan', 'none', 'n/a', 'na', '#n/a']:\n",
    "        return False\n",
    "    if '@' not in email_str or '.' not in email_str:\n",
    "        return False\n",
    "    if not re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$', email_str):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def normalize_name(name) -> str:\n",
    "    \"\"\"Normalize name for fuzzy matching\"\"\"\n",
    "    if not name or pd.isna(name):\n",
    "        return \"\"\n",
    "    name = str(name).lower()\n",
    "    name = unicodedata.normalize('NFKC', name)\n",
    "    name = re.sub(r'[^a-z0-9\\s]', ' ', name)\n",
    "    name = ' '.join(name.split())\n",
    "    return name.strip()\n",
    "\n",
    "\n",
    "def fuzzy_match_name(target_name: str, name_index: Dict, ad_cache: Dict, top_n: int = 5) -> List[Dict]:\n",
    "    \"\"\"Find best email matches for a name\"\"\"\n",
    "    if not FUZZY_AVAILABLE or not name_index:\n",
    "        return []\n",
    "\n",
    "    norm_target = normalize_name(target_name)\n",
    "    if not norm_target:\n",
    "        return []\n",
    "\n",
    "    # Exact match check\n",
    "    if norm_target in name_index:\n",
    "        email = name_index[norm_target]\n",
    "        user = ad_cache[email]\n",
    "        return [{\n",
    "            'email': email,\n",
    "            'name': user['name'],\n",
    "            'dept': user['dept'],\n",
    "            'score': 100,\n",
    "            'match_type': 'exact'\n",
    "        }]\n",
    "\n",
    "    # Fuzzy search\n",
    "    try:\n",
    "        candidates = list(name_index.keys())\n",
    "        matches = process.extract(\n",
    "            norm_target,\n",
    "            candidates,\n",
    "            scorer=fuzz.token_sort_ratio,\n",
    "            limit=top_n * 2\n",
    "        )\n",
    "\n",
    "        results = []\n",
    "        seen = set()\n",
    "\n",
    "        for match_name, score, _ in matches:\n",
    "            if score < 70:\n",
    "                continue\n",
    "\n",
    "            email = name_index[match_name]\n",
    "            if email in seen:\n",
    "                continue\n",
    "\n",
    "            seen.add(email)\n",
    "            user = ad_cache[email]\n",
    "\n",
    "            results.append({\n",
    "                'email': email,\n",
    "                'name': user['name'],\n",
    "                'dept': user['dept'],\n",
    "                'score': int(score),\n",
    "                'match_type': 'high' if score >= 90 else 'medium'\n",
    "            })\n",
    "\n",
    "            if len(results) >= top_n:\n",
    "                break\n",
    "\n",
    "        return results\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "\n",
    "def load_ad_cache():\n",
    "    \"\"\"Load AD cache from Stage 1\"\"\"\n",
    "    global stage2_ad_cache, stage2_name_index\n",
    "\n",
    "    try:\n",
    "        cache_files = glob.glob(os.path.join(AD_CACHE_DIR, \"ad_users_*.csv\"))\n",
    "        if not cache_files:\n",
    "            return False, \"No AD cache found. Please run Stage 1 first.\"\n",
    "\n",
    "        latest_cache = max(cache_files, key=os.path.getmtime)\n",
    "        df = pd.read_csv(latest_cache)\n",
    "\n",
    "        # Build cache\n",
    "        for _, row in df.iterrows():\n",
    "            email = str(row['email']).lower().strip()\n",
    "            if not email or email == 'nan':\n",
    "                continue\n",
    "\n",
    "            stage2_ad_cache[email] = {\n",
    "                'email': email,\n",
    "                'name': row['displayName'],\n",
    "                'dept': row['department'],\n",
    "                'active': row['accountEnabled']\n",
    "            }\n",
    "\n",
    "            # Build name index\n",
    "            norm_name = normalize_name(row['displayName'])\n",
    "            if norm_name:\n",
    "                stage2_name_index[norm_name] = email\n",
    "\n",
    "                # Add reversed name\n",
    "                parts = norm_name.split()\n",
    "                if len(parts) == 2:\n",
    "                    reversed_name = f\"{parts[1]} {parts[0]}\"\n",
    "                    stage2_name_index[reversed_name] = email\n",
    "\n",
    "        return True, f\"Loaded {len(stage2_ad_cache)} users from {os.path.basename(latest_cache)}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return False, f\"Error loading AD cache: {str(e)}\"\n",
    "\n",
    "\n",
    "def categorize_user(row: pd.Series, ad_cache: Dict, name_index: Dict) -> Tuple[str, Dict]:\n",
    "    \"\"\"Categorize a user record\"\"\"\n",
    "    user_email = row.get('Email') if 'Email' in row.index else row.iloc[0]\n",
    "    user_name = row.get('User Name') if 'User Name' in row.index else row.iloc[1] if len(row) > 1 else ''\n",
    "\n",
    "    metadata = {\n",
    "        'original_email': user_email,\n",
    "        'original_name': user_name,\n",
    "        'ad_user': None,\n",
    "        'fuzzy_matches': [],\n",
    "        'validation_message': '',\n",
    "        'final_email': '',\n",
    "        'final_name': ''\n",
    "    }\n",
    "\n",
    "    email_valid = is_email_valid(user_email)\n",
    "\n",
    "    # Case 1: Both missing\n",
    "    if not email_valid and (not user_name or pd.isna(user_name) or str(user_name).strip() == ''):\n",
    "        metadata['validation_message'] = 'Insufficient data'\n",
    "        return ValidationStatus.ERR_MISSING_DATA, metadata\n",
    "\n",
    "    # Case 2: Email valid\n",
    "    if email_valid:\n",
    "        email_clean = str(user_email).strip().lower()\n",
    "\n",
    "        if email_clean not in ad_cache:\n",
    "            metadata['validation_message'] = f'Email not in AD'\n",
    "            return ValidationStatus.ERR_EMAIL_INVALID, metadata\n",
    "\n",
    "        ad_user = ad_cache[email_clean]\n",
    "        metadata['ad_user'] = ad_user\n",
    "        metadata['final_email'] = email_clean\n",
    "        metadata['final_name'] = ad_user['name']\n",
    "\n",
    "        # Check name match\n",
    "        ad_name_norm = normalize_name(ad_user['name'])\n",
    "        input_name_norm = normalize_name(user_name)\n",
    "\n",
    "        if input_name_norm and ad_name_norm == input_name_norm:\n",
    "            metadata['validation_message'] = 'Perfect match'\n",
    "            return ValidationStatus.VALID_PERFECT, metadata\n",
    "        else:\n",
    "            metadata['validation_message'] = f\"Name differs\"\n",
    "            return ValidationStatus.WARN_NAME_MISMATCH, metadata\n",
    "\n",
    "    # Case 3: Email missing, try fuzzy match\n",
    "    if not user_name or pd.isna(user_name) or str(user_name).strip() == '':\n",
    "        metadata['validation_message'] = 'No name provided'\n",
    "        return ValidationStatus.ERR_MISSING_DATA, metadata\n",
    "\n",
    "    fuzzy_matches = fuzzy_match_name(user_name, name_index, ad_cache, top_n=5)\n",
    "\n",
    "    if not fuzzy_matches:\n",
    "        metadata['validation_message'] = 'No match found'\n",
    "        return ValidationStatus.ERR_NOT_FOUND, metadata\n",
    "\n",
    "    metadata['fuzzy_matches'] = fuzzy_matches\n",
    "\n",
    "    if len(fuzzy_matches) == 1:\n",
    "        match = fuzzy_matches[0]\n",
    "        if match['score'] >= 80:\n",
    "            # High confidence ‚Äî auto-populate\n",
    "            metadata['final_email'] = match['email']\n",
    "            metadata['final_name'] = match['name']\n",
    "            metadata['validation_message'] = f'Single match: {match[\"score\"]}%'\n",
    "            return ValidationStatus.INFO_FUZZY_UNIQUE, metadata\n",
    "        else:\n",
    "            # Low confidence ‚Äî require manual selection\n",
    "            metadata['validation_message'] = f'Low confidence: {match[\"score\"]}%'\n",
    "            return ValidationStatus.ERR_FUZZY_MULTIPLE, metadata\n",
    "    else:\n",
    "        metadata['validation_message'] = f'{len(fuzzy_matches)} matches found'\n",
    "        return ValidationStatus.ERR_FUZZY_MULTIPLE, metadata\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# UI Components\n",
    "# ============================================\n",
    "\n",
    "def create_fuzzy_unique_row(idx: int, row: pd.Series, metadata: Dict):\n",
    "    \"\"\"Green row for single fuzzy match, with delete button\"\"\"\n",
    "    original_name = str(metadata['original_name'])\n",
    "    match = metadata['fuzzy_matches'][0]\n",
    "\n",
    "    name_html = f\"\"\"\n",
    "    <div style='width:220px; padding:5px;'>\n",
    "        <b style='color:#34c759;'>‚úì {original_name}</b>\n",
    "        <br><small style='color:#34c759;'>Match: {match['score']}%</small>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    info_html = f\"\"\"\n",
    "    <div style='padding:5px; border:1px solid #34c759; background:#e8f5e9; border-radius:4px; width:500px;'>\n",
    "        <b style='color:#34c759;'>‚úÖ Single Match</b><br>\n",
    "        <b>{match['name']}</b> ({match['email']})<br>\n",
    "        Dept: {match['dept']} | Confidence: {match['score']}%\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    btn_delete = widgets.Button(\n",
    "        description='‚úï',\n",
    "        button_style='danger',\n",
    "        layout=widgets.Layout(width='36px', height='30px'),\n",
    "        tooltip='Remove this record'\n",
    "    )\n",
    "\n",
    "    container = widgets.HBox([\n",
    "        widgets.HTML(value=name_html),\n",
    "        widgets.HTML(value=info_html),\n",
    "        btn_delete\n",
    "    ])\n",
    "\n",
    "    result = {\n",
    "        'index': idx,\n",
    "        'row': container,\n",
    "        'selected_email': match['email'],\n",
    "        'selected_name': match['name'],\n",
    "        'deleted': False\n",
    "    }\n",
    "\n",
    "    def on_delete(b):\n",
    "        result['deleted'] = True\n",
    "        container.layout.display = 'none'\n",
    "\n",
    "    btn_delete.on_click(on_delete)\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_fuzzy_multiple_row(idx: int, row: pd.Series, metadata: Dict):\n",
    "    \"\"\"Orange row for multiple fuzzy matches or low-confidence single match\"\"\"\n",
    "    original_name = str(metadata['original_name'])\n",
    "    fuzzy_matches = metadata['fuzzy_matches']\n",
    "    is_low_confidence = len(fuzzy_matches) == 1\n",
    "\n",
    "    if is_low_confidence:\n",
    "        badge_text = f\"Low confidence: {fuzzy_matches[0]['score']}%\"\n",
    "    else:\n",
    "        badge_text = f\"{len(fuzzy_matches)} matches\"\n",
    "\n",
    "    name_html = f\"\"\"\n",
    "    <div style='width:220px; padding:5px;'>\n",
    "        <b style='color:#ff9500;'>‚ö†Ô∏è {original_name}</b>\n",
    "        <br><small style='color:#ff9500;'>{badge_text}</small>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    options = [('-- Select --', '')]\n",
    "    for match in fuzzy_matches:\n",
    "        label = f\"{match['name']} ({match['email']}) - {match['dept']} [{match['score']}%]\"\n",
    "        options.append((label, match['email']))\n",
    "    options.append(('-- Manual Entry --', 'MANUAL'))\n",
    "\n",
    "    # Low-confidence single match: don't pre-select, force manual choice\n",
    "    default_value = '' if is_low_confidence else fuzzy_matches[0]['email']\n",
    "\n",
    "    dropdown = widgets.Dropdown(\n",
    "        options=options,\n",
    "        value=default_value,\n",
    "        description='',\n",
    "        layout=widgets.Layout(width='550px')\n",
    "    )\n",
    "\n",
    "    txt_manual = widgets.Text(\n",
    "        placeholder='Enter email manually',\n",
    "        layout=widgets.Layout(width='300px'),\n",
    "        disabled=True\n",
    "    )\n",
    "\n",
    "    def on_dropdown_change(change):\n",
    "        if change['new'] == 'MANUAL':\n",
    "            txt_manual.disabled = False\n",
    "        else:\n",
    "            txt_manual.disabled = True\n",
    "            txt_manual.value = ''\n",
    "\n",
    "    dropdown.observe(on_dropdown_change, names='value')\n",
    "\n",
    "    btn_delete = widgets.Button(\n",
    "        description='‚úï',\n",
    "        button_style='danger',\n",
    "        layout=widgets.Layout(width='36px', height='30px'),\n",
    "        tooltip='Remove this record'\n",
    "    )\n",
    "\n",
    "    container = widgets.HBox([\n",
    "        widgets.HTML(value=name_html),\n",
    "        dropdown,\n",
    "        txt_manual,\n",
    "        btn_delete\n",
    "    ])\n",
    "\n",
    "    result = {\n",
    "        'index': idx,\n",
    "        'dropdown': dropdown,\n",
    "        'manual_input': txt_manual,\n",
    "        'metadata': metadata,\n",
    "        'row': container,\n",
    "        'deleted': False\n",
    "    }\n",
    "\n",
    "    def on_delete(b):\n",
    "        result['deleted'] = True\n",
    "        container.layout.display = 'none'\n",
    "\n",
    "    btn_delete.on_click(on_delete)\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_mismatch_row(idx: int, row: pd.Series, metadata: Dict):\n",
    "    \"\"\"Yellow row for name mismatch\"\"\"\n",
    "    original_email = metadata['original_email']\n",
    "    original_name = metadata['original_name']\n",
    "    ad_user = metadata['ad_user']\n",
    "\n",
    "    chk_accept = widgets.Checkbox(\n",
    "        value=True,\n",
    "        description='Accept AD Name',\n",
    "        indent=False\n",
    "    )\n",
    "\n",
    "    info_html = f\"\"\"\n",
    "    <div style='padding:5px; border:1px solid #ff9800; background:#fff3e0; border-radius:4px;'>\n",
    "        <b style='color:#ff9800;'>‚ö†Ô∏è Name Mismatch</b><br>\n",
    "        Input: {original_name}<br>\n",
    "        AD: {ad_user['name']}<br>\n",
    "        Email: {original_email} ‚úÖ\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    btn_delete = widgets.Button(\n",
    "        description='‚úï',\n",
    "        button_style='danger',\n",
    "        layout=widgets.Layout(width='36px', height='30px'),\n",
    "        tooltip='Remove this record'\n",
    "    )\n",
    "\n",
    "    container = widgets.HBox([\n",
    "        chk_accept,\n",
    "        widgets.HTML(value=info_html),\n",
    "        btn_delete\n",
    "    ])\n",
    "\n",
    "    result = {\n",
    "        'index': idx,\n",
    "        'accept_checkbox': chk_accept,\n",
    "        'metadata': metadata,\n",
    "        'row': container,\n",
    "        'deleted': False\n",
    "    }\n",
    "\n",
    "    def on_delete(b):\n",
    "        result['deleted'] = True\n",
    "        container.layout.display = 'none'\n",
    "\n",
    "    btn_delete.on_click(on_delete)\n",
    "    return result\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Main Validation Function\n",
    "# ============================================\n",
    "\n",
    "def do_validation(b):\n",
    "    \"\"\"Validate uploaded file\"\"\"\n",
    "    global stage2_input_df, stage2_input_filename, stage2_categorized, stage2_ui_rows\n",
    "\n",
    "    s2_output.clear_output()\n",
    "\n",
    "    if not s2_upload.value:\n",
    "        with s2_output:\n",
    "            print(\"‚ùå Please upload a file\")\n",
    "        return\n",
    "\n",
    "    b.disabled = True\n",
    "\n",
    "    try:\n",
    "        with s2_output:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"üîç Stage 2: Email/User Validation\")\n",
    "            print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "        # Load file\n",
    "        f_item = s2_upload.value[0]\n",
    "        stage2_input_filename = f_item['name']\n",
    "\n",
    "        if stage2_input_filename.endswith('.csv'):\n",
    "            stage2_input_df = pd.read_csv(io.BytesIO(f_item['content']))\n",
    "        else:\n",
    "            stage2_input_df = pd.read_excel(io.BytesIO(f_item['content']))\n",
    "\n",
    "        with s2_output:\n",
    "            print(f\"üìÑ Loaded: {stage2_input_filename}\")\n",
    "            print(f\"   Rows: {len(stage2_input_df)}\")\n",
    "            print(f\"   Columns: {list(stage2_input_df.columns)}\\n\")\n",
    "\n",
    "        # Categorize users\n",
    "        print(\"üîç Categorizing users...\")\n",
    "        stage2_categorized = {}\n",
    "\n",
    "        for idx, row in stage2_input_df.iterrows():\n",
    "            status, metadata = categorize_user(row, stage2_ad_cache, stage2_name_index)\n",
    "\n",
    "            if status not in stage2_categorized:\n",
    "                stage2_categorized[status] = []\n",
    "\n",
    "            stage2_categorized[status].append({\n",
    "                'index': idx,\n",
    "                'row': row,\n",
    "                'metadata': metadata,\n",
    "                'status': status\n",
    "            })\n",
    "\n",
    "        # Statistics\n",
    "        stats = {status: len(stage2_categorized.get(status, [])) for status in [\n",
    "            ValidationStatus.VALID_PERFECT,\n",
    "            ValidationStatus.WARN_NAME_MISMATCH,\n",
    "            ValidationStatus.INFO_FUZZY_UNIQUE,\n",
    "            ValidationStatus.ERR_FUZZY_MULTIPLE,\n",
    "            ValidationStatus.ERR_NOT_FOUND,\n",
    "            ValidationStatus.ERR_EMAIL_INVALID,\n",
    "            ValidationStatus.ERR_MISSING_DATA\n",
    "        ]}\n",
    "\n",
    "        with s2_output:\n",
    "            print(f\"\\nüìä Validation Statistics:\")\n",
    "            print(f\"   ‚úÖ Perfect Match (folded):      {stats[ValidationStatus.VALID_PERFECT]}\")\n",
    "            print(f\"   üîµ Single Fuzzy (>=80%):       {stats[ValidationStatus.INFO_FUZZY_UNIQUE]}\")\n",
    "            print(f\"   ‚ö†Ô∏è  Name Mismatch:              {stats[ValidationStatus.WARN_NAME_MISMATCH]}\")\n",
    "            print(f\"   üü† Manual Select (<80%/multi): {stats[ValidationStatus.ERR_FUZZY_MULTIPLE]}\")\n",
    "            print(f\"   ‚ùå Not Found:                  {stats[ValidationStatus.ERR_NOT_FOUND]}\")\n",
    "            print(f\"   ‚ùå Email Invalid:              {stats[ValidationStatus.ERR_EMAIL_INVALID]}\")\n",
    "            print(f\"   ‚ö™ Missing Data:               {stats[ValidationStatus.ERR_MISSING_DATA]}\")\n",
    "            print(f\"   üìå Total:                      {len(stage2_input_df)}\\n\")\n",
    "\n",
    "        # Build UI\n",
    "        ui_sections = []\n",
    "        stage2_ui_rows = {\n",
    "            'fuzzy_unique': [],\n",
    "            'fuzzy_multiple': [],\n",
    "            'mismatch': []\n",
    "        }\n",
    "\n",
    "        # Summary\n",
    "        summary_html = f\"\"\"\n",
    "        <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "                    padding: 20px; border-radius: 8px; color: white; margin-bottom: 20px;'>\n",
    "            <h2 style='margin: 0 0 10px 0;'>üîç Validation Results</h2>\n",
    "            <div style='display: grid; grid-template-columns: repeat(4, 1fr); gap: 15px;'>\n",
    "                <div style='background: rgba(255,255,255,0.2); padding: 10px; border-radius: 5px; text-align: center;'>\n",
    "                    <div style='font-size: 24px; font-weight: bold;'>{stats[ValidationStatus.VALID_PERFECT]}</div>\n",
    "                    <div>‚úÖ Perfect (Auto)</div>\n",
    "                </div>\n",
    "                <div style='background: rgba(52,199,89,0.3); padding: 10px; border-radius: 5px; text-align: center;'>\n",
    "                    <div style='font-size: 24px; font-weight: bold;'>{stats[ValidationStatus.INFO_FUZZY_UNIQUE]}</div>\n",
    "                    <div>üîµ Single</div>\n",
    "                </div>\n",
    "                <div style='background: rgba(255,149,0,0.3); padding: 10px; border-radius: 5px; text-align: center;'>\n",
    "                    <div style='font-size: 24px; font-weight: bold;'>{stats[ValidationStatus.ERR_FUZZY_MULTIPLE]}</div>\n",
    "                    <div>üü† Multiple</div>\n",
    "                </div>\n",
    "                <div style='background: rgba(255,152,0,0.3); padding: 10px; border-radius: 5px; text-align: center;'>\n",
    "                    <div style='font-size: 24px; font-weight: bold;'>{stats[ValidationStatus.WARN_NAME_MISMATCH]}</div>\n",
    "                    <div>‚ö†Ô∏è Mismatch</div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        ui_sections.append(widgets.HTML(value=summary_html))\n",
    "\n",
    "        # Perfect matches (foldable accordion ‚Äî collapsed by default)\n",
    "        if stats[ValidationStatus.VALID_PERFECT] > 0:\n",
    "            perfect_rows_html = []\n",
    "            for item in stage2_categorized.get(ValidationStatus.VALID_PERFECT, []):\n",
    "                m = item['metadata']\n",
    "                ad = m.get('ad_user') or {}\n",
    "                dept = ad.get('dept', 'N/A')\n",
    "                active = 'Yes' if ad.get('active') else 'No'\n",
    "                perfect_rows_html.append(\n",
    "                    f\"<tr>\"\n",
    "                    f\"<td style='padding:6px 10px; border-bottom:1px solid #eee;'>{m['final_name']}</td>\"\n",
    "                    f\"<td style='padding:6px 10px; border-bottom:1px solid #eee;'>{m['final_email']}</td>\"\n",
    "                    f\"<td style='padding:6px 10px; border-bottom:1px solid #eee;'>{dept}</td>\"\n",
    "                    f\"<td style='padding:6px 10px; border-bottom:1px solid #eee;'>{active}</td>\"\n",
    "                    f\"</tr>\"\n",
    "                )\n",
    "            table_html = (\n",
    "                \"<div style='max-height:400px; overflow:auto;'>\"\n",
    "                \"<table style='width:100%; border-collapse:collapse;'>\"\n",
    "                \"<tr style='background:#e8f5e9; position:sticky; top:0;'>\"\n",
    "                \"<th style='padding:8px 10px; text-align:left; border-bottom:2px solid #4caf50;'>Name</th>\"\n",
    "                \"<th style='padding:8px 10px; text-align:left; border-bottom:2px solid #4caf50;'>Email</th>\"\n",
    "                \"<th style='padding:8px 10px; text-align:left; border-bottom:2px solid #4caf50;'>Department</th>\"\n",
    "                \"<th style='padding:8px 10px; text-align:left; border-bottom:2px solid #4caf50;'>AD Active</th>\"\n",
    "                \"</tr>\"\n",
    "                + ''.join(perfect_rows_html) +\n",
    "                \"</table></div>\"\n",
    "            )\n",
    "            accordion_content = widgets.HTML(value=table_html)\n",
    "            accordion = widgets.Accordion(children=[accordion_content])\n",
    "            accordion.set_title(0, f\"‚úÖ Perfect Match ({stats[ValidationStatus.VALID_PERFECT]} records ‚Äî auto-validated, click to expand)\")\n",
    "            accordion.selected_index = None  # Collapsed by default\n",
    "            ui_sections.append(accordion)\n",
    "\n",
    "        # Single fuzzy matches\n",
    "        if stats[ValidationStatus.INFO_FUZZY_UNIQUE] > 0:\n",
    "            ui_sections.append(widgets.HTML(value=\"\"\"\n",
    "                <h3 style='color: #34c759; border-bottom: 2px solid #34c759; padding-bottom: 5px;'>\n",
    "                    üîµ Single Match (Auto-Selected)\n",
    "                </h3>\n",
    "            \"\"\"))\n",
    "\n",
    "            for item in stage2_categorized.get(ValidationStatus.INFO_FUZZY_UNIQUE, []):\n",
    "                row_ui = create_fuzzy_unique_row(item['index'], item['row'], item['metadata'])\n",
    "                stage2_ui_rows['fuzzy_unique'].append(row_ui)\n",
    "                ui_sections.append(row_ui['row'])\n",
    "\n",
    "        # Multiple fuzzy matches\n",
    "        if stats[ValidationStatus.ERR_FUZZY_MULTIPLE] > 0:\n",
    "            ui_sections.append(widgets.HTML(value=\"\"\"\n",
    "                <h3 style='color: #ff9500; border-bottom: 2px solid #ff9500; padding-bottom: 5px; margin-top: 30px;'>\n",
    "                    üü† Multiple Matches - Select One\n",
    "                </h3>\n",
    "            \"\"\"))\n",
    "\n",
    "            for item in stage2_categorized.get(ValidationStatus.ERR_FUZZY_MULTIPLE, []):\n",
    "                row_ui = create_fuzzy_multiple_row(item['index'], item['row'], item['metadata'])\n",
    "                stage2_ui_rows['fuzzy_multiple'].append(row_ui)\n",
    "                ui_sections.append(row_ui['row'])\n",
    "\n",
    "        # Name mismatches\n",
    "        if stats[ValidationStatus.WARN_NAME_MISMATCH] > 0:\n",
    "            ui_sections.append(widgets.HTML(value=\"\"\"\n",
    "                <h3 style='color: #ff9800; border-bottom: 2px solid #ff9800; padding-bottom: 5px; margin-top: 30px;'>\n",
    "                    ‚ö†Ô∏è Name Mismatch - Review\n",
    "                </h3>\n",
    "            \"\"\"))\n",
    "\n",
    "            for item in stage2_categorized.get(ValidationStatus.WARN_NAME_MISMATCH, []):\n",
    "                row_ui = create_mismatch_row(item['index'], item['row'], item['metadata'])\n",
    "                stage2_ui_rows['mismatch'].append(row_ui)\n",
    "                ui_sections.append(row_ui['row'])\n",
    "\n",
    "        # Save button\n",
    "        ui_sections.append(widgets.HTML(value=\"<hr style='margin: 30px 0;'>\"))\n",
    "        ui_sections.append(widgets.HBox([s2_btn_save]))\n",
    "\n",
    "        # Display UI\n",
    "        with s2_output:\n",
    "            display(widgets.VBox(ui_sections))\n",
    "\n",
    "        s2_btn_save.disabled = False\n",
    "        s2_status.value = f\"<span style='color:green;'>‚úÖ Validation complete</span>\"\n",
    "\n",
    "    except Exception as e:\n",
    "        with s2_output:\n",
    "            print(f\"\\n‚ùå Error: {str(e)}\")\n",
    "        s2_status.value = f\"<span style='color:red;'>‚ùå Error: {str(e)}</span>\"\n",
    "    finally:\n",
    "        b.disabled = False\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Save Function\n",
    "# ============================================\n",
    "\n",
    "def do_save(b):\n",
    "    \"\"\"Save validated file\"\"\"\n",
    "    if stage2_input_df is None:\n",
    "        print(\"‚ùå No data to save\")\n",
    "        return\n",
    "\n",
    "    b.disabled = True\n",
    "\n",
    "    try:\n",
    "        print(\"\\nüíæ Saving validated file...\")\n",
    "\n",
    "        validated_rows = []\n",
    "        skipped_count = 0\n",
    "        deleted_count = 0\n",
    "\n",
    "        def _ad_fields(email_key):\n",
    "            \"\"\"Look up Department and is_AD_active from AD cache\"\"\"\n",
    "            if email_key and email_key in stage2_ad_cache:\n",
    "                ad = stage2_ad_cache[email_key]\n",
    "                return ad.get('dept', ''), 'Yes' if ad.get('active') else 'No'\n",
    "            return '', ''\n",
    "\n",
    "        # 1. Perfect matches (folded)\n",
    "        for item in stage2_categorized.get(ValidationStatus.VALID_PERFECT, []):\n",
    "            row_data = item['row'].to_dict()\n",
    "            metadata = item['metadata']\n",
    "            row_data['Email'] = metadata['final_email']\n",
    "            row_data['User Name'] = metadata['final_name']\n",
    "            row_data['Department'], row_data['is_AD_active'] = _ad_fields(metadata['final_email'])\n",
    "            row_data['Validation Status'] = ValidationStatus.get_display_text(ValidationStatus.VALID_PERFECT)\n",
    "            validated_rows.append(row_data)\n",
    "\n",
    "        # 2. Single fuzzy matches (>= 80%)\n",
    "        for row_ui in stage2_ui_rows['fuzzy_unique']:\n",
    "            if row_ui.get('deleted'):\n",
    "                deleted_count += 1\n",
    "                continue\n",
    "            item = stage2_categorized[ValidationStatus.INFO_FUZZY_UNIQUE][stage2_ui_rows['fuzzy_unique'].index(row_ui)]\n",
    "            row_data = item['row'].to_dict()\n",
    "            row_data['Email'] = row_ui['selected_email']\n",
    "            row_data['User Name'] = row_ui['selected_name']\n",
    "            row_data['Department'], row_data['is_AD_active'] = _ad_fields(row_ui['selected_email'])\n",
    "            row_data['Validation Status'] = ValidationStatus.get_display_text(ValidationStatus.INFO_FUZZY_UNIQUE)\n",
    "            validated_rows.append(row_data)\n",
    "\n",
    "        # 3. Multiple fuzzy matches / low-confidence singles\n",
    "        for row_ui in stage2_ui_rows['fuzzy_multiple']:\n",
    "            if row_ui.get('deleted'):\n",
    "                deleted_count += 1\n",
    "                continue\n",
    "            item = stage2_categorized[ValidationStatus.ERR_FUZZY_MULTIPLE][stage2_ui_rows['fuzzy_multiple'].index(row_ui)]\n",
    "            row_data = item['row'].to_dict()\n",
    "\n",
    "            selected = row_ui['dropdown'].value\n",
    "            is_manual = (selected == 'MANUAL')\n",
    "\n",
    "            if is_manual:\n",
    "                selected = row_ui['manual_input'].value.strip().lower()\n",
    "\n",
    "            if selected:\n",
    "                found = False\n",
    "                for match in row_ui['metadata']['fuzzy_matches']:\n",
    "                    if match['email'] == selected:\n",
    "                        row_data['Email'] = match['email']\n",
    "                        row_data['User Name'] = match['name']\n",
    "                        found = True\n",
    "                        break\n",
    "\n",
    "                if is_manual and not found:\n",
    "                    row_data['Email'] = selected\n",
    "                    if selected in stage2_ad_cache:\n",
    "                        row_data['User Name'] = stage2_ad_cache[selected]['name']\n",
    "\n",
    "                row_data['Department'], row_data['is_AD_active'] = _ad_fields(selected)\n",
    "                row_data['Validation Status'] = \"üîß Manually Resolved\" if is_manual else ValidationStatus.get_display_text(ValidationStatus.ERR_FUZZY_MULTIPLE)\n",
    "                validated_rows.append(row_data)\n",
    "            else:\n",
    "                # User didn't select anything ‚Äî still include with warning\n",
    "                row_data['Department'] = ''\n",
    "                row_data['is_AD_active'] = ''\n",
    "                row_data['Validation Status'] = \"‚ö†Ô∏è Unresolved (No Selection Made)\"\n",
    "                validated_rows.append(row_data)\n",
    "                skipped_count += 1\n",
    "\n",
    "        # 4. Name mismatches\n",
    "        for row_ui in stage2_ui_rows['mismatch']:\n",
    "            if row_ui.get('deleted'):\n",
    "                deleted_count += 1\n",
    "                continue\n",
    "            item = stage2_categorized[ValidationStatus.WARN_NAME_MISMATCH][stage2_ui_rows['mismatch'].index(row_ui)]\n",
    "            row_data = item['row'].to_dict()\n",
    "            metadata = row_ui['metadata']\n",
    "\n",
    "            if row_ui['accept_checkbox'].value:\n",
    "                row_data['Email'] = metadata['final_email']\n",
    "                row_data['User Name'] = metadata['final_name']\n",
    "                row_data['Validation Status'] = \"‚úÖ Name Mismatch Resolved (AD Name)\"\n",
    "            else:\n",
    "                row_data['Email'] = metadata['final_email']\n",
    "                row_data['User Name'] = metadata['original_name']\n",
    "                row_data['Validation Status'] = \"‚ö†Ô∏è Name Mismatch (Kept Original)\"\n",
    "\n",
    "            row_data['Department'], row_data['is_AD_active'] = _ad_fields(metadata['final_email'])\n",
    "            validated_rows.append(row_data)\n",
    "\n",
    "        # 5. Errors (included with empty AD fields)\n",
    "        for status in [ValidationStatus.ERR_NOT_FOUND, ValidationStatus.ERR_EMAIL_INVALID, ValidationStatus.ERR_MISSING_DATA]:\n",
    "            for item in stage2_categorized.get(status, []):\n",
    "                row_data = item['row'].to_dict()\n",
    "                row_data['Department'] = ''\n",
    "                row_data['is_AD_active'] = ''\n",
    "                row_data['Validation Status'] = ValidationStatus.get_display_text(status)\n",
    "                validated_rows.append(row_data)\n",
    "\n",
    "        # Warn about unresolved/deleted rows\n",
    "        if skipped_count > 0:\n",
    "            print(f\"‚ö†Ô∏è  {skipped_count} rows had no selection ‚Äî marked as 'Unresolved'\")\n",
    "        if deleted_count > 0:\n",
    "            print(f\"üóëÔ∏è  {deleted_count} rows deleted by user ‚Äî excluded from output\")\n",
    "\n",
    "        # Create output\n",
    "        output_df = pd.DataFrame(validated_rows)\n",
    "        priority_cols = ['Validation Status', 'Email', 'User Name', 'Department', 'is_AD_active']\n",
    "        other_cols = [c for c in output_df.columns if c not in priority_cols]\n",
    "        cols = priority_cols + other_cols\n",
    "        cols = [c for c in cols if c in output_df.columns]\n",
    "        output_df = output_df[cols]\n",
    "\n",
    "        # Save\n",
    "        base_name = stage2_input_filename.replace('.csv', '').replace('.xlsx', '')\n",
    "        date_str = datetime.now().strftime('%Y%m%d')\n",
    "        output_filename = f\"{base_name}_validated_{date_str}.xlsx\"\n",
    "        output_path = os.path.join(STAGE2_DIR, output_filename)\n",
    "\n",
    "        output_df.to_excel(output_path, index=False, sheet_name='Validated')\n",
    "\n",
    "        print(f\"\\n‚úÖ Saved: {output_path}\")\n",
    "        print(f\"   Rows: {len(output_df)}\")\n",
    "        print(f\"   Columns: {list(output_df.columns)}\")\n",
    "\n",
    "        s2_status.value = f\"<span style='color:blue;'>‚úÖ Saved: {output_filename}</span>\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Save error: {str(e)}\")\n",
    "        s2_status.value = f\"<span style='color:red;'>‚ùå Error: {str(e)}</span>\"\n",
    "    finally:\n",
    "        b.disabled = False\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# UI Setup\n",
    "# ============================================\n",
    "\n",
    "s2_upload = widgets.FileUpload(\n",
    "    accept='.xlsx, .csv',\n",
    "    description=\"Upload File\",\n",
    "    button_style='info'\n",
    ")\n",
    "s2_upload_status = widgets.HTML(value=\"<i>No file selected</i>\")\n",
    "s2_btn_validate = widgets.Button(\n",
    "    description=\"üîç Validate\",\n",
    "    button_style='warning',\n",
    "    layout=widgets.Layout(width='140px', height='40px'),\n",
    "    disabled=True\n",
    ")\n",
    "s2_btn_save = widgets.Button(\n",
    "    description=\"üíæ Save\",\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='140px', height='40px'),\n",
    "    disabled=True\n",
    ")\n",
    "s2_status = widgets.HTML(value=\"<i>Loading AD cache...</i>\")\n",
    "s2_output = widgets.Output()\n",
    "\n",
    "# Event handlers\n",
    "def on_upload_change(change):\n",
    "    if s2_upload.value:\n",
    "        fname = s2_upload.value[0]['name']\n",
    "        s2_upload_status.value = f\"<b style='color:green;'>‚úÖ {fname}</b>\"\n",
    "        s2_btn_validate.disabled = False\n",
    "\n",
    "s2_upload.observe(on_upload_change, 'value')\n",
    "s2_btn_validate.on_click(do_validation)\n",
    "s2_btn_save.on_click(do_save)\n",
    "\n",
    "# Initialize\n",
    "success, msg = load_ad_cache()\n",
    "if success:\n",
    "    s2_status.value = f\"<span style='color:green;'>‚úÖ {msg}</span>\"\n",
    "else:\n",
    "    s2_status.value = f\"<span style='color:red;'>‚ö†Ô∏è {msg}</span>\"\n",
    "\n",
    "# Main UI\n",
    "stage2_ui = widgets.VBox([\n",
    "    widgets.HTML(\"\"\"\n",
    "        <div style='background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);\n",
    "                    padding: 20px; border-radius: 8px; color: white; margin-bottom: 20px;'>\n",
    "            <h2 style='margin: 0 0 10px 0;'>üîç Stage 2: Email/User Validation</h2>\n",
    "            <p style='margin: 0;'>Upload user list, validate against AD, resolve mismatches</p>\n",
    "        </div>\n",
    "    \"\"\"),\n",
    "    widgets.HBox([s2_upload, s2_upload_status]),\n",
    "    widgets.HBox([s2_btn_validate, s2_btn_save]),\n",
    "    s2_status,\n",
    "    s2_output\n",
    "])\n",
    "\n",
    "clear_output()\n",
    "display(stage2_ui)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Stage 2 UI Ready\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Stage 3: Reviewer Assignment with Complete Columns (v3.0 FINAL)\n",
    "\n",
    "Complete output columns:\n",
    "1. All input columns (preserved)\n",
    "2. Reviewer (email from mapping)\n",
    "3. Manual Review (Yes if email match, empty if dept match)\n",
    "4. Reviewer's Response (dropdown: Approved/Denied/Changes Required)\n",
    "5. Details of Access Change (free text for reviewer to fill)\n",
    "\n",
    "Matching logic:\n",
    "- Email exact match ‚Üí Fill reviewer + Mark \"Manual Review\" = \"Yes\"\n",
    "- Department contains match ‚Üí Fill reviewer, no manual review mark\n",
    "- Keep all input columns clean (no text pollution)\n",
    "\n",
    "Usage in Jupyter:\n",
    "    1. Run this cell\n",
    "    2. Upload validated file from Stage 2\n",
    "    3. Upload or use default mapping file\n",
    "    4. Click \"Assign Reviewers\"\n",
    "    5. Review assignments\n",
    "    6. Click \"Save Final Review\"\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, logging, glob, io\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.worksheet.datavalidation import DataValidation\n",
    "from openpyxl.utils import get_column_letter\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# ============================================\n",
    "# Setup Paths\n",
    "# ============================================\n",
    "\n",
    "today_str = datetime.now().strftime('%Y-%m-%d')\n",
    "BASE_DIR = os.path.join(\"output\", today_str)\n",
    "STAGE2_DIR = os.path.join(BASE_DIR, \"stage2_validated\")\n",
    "STAGE3_DIR = os.path.join(BASE_DIR, \"stage3_review\")\n",
    "MAPPING_DIR = os.path.join(\"input\", \"mapping\")\n",
    "LOG_DIR = os.path.join(BASE_DIR, \"logs\")\n",
    "os.makedirs(STAGE3_DIR, exist_ok=True)\n",
    "\n",
    "# ============================================\n",
    "# Logging\n",
    "# ============================================\n",
    "\n",
    "log_file = os.path.join(LOG_DIR, f\"aer_stage3_{datetime.now().strftime('%Y%m%d_%H%M')}.log\")\n",
    "logger_s3 = logging.getLogger(\"aer_stage3\")\n",
    "logger_s3.handlers.clear()\n",
    "logger_s3.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "fh = logging.FileHandler(log_file, encoding=\"utf-8\")\n",
    "fh.setFormatter(formatter)\n",
    "logger_s3.addHandler(fh)\n",
    "logger_s3.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# ============================================\n",
    "# Global State\n",
    "# ============================================\n",
    "\n",
    "stage3_input_df = None\n",
    "stage3_mapping_df = None\n",
    "stage3_final_df = None\n",
    "stage3_input_filename = \"\"\n",
    "\n",
    "# ============================================\n",
    "# UI Components\n",
    "# ============================================\n",
    "\n",
    "s3_upload = widgets.FileUpload(\n",
    "    accept='.xlsx, .csv',\n",
    "    description=\"Upload Validated File\",\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='250px')\n",
    ")\n",
    "s3_upload_status = widgets.HTML(value=\"<i>No file selected</i>\")\n",
    "\n",
    "s3_upload_map = widgets.FileUpload(\n",
    "    accept='.csv',\n",
    "    description=\"Mapping File\",\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='250px')\n",
    ")\n",
    "s3_map_status = widgets.HTML(value=\"<i>Will use default mapping if available</i>\")\n",
    "\n",
    "s3_btn_assign = widgets.Button(\n",
    "    description=\"‚öôÔ∏è Assign Reviewers\",\n",
    "    button_style='warning',\n",
    "    layout=widgets.Layout(width='180px', height='40px'),\n",
    "    disabled=True\n",
    ")\n",
    "s3_btn_save = widgets.Button(\n",
    "    description=\"üíæ Save Final Review\",\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='180px', height='40px'),\n",
    "    disabled=True\n",
    ")\n",
    "s3_status = widgets.HTML(value=\"<i>Please upload validated file from Stage 2</i>\")\n",
    "s3_output = widgets.Output()\n",
    "\n",
    "# ============================================\n",
    "# Helper Functions\n",
    "# ============================================\n",
    "\n",
    "def get_latest_mapping():\n",
    "    \"\"\"Get latest mapping file from default location\"\"\"\n",
    "    try:\n",
    "        files = glob.glob(os.path.join(MAPPING_DIR, \"*.csv\"))\n",
    "        if not files:\n",
    "            files = glob.glob(os.path.join(MAPPING_DIR, \"**\", \"*.csv\"), recursive=True)\n",
    "        return max(files, key=os.path.getmtime) if files else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def detect_column(df, candidates):\n",
    "    \"\"\"Detect column by name matching\"\"\"\n",
    "    cols_lower = {str(c).lower().strip(): c for c in df.columns}\n",
    "\n",
    "    for cand in candidates:\n",
    "        for col_key, col_actual in cols_lower.items():\n",
    "            if cand in col_key:\n",
    "                return col_actual\n",
    "    return None\n",
    "\n",
    "\n",
    "def assign_reviewers(input_df, mapping_df):\n",
    "    \"\"\"\n",
    "    Assign reviewers based on email/department mapping\n",
    "\n",
    "    Args:\n",
    "        input_df: Input DataFrame (must have 'Email', 'Department' columns)\n",
    "        mapping_df: Mapping DataFrame with columns:\n",
    "            - email: User email for exact matching (optional)\n",
    "            - department: Department name/substring\n",
    "            - reviewer: Reviewer email to assign\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with:\n",
    "        - All input columns (preserved)\n",
    "        - Reviewer (email)\n",
    "        - Manual Review (Yes if email match, empty otherwise)\n",
    "        - Reviewer's Response (empty, for dropdown)\n",
    "        - Details of Access Change (empty, for free text)\n",
    "    \"\"\"\n",
    "\n",
    "    # Detect mapping columns\n",
    "    map_cols = {\n",
    "        'email': detect_column(mapping_df, ['email', 'mail']),\n",
    "        'department': detect_column(mapping_df, ['department', 'dept']),\n",
    "        'reviewer': detect_column(mapping_df, ['reviewer', 'owner', 'manager'])\n",
    "    }\n",
    "\n",
    "    if not map_cols['department'] or not map_cols['reviewer']:\n",
    "        raise ValueError(\n",
    "            f\"Mapping file must have 'department' and 'reviewer' columns. \"\n",
    "            f\"Found: {list(mapping_df.columns)}\"\n",
    "        )\n",
    "\n",
    "    # Build mapping dictionaries\n",
    "    email_map = {}\n",
    "    dept_map = {}\n",
    "\n",
    "    # Email mapping (if email column exists)\n",
    "    if map_cols['email']:\n",
    "        for _, row in mapping_df.iterrows():\n",
    "            email_key = str(row[map_cols['email']]).lower().strip()\n",
    "            if email_key and email_key not in ['nan', 'none', '*']:\n",
    "                email_map[email_key] = str(row[map_cols['reviewer']]).strip()\n",
    "\n",
    "    # Department mapping\n",
    "    for _, row in mapping_df.iterrows():\n",
    "        dept_key = str(row[map_cols['department']]).lower().strip()\n",
    "        if dept_key and dept_key != 'nan':\n",
    "            dept_map[dept_key] = str(row[map_cols['reviewer']]).strip()\n",
    "\n",
    "    print(f\"üìä Loaded mapping:\")\n",
    "    print(f\"   Email mappings: {len(email_map)}\")\n",
    "    print(f\"   Dept mappings: {len(dept_map)}\\n\")\n",
    "\n",
    "    # Create output DataFrame (copy all input columns)\n",
    "    output_df = input_df.copy()\n",
    "    output_df['Reviewer'] = ''\n",
    "    output_df['Manual Review'] = ''\n",
    "    output_df['Reviewer\\'s Response'] = ''\n",
    "    output_df['Details of Access Change'] = ''\n",
    "\n",
    "    # Statistics\n",
    "    stats = {'email_match': 0, 'dept_match': 0, 'no_match': 0}\n",
    "\n",
    "    # Process each user\n",
    "    for idx, row in output_df.iterrows():\n",
    "        user_email = str(row.get('Email', '')).lower().strip()\n",
    "        user_dept = str(row.get('Department', '')).strip()\n",
    "\n",
    "        reviewer_assigned = None\n",
    "        is_manual_review = False\n",
    "\n",
    "        # Priority 1: Email exact match ‚Üí Manual Review = Yes\n",
    "        if user_email and user_email != 'nan' and user_email in email_map:\n",
    "            reviewer_assigned = email_map[user_email]\n",
    "            is_manual_review = True\n",
    "            stats['email_match'] += 1\n",
    "\n",
    "        # Priority 2: Department contains match ‚Üí Auto assign\n",
    "        elif user_dept and user_dept not in ['N/A', 'nan', '']:\n",
    "            user_dept_lower = user_dept.lower()\n",
    "\n",
    "            # Try exact match first\n",
    "            if user_dept_lower in dept_map:\n",
    "                reviewer_assigned = dept_map[user_dept_lower]\n",
    "                stats['dept_match'] += 1\n",
    "            else:\n",
    "                # Try contains logic\n",
    "                # Example: input=\"corporate 123 - finance\", mapping=\"finance\" ‚Üí MATCH\n",
    "                for map_dept_key, map_reviewer in dept_map.items():\n",
    "                    if map_dept_key in user_dept_lower:\n",
    "                        reviewer_assigned = map_reviewer\n",
    "                        stats['dept_match'] += 1\n",
    "                        break\n",
    "\n",
    "        # Assign results\n",
    "        if reviewer_assigned:\n",
    "            output_df.at[idx, 'Reviewer'] = reviewer_assigned\n",
    "            output_df.at[idx, 'Manual Review'] = 'Yes' if is_manual_review else ''\n",
    "        else:\n",
    "            stats['no_match'] += 1\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"üìà Assignment Results:\")\n",
    "    print(f\"   Email Match (Manual Review): {stats['email_match']}\")\n",
    "    print(f\"   Dept Match (Auto):           {stats['dept_match']}\")\n",
    "    print(f\"   No Match:                    {stats['no_match']}\")\n",
    "    print(f\"   Total:                       {len(output_df)}\\n\")\n",
    "\n",
    "    return output_df\n",
    "\n",
    "\n",
    "def save_with_validation(df, output_path):\n",
    "    \"\"\"\n",
    "    Save DataFrame to Excel with data validation for dropdown columns\n",
    "\n",
    "    Dropdowns:\n",
    "    - Manual Review: Yes/No\n",
    "    - Reviewer's Response: Approved/Denied/Changes Required\n",
    "    \"\"\"\n",
    "\n",
    "    # Save to Excel\n",
    "    df.to_excel(output_path, index=False, sheet_name='Review')\n",
    "\n",
    "    # Add data validation\n",
    "    wb = load_workbook(output_path)\n",
    "    ws = wb.active\n",
    "\n",
    "    # Find columns\n",
    "    col_indices = {}\n",
    "    for i, col_name in enumerate(df.columns, 1):\n",
    "        col_str = str(col_name)\n",
    "        if col_str == 'Manual Review':\n",
    "            col_indices['manual_review'] = i\n",
    "        elif col_str == 'Reviewer\\'s Response':\n",
    "            col_indices['reviewer_response'] = i\n",
    "\n",
    "    # Manual Review dropdown (Yes/No)\n",
    "    if 'manual_review' in col_indices:\n",
    "        dv = DataValidation(\n",
    "            type=\"list\",\n",
    "            formula1='\"Yes,No\"',\n",
    "            allow_blank=True\n",
    "        )\n",
    "        dv.promptTitle = \"Manual Review Status\"\n",
    "        dv.prompt = \"Select Yes if this assignment requires manual review\"\n",
    "        dv.showInputMessage = True\n",
    "\n",
    "        ws.add_data_validation(dv)\n",
    "        letter = get_column_letter(col_indices['manual_review'])\n",
    "        dv.add(f\"{letter}2:{letter}{len(df)+1}\")\n",
    "\n",
    "    # Reviewer's Response dropdown (Approved/Denied/Changes Required)\n",
    "    if 'reviewer_response' in col_indices:\n",
    "        dv = DataValidation(\n",
    "            type=\"list\",\n",
    "            formula1='\"Approved,Denied,Changes Required\"',\n",
    "            allow_blank=True\n",
    "        )\n",
    "        dv.promptTitle = \"Reviewer's Response\"\n",
    "        dv.prompt = \"Select the review decision\"\n",
    "        dv.showInputMessage = True\n",
    "        dv.errorTitle = \"Invalid Selection\"\n",
    "        dv.error = \"Please select a valid option from the dropdown\"\n",
    "        dv.showErrorMessage = True\n",
    "\n",
    "        ws.add_data_validation(dv)\n",
    "        letter = get_column_letter(col_indices['reviewer_response'])\n",
    "        dv.add(f\"{letter}2:{letter}{len(df)+1}\")\n",
    "\n",
    "    wb.save(output_path)\n",
    "    print(f\"‚úÖ Added dropdown validation for:\")\n",
    "    if 'manual_review' in col_indices:\n",
    "        print(f\"   - Manual Review (Yes/No)\")\n",
    "    if 'reviewer_response' in col_indices:\n",
    "        print(f\"   - Reviewer's Response (Approved/Denied/Changes Required)\")\n",
    "    print()\n",
    "\n",
    "# ============================================\n",
    "# Event Handlers\n",
    "# ============================================\n",
    "\n",
    "def on_s3_upload_change(change):\n",
    "    \"\"\"Handle input file upload\"\"\"\n",
    "    if s3_upload.value and len(s3_upload.value) > 0:\n",
    "        fname = s3_upload.value[0]['name']\n",
    "        s3_upload_status.value = f\"<b style='color:green;'>‚úÖ Selected: {fname}</b>\"\n",
    "        s3_btn_assign.disabled = False\n",
    "\n",
    "\n",
    "def on_s3_map_change(change):\n",
    "    \"\"\"Handle mapping file upload\"\"\"\n",
    "    if s3_upload_map.value and len(s3_upload_map.value) > 0:\n",
    "        fname = s3_upload_map.value[0]['name']\n",
    "        s3_map_status.value = f\"<b style='color:green;'>‚úÖ Using: {fname}</b>\"\n",
    "\n",
    "\n",
    "def do_stage3_assign(b):\n",
    "    \"\"\"Assign reviewers based on mapping\"\"\"\n",
    "    global stage3_input_df, stage3_mapping_df, stage3_final_df, stage3_input_filename\n",
    "\n",
    "    s3_output.clear_output()\n",
    "\n",
    "    if not s3_upload.value:\n",
    "        with s3_output:\n",
    "            print(\"‚ùå Please upload a validated file from Stage 2\")\n",
    "        return\n",
    "\n",
    "    b.disabled = True\n",
    "\n",
    "    try:\n",
    "        with s3_output:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"‚öôÔ∏è Stage 3: Reviewer Assignment (Complete)\")\n",
    "            print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "        # Load input file\n",
    "        f_item = s3_upload.value[0]\n",
    "        stage3_input_filename = f_item['name']\n",
    "\n",
    "        if stage3_input_filename.endswith('.csv'):\n",
    "            stage3_input_df = pd.read_csv(io.BytesIO(f_item['content']))\n",
    "        else:\n",
    "            stage3_input_df = pd.read_excel(io.BytesIO(f_item['content']))\n",
    "\n",
    "        logger_s3.info(f\"Loaded input: {stage3_input_filename}, {len(stage3_input_df)} rows\")\n",
    "\n",
    "        with s3_output:\n",
    "            print(f\"üìÑ Input file: {stage3_input_filename}\")\n",
    "            print(f\"   Rows: {len(stage3_input_df)}\")\n",
    "            print(f\"   Columns: {list(stage3_input_df.columns)}\\n\")\n",
    "\n",
    "        # Validate required columns\n",
    "        if 'Email' not in stage3_input_df.columns:\n",
    "            with s3_output:\n",
    "                print(f\"‚ùå Input file missing 'Email' column\")\n",
    "                print(f\"   Available: {list(stage3_input_df.columns)}\")\n",
    "            b.disabled = False\n",
    "            return\n",
    "\n",
    "        if 'Department' not in stage3_input_df.columns:\n",
    "            with s3_output:\n",
    "                print(\"‚ö†Ô∏è  Warning: 'Department' column not found. Adding placeholder.\")\n",
    "            stage3_input_df['Department'] = 'N/A'\n",
    "\n",
    "        # Load mapping file\n",
    "        map_src = None\n",
    "        map_name = \"\"\n",
    "\n",
    "        if s3_upload_map.value and len(s3_upload_map.value) > 0:\n",
    "            map_src = io.BytesIO(s3_upload_map.value[0]['content'])\n",
    "            map_name = s3_upload_map.value[0]['name']\n",
    "        else:\n",
    "            default_map = get_latest_mapping()\n",
    "            if default_map:\n",
    "                map_src = default_map\n",
    "                map_name = os.path.basename(default_map)\n",
    "\n",
    "        if not map_src:\n",
    "            with s3_output:\n",
    "                print(\"‚ùå No mapping file found\")\n",
    "                print(f\"   Upload a mapping file or place one in: {MAPPING_DIR}\")\n",
    "            s3_status.value = \"<span style='color:red;'>‚ùå Mapping file required</span>\"\n",
    "            b.disabled = False\n",
    "            return\n",
    "\n",
    "        stage3_mapping_df = pd.read_csv(map_src)\n",
    "\n",
    "        with s3_output:\n",
    "            print(f\"üìã Mapping file: {map_name}\")\n",
    "            print(f\"   Rows: {len(stage3_mapping_df)}\")\n",
    "            print(f\"   Columns: {list(stage3_mapping_df.columns)}\\n\")\n",
    "\n",
    "        logger_s3.info(f\"Loaded mapping: {map_name}, {len(stage3_mapping_df)} rows\")\n",
    "\n",
    "        # Assign reviewers\n",
    "        with s3_output:\n",
    "            print(\"=\"*60)\n",
    "            print(\"üîç Assigning Reviewers\")\n",
    "            print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "        stage3_final_df = assign_reviewers(stage3_input_df, stage3_mapping_df)\n",
    "\n",
    "        # Preview results\n",
    "        with s3_output:\n",
    "            print(\"=\"*60)\n",
    "            print(\"üìä Preview (first 5 rows)\")\n",
    "            print(\"=\"*60)\n",
    "            preview_cols = ['Email', 'Department', 'Reviewer', 'Manual Review']\n",
    "            available_cols = [c for c in preview_cols if c in stage3_final_df.columns]\n",
    "            print(stage3_final_df[available_cols].head())\n",
    "            print()\n",
    "\n",
    "        s3_btn_save.disabled = False\n",
    "        s3_status.value = f\"<span style='color:green;'>‚úÖ Assignment complete: {len(stage3_final_df)} users ready</span>\"\n",
    "        logger_s3.info(f\"Assignment complete: {len(stage3_final_df)} rows\")\n",
    "\n",
    "    except Exception as e:\n",
    "        with s3_output:\n",
    "            print(f\"\\n‚ùå Error: {str(e)}\")\n",
    "        logger_s3.error(f\"Assignment error: {str(e)}\", exc_info=True)\n",
    "        s3_status.value = f\"<span style='color:red;'>‚ùå Error: {str(e)}</span>\"\n",
    "    finally:\n",
    "        b.disabled = False\n",
    "\n",
    "\n",
    "def do_stage3_save(b):\n",
    "    \"\"\"Save final review file with dropdowns\"\"\"\n",
    "    if stage3_final_df is None:\n",
    "        with s3_output:\n",
    "            print(\"‚ùå No data to save. Please assign reviewers first.\")\n",
    "        return\n",
    "\n",
    "    b.disabled = True\n",
    "\n",
    "    try:\n",
    "        with s3_output:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"üíæ Saving Final Review File\")\n",
    "            print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "        # Generate filename\n",
    "        base_name = stage3_input_filename.replace('.csv', '').replace('.xlsx', '').replace('_AD_verified', '')\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "        output_filename = f\"{base_name}_review_{timestamp}.xlsx\"\n",
    "        output_path = os.path.join(STAGE3_DIR, output_filename)\n",
    "\n",
    "        # Save with validation\n",
    "        save_with_validation(stage3_final_df, output_path)\n",
    "\n",
    "        with s3_output:\n",
    "            print(f\"‚úÖ Saved to: {output_path}\")\n",
    "            print(f\"   Rows: {len(stage3_final_df)}\")\n",
    "            print(f\"   Columns: {list(stage3_final_df.columns)}\")\n",
    "            print(\"=\"*60)\n",
    "\n",
    "        s3_status.value = f\"<span style='color:blue;'>‚úÖ Saved: {output_filename}</span>\"\n",
    "        logger_s3.info(f\"Saved review file: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        with s3_output:\n",
    "            print(f\"\\n‚ùå Save error: {str(e)}\")\n",
    "        logger_s3.error(f\"Save error: {str(e)}\", exc_info=True)\n",
    "        s3_status.value = f\"<span style='color:red;'>‚ùå Save error: {str(e)}</span>\"\n",
    "    finally:\n",
    "        b.disabled = False\n",
    "\n",
    "# ============================================\n",
    "# Bind Events\n",
    "# ============================================\n",
    "\n",
    "s3_upload.observe(on_s3_upload_change, 'value')\n",
    "s3_upload_map.observe(on_s3_map_change, 'value')\n",
    "s3_btn_assign.on_click(do_stage3_assign)\n",
    "s3_btn_save.on_click(do_stage3_save)\n",
    "\n",
    "# ============================================\n",
    "# Initialize: Check for default mapping\n",
    "# ============================================\n",
    "\n",
    "default_map = get_latest_mapping()\n",
    "if default_map:\n",
    "    s3_map_status.value = f\"<b style='color:green;'>‚úÖ Default: {os.path.basename(default_map)}</b>\"\n",
    "    logger_s3.info(f\"Default mapping found: {os.path.basename(default_map)}\")\n",
    "else:\n",
    "    s3_map_status.value = f\"<i>No default mapping found in {MAPPING_DIR}</i>\"\n",
    "    logger_s3.warning(f\"No default mapping found\")\n",
    "\n",
    "# ============================================\n",
    "# UI Layout\n",
    "# ============================================\n",
    "\n",
    "stage3_ui = widgets.VBox([\n",
    "    widgets.HTML(\"\"\"\n",
    "        <div style='\n",
    "            background: linear-gradient(135deg, #fa709a 0%, #fee140 100%);\n",
    "            padding: 20px;\n",
    "            border-radius: 8px;\n",
    "            color: white;\n",
    "            margin-bottom: 20px;\n",
    "            box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
    "        '>\n",
    "            <h2 style='margin: 0 0 10px 0;'>‚öôÔ∏è Stage 3: Reviewer Assignment (Complete)</h2>\n",
    "            <p style='margin: 0; opacity: 0.9;'>\n",
    "                Assign reviewers + prepare complete review sheet with all required columns\n",
    "            </p>\n",
    "            <div style='margin-top: 10px; padding: 10px; background: rgba(255,255,255,0.2); border-radius: 5px;'>\n",
    "                <b>Output columns:</b> Reviewer | Manual Review | Reviewer's Response | Details of Access Change\n",
    "            </div>\n",
    "        </div>\n",
    "    \"\"\"),\n",
    "    widgets.HBox([s3_upload, s3_upload_status]),\n",
    "    widgets.HBox([s3_upload_map, s3_map_status]),\n",
    "    widgets.HBox([s3_btn_assign, s3_btn_save], layout=widgets.Layout(margin='10px 0')),\n",
    "    s3_status,\n",
    "    s3_output\n",
    "])\n",
    "\n",
    "clear_output()\n",
    "display(stage3_ui)\n",
    "\n",
    "logger_s3.info(\"Stage 3 UI initialized (Complete version)\")\n",
    "logger_s3.info(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 1: Setup & Authentication ===\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from msal import PublicClientApplication\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# === Logging ===\n",
    "today_str = datetime.now().strftime('%Y-%m-%d')\n",
    "hour_str = datetime.now().strftime('%H')\n",
    "log_dir = f\"output/{today_str}/report/logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "log_file = f\"{log_dir}/aer_{today_str}_{hour_str}00.log\"\n",
    "\n",
    "logger = logging.getLogger(\"aer\")\n",
    "logger.handlers.clear()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "def _get_console_stream():\n",
    "    s = getattr(sys, \"stdout\", None)\n",
    "    try:\n",
    "        if s and hasattr(s, \"reconfigure\"):\n",
    "            s.reconfigure(encoding=\"utf-8\")\n",
    "            if hasattr(sys.stderr, \"reconfigure\"):\n",
    "                sys.stderr.reconfigure(encoding=\"utf-8\")\n",
    "            return s\n",
    "    except Exception: pass\n",
    "    return sys.stdout\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "ch = logging.StreamHandler(_get_console_stream())\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "fh = logging.FileHandler(log_file, encoding=\"utf-8\", mode='a')\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "# === Azure AD Config ===\n",
    "TENANT_ID = os.getenv(\"AZURE_TENANT_ID\")\n",
    "CLIENT_ID = os.getenv(\"AZURE_CLIENT_ID\")\n",
    "SHAREPOINT_HOST = os.getenv(\"SHAREPOINT_HOST\", \"davidshih.sharepoint.com\")\n",
    "SITE_NAME = os.getenv(\"SITE_NAME\", \"aer\")\n",
    "APP_NAME = \"2025 Entitlement Review\"\n",
    "BASE_PATH = APP_NAME\n",
    "SENDER_EMAIL = os.getenv(\"SENDER_EMAIL\")\n",
    "\n",
    "SCOPES = [\n",
    "    \"User.Read.All\", \"Mail.Send\", \"Mail.Read\", \n",
    "    \"Files.Read.All\", \"Sites.Read.All\"\n",
    "]\n",
    "\n",
    "app = PublicClientApplication(CLIENT_ID, authority=f\"https://login.microsoftonline.com/{TENANT_ID}\")\n",
    "print(\"üöÄ Opening browser for authentication...\")\n",
    "interactive_result = app.acquire_token_interactive(scopes=SCOPES, prompt=\"select_account\")\n",
    "\n",
    "if \"access_token\" not in interactive_result:\n",
    "    raise RuntimeError(f\"Login Failed: {interactive_result.get('error_description')}\")\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {interactive_result['access_token']}\"}\n",
    "logger.info(\"‚úÖ Login Successful\")\n",
    "logger.info(f\"Log File: {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 2: SharePoint API & App Selector (v3.6 with Counts & Filtering) ===\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import requests\n",
    "\n",
    "# --- 1. SharePoint API Functions ---\n",
    "def get_site_id(site_name: str) -> str:\n",
    "    url = f\"https://graph.microsoft.com/v1.0/sites/{SHAREPOINT_HOST}:/sites/{site_name}\"\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"id\"]\n",
    "\n",
    "def list_folders_with_count(site_id: str, path: str) -> list[dict]:\n",
    "    if not path or path.strip() == \"\":\n",
    "        url = f\"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/root/children\"\n",
    "    else:\n",
    "        clean_path = path.strip(\"/\")\n",
    "        url = f\"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/root:/{clean_path}:/children\"\n",
    "    \n",
    "    resp = requests.get(url, headers=headers)\n",
    "    results = []\n",
    "    EXCLUDED_NAMES = [\"forms\", \"_private\", \"audit logs\", \"audit\", \"user listings\", \"shared documents\"]\n",
    "\n",
    "    for item in resp.json().get(\"value\", []):\n",
    "        if item.get(\"folder\"):\n",
    "            name_lower = item[\"name\"].lower()\n",
    "            if any(ex in name_lower for ex in EXCLUDED_NAMES):\n",
    "                continue\n",
    "\n",
    "            count = item.get(\"folder\", {}).get(\"childCount\", 0)\n",
    "            results.append({\n",
    "                \"name\": item[\"name\"], \n",
    "                \"webUrl\": item.get(\"webUrl\", \"\"),\n",
    "                \"count\": count\n",
    "            })\n",
    "    return results\n",
    "\n",
    "def list_excel_files(site_id: str, folder_path: str) -> list[dict]:\n",
    "    clean_path = folder_path.strip(\"/\")\n",
    "    url = f\"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/root:/{clean_path}:/children\"\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    files = []\n",
    "    for item in resp.json().get(\"value\", []):\n",
    "        if item[\"name\"].endswith(\".xlsx\"):\n",
    "            files.append({\n",
    "                \"id\": item[\"id\"], \"name\": item[\"name\"],\n",
    "                \"lastModifiedDateTime\": item.get(\"lastModifiedDateTime\"),\n",
    "                \"createdDateTime\": item.get(\"createdDateTime\"),\n",
    "                \"webUrl\": item.get(\"webUrl\")\n",
    "            })\n",
    "    return sorted(files, key=lambda f: f.get(\"lastModifiedDateTime\", \"\"), reverse=True)\n",
    "\n",
    "def download_file(site_id: str, file_path: str) -> bytes:\n",
    "    clean_path = file_path.strip(\"/\")\n",
    "    url = f\"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/root:/{clean_path}:/content\"\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    resp.raise_for_status()\n",
    "    return resp.content\n",
    "\n",
    "def get_file_audit_info(site_id: str, file_id: str) -> dict:\n",
    "    url = f\"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/items/{file_id}/versions\"\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    default_res = {\"log\": \"N/A\", \"creator\": \"Unknown\", \"modifier\": \"Unknown\", \"created_ts\": None}\n",
    "    if resp.status_code != 200: return default_res\n",
    "    \n",
    "    versions = resp.json().get(\"value\", [])\n",
    "    if not versions: return default_res\n",
    "\n",
    "    logs = []\n",
    "    for v in versions:\n",
    "        mod_time = v.get(\"lastModifiedDateTime\", \"\")[:19].replace(\"T\", \" \")\n",
    "        actor = v.get(\"lastModifiedBy\", {}).get(\"user\", {}).get(\"displayName\") or \"System\"\n",
    "        logs.append(f\"{mod_time} - {actor}\")\n",
    "    \n",
    "    last_v = versions[0]\n",
    "    first_v = versions[-1]\n",
    "\n",
    "    return {\n",
    "        \"log\": \"\\n\".join(logs),\n",
    "        \"creator\": first_v.get(\"lastModifiedBy\", {}).get(\"user\", {}).get(\"displayName\") or \"System\",\n",
    "        \"modifier\": last_v.get(\"lastModifiedBy\", {}).get(\"user\", {}).get(\"displayName\") or \"System\",\n",
    "        \"created_ts\": first_v.get(\"lastModifiedDateTime\")\n",
    "    }\n",
    "\n",
    "# --- 2. Initialize Connection ---\n",
    "try:\n",
    "    site_id = get_site_id(SITE_NAME)\n",
    "    logger.info(f\"‚úÖ SharePoint Connected (Site ID: {site_id[:10]}...)\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Connection Failed: {e}\")\n",
    "\n",
    "# --- 3. Tree Selector UI (with Counts) ---\n",
    "TARGET_APPS = [] \n",
    "USE_CACHE = True \n",
    "\n",
    "def create_app_selector():\n",
    "    print(f\"üìÇ Reading Root: {BASE_PATH} ...\")\n",
    "    try:\n",
    "        categories = list_folders_with_count(site_id, BASE_PATH)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Read Failed: {e}\")\n",
    "        return\n",
    "\n",
    "    ui_container = widgets.VBox()\n",
    "    app_checkboxes = []\n",
    "    \n",
    "    chk_cache = widgets.Checkbox(value=True, description=\"‚ö° Use Cache (Faster)\", indent=False)\n",
    "    ui_container.children += (widgets.HTML(\"<h3>üìÇ App Selector (v3.6)</h3>\"), chk_cache, widgets.HTML(\"<hr>\"))\n",
    "\n",
    "    for cat in categories:\n",
    "        if cat['name'] in [\"Forms\", \"_private\"] or \"audit\" in cat['name'].lower(): continue\n",
    "            \n",
    "        cat_label = widgets.HTML(f\"<b>üìÅ {cat['name']}</b>\", layout=widgets.Layout(width='150px'))\n",
    "        btn_expand = widgets.Button(description=\"‚ûï Expand\", button_style='info', layout=widgets.Layout(width='80px'))\n",
    "        app_list_box = widgets.VBox(layout=widgets.Layout(margin='0 0 0 30px', display='none'))\n",
    "        \n",
    "        def on_expand(b, cat_name=cat['name'], container=app_list_box, btn=btn_expand):\n",
    "            if btn.description == \"‚ûï Expand\":\n",
    "                btn.description = \"‚è≥\"\n",
    "                sub_path = f\"{BASE_PATH}/{cat_name}\"\n",
    "                try:\n",
    "                    apps = list_folders_with_count(site_id, sub_path)\n",
    "                    checks = []\n",
    "                    if not apps: checks.append(widgets.Label(\"(Empty)\"))\n",
    "                    \n",
    "                    for app in apps:\n",
    "                        if app['name'] in [\"Forms\", \"_private\"]: continue\n",
    "                        \n",
    "                        count_display = f\" <span style='color:#888; font-size:11px'>({app['count']} users)</span>\"\n",
    "                        cb = widgets.Checkbox(value=False, description=app['name'], indent=False, layout=widgets.Layout(width='400px'))\n",
    "                        lbl_count = widgets.HTML(count_display)\n",
    "                        \n",
    "                        cb.app_data = (cat_name, app['name'], f\"{sub_path}/{app['name']}\")\n",
    "                        app_checkboxes.append(cb)\n",
    "                        checks.append(widgets.HBox([cb, lbl_count]))\n",
    "                    \n",
    "                    container.children = tuple(checks)\n",
    "                    container.layout.display = 'block'\n",
    "                    btn.description = \"‚ûñ Collapse\"\n",
    "                except Exception as e:\n",
    "                    container.children = (widgets.Label(f\"Error: {e}\"),)\n",
    "                    btn.description = \"‚ùå\"\n",
    "            else:\n",
    "                if container.layout.display == 'none':\n",
    "                    container.layout.display = 'block'; btn.description = \"‚ûñ Collapse\"\n",
    "                else:\n",
    "                    container.layout.display = 'none'; btn.description = \"‚ûï Expand\"\n",
    "\n",
    "        btn_expand.on_click(on_expand)\n",
    "        ui_container.children += (widgets.HBox([btn_expand, cat_label]), app_list_box)\n",
    "\n",
    "    btn_confirm = widgets.Button(description=\"‚úÖ Confirm Selection\", button_style='success', layout=widgets.Layout(margin='20px 0'))\n",
    "    output_area = widgets.Output()\n",
    "\n",
    "    def on_confirm(b):\n",
    "        global TARGET_APPS, USE_CACHE\n",
    "        TARGET_APPS = [cb.app_data for cb in app_checkboxes if cb.value]\n",
    "        USE_CACHE = chk_cache.value\n",
    "        \n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            if not TARGET_APPS: print(\"‚ö†Ô∏è No apps selected!\")\n",
    "            else:\n",
    "                print(f\"üéØ Selected {len(TARGET_APPS)} Apps | Cache: {USE_CACHE}\")\n",
    "                print(\"‚è≥ Proceed to Cell 4 (Enrichment) or Cell 5 (Scan).\")\n",
    "\n",
    "    btn_confirm.on_click(on_confirm)\n",
    "    display(ui_container, btn_confirm, output_area)\n",
    "\n",
    "create_app_selector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 5: AER Engine v4.2 (Cache Fix, User Info, Global Report, Safe Write) ===\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re, time, json, os, requests\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Alignment\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "\n",
    "# PART 1: CONFIG & LOADER\n",
    "\n",
    "# ==========================================\n",
    "\n",
    "CACHE_FILE = \"aer_cache.json\"\n",
    "\n",
    "NOTES_FILE = \"aer_manual_notes.json\"\n",
    "\n",
    "CACHE_VERSION = 4.2\n",
    "\n",
    "cache_updated = False\n",
    "\n",
    "EXCLUDED_FOLDERS = [\"forms\", \"_private\", \"user listings\", \"audit logs\", \"audit\"]\n",
    "\n",
    "\n",
    "\n",
    "def load_json(file_path):\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "\n",
    "        try:\n",
    "\n",
    "            with open(file_path, 'r', encoding='utf-8') as f: return json.load(f)\n",
    "\n",
    "        except: return {}\n",
    "\n",
    "    return {}\n",
    "\n",
    "\n",
    "\n",
    "def save_json(file_path, data):\n",
    "\n",
    "    with open(file_path, 'w', encoding='utf-8') as f: json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "\n",
    "def safe_excel_path(base_path):\n",
    "\n",
    "    \"\"\"If base_path is locked/open, append _1, _2, ... until writable.\"\"\"\n",
    "\n",
    "    if not os.path.exists(base_path):\n",
    "\n",
    "        return base_path\n",
    "\n",
    "    try:\n",
    "\n",
    "        with open(base_path, 'a'):\n",
    "\n",
    "            pass\n",
    "\n",
    "        return base_path\n",
    "\n",
    "    except OSError:\n",
    "\n",
    "        pass\n",
    "\n",
    "    stem, ext = os.path.splitext(base_path)\n",
    "\n",
    "    for i in range(1, 100):\n",
    "\n",
    "        candidate = f\"{stem}_{i}{ext}\"\n",
    "\n",
    "        if not os.path.exists(candidate):\n",
    "\n",
    "            return candidate\n",
    "\n",
    "    return f\"{stem}_{int(time.time())}{ext}\"\n",
    "\n",
    "\n",
    "\n",
    "def format_export_excel(file_path, audit_col_name=\"Audit Log\"):\n",
    "\n",
    "    wb = load_workbook(file_path)\n",
    "\n",
    "    ws = wb.active\n",
    "\n",
    "    header_to_col = {}\n",
    "\n",
    "    for col_idx in range(1, ws.max_column + 1):\n",
    "\n",
    "        hdr = ws.cell(row=1, column=col_idx).value\n",
    "\n",
    "        hdr_txt = str(hdr).strip() if hdr is not None else \"\"\n",
    "\n",
    "        if hdr_txt:\n",
    "\n",
    "            header_to_col[hdr_txt] = col_idx\n",
    "\n",
    "        max_len = len(hdr_txt)\n",
    "\n",
    "        for row_idx in range(2, ws.max_row + 1):\n",
    "\n",
    "            cell_val = ws.cell(row=row_idx, column=col_idx).value\n",
    "\n",
    "            if cell_val is None:\n",
    "\n",
    "                continue\n",
    "\n",
    "            lines = str(cell_val).splitlines() or [str(cell_val)]\n",
    "\n",
    "            max_len = max(max_len, max(len(line) for line in lines))\n",
    "\n",
    "        ws.column_dimensions[get_column_letter(col_idx)].width = min(max(10, max_len + 2), 80)\n",
    "\n",
    "    audit_col = header_to_col.get(audit_col_name)\n",
    "\n",
    "    if audit_col:\n",
    "\n",
    "        for row_idx in range(2, ws.max_row + 1):\n",
    "\n",
    "            cell = ws.cell(row=row_idx, column=audit_col)\n",
    "\n",
    "            txt = \"\" if cell.value is None else str(cell.value)\n",
    "\n",
    "            line_count = max(1, txt.count(\"\\n\") + 1)\n",
    "\n",
    "            cell.alignment = Alignment(wrap_text=True, vertical=\"top\")\n",
    "\n",
    "            current_height = ws.row_dimensions[row_idx].height or 15\n",
    "\n",
    "            ws.row_dimensions[row_idx].height = max(current_height, min(15 * line_count, 300))\n",
    "\n",
    "    wb.save(file_path)\n",
    "\n",
    "\n",
    "\n",
    "local_cache = load_json(CACHE_FILE)\n",
    "\n",
    "manual_data_store = load_json(NOTES_FILE)\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "\n",
    "# PART 2: ROBUST EXCEL PARSER\n",
    "\n",
    "# ==========================================\n",
    "\n",
    "def find_col_index(headers, keywords):\n",
    "\n",
    "    \"\"\"Case-insensitive search for column index.\"\"\"\n",
    "\n",
    "    for idx, h in enumerate(headers):\n",
    "\n",
    "        if not h: continue\n",
    "\n",
    "        h_str = str(h).strip().lower()\n",
    "\n",
    "        if all(k in h_str for k in keywords):\n",
    "\n",
    "            return idx\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def is_name_like_header(header_text: str) -> bool:\n",
    "\n",
    "    txt = (header_text or \"\").strip().lower()\n",
    "\n",
    "    if not txt:\n",
    "\n",
    "        return False\n",
    "\n",
    "    if \"reviewer\" in txt or \"manager\" in txt:\n",
    "\n",
    "        return False\n",
    "\n",
    "    return (\"name\" in txt) or (\"display\" in txt and \"user\" in txt) or (\"full\" in txt and \"name\" in txt)\n",
    "\n",
    "\n",
    "\n",
    "def is_email_like_header(header_text: str) -> bool:\n",
    "\n",
    "    txt = (header_text or \"\").strip().lower()\n",
    "\n",
    "    if not txt:\n",
    "\n",
    "        return False\n",
    "\n",
    "    return (\"email\" in txt) or (\"mail\" == txt) or txt.endswith(\" mail\")\n",
    "\n",
    "\n",
    "\n",
    "def resolve_column_map(header, app_col_map=None):\n",
    "\n",
    "    if app_col_map:\n",
    "\n",
    "        return app_col_map, \"app-locked\"\n",
    "\n",
    "    idx_rev = find_col_index(header, [\"reviewer\"])\n",
    "\n",
    "    idx_res = find_col_index(header, [\"response\"])\n",
    "\n",
    "    idx_det = find_col_index(header, [\"details\", \"change\"])\n",
    "\n",
    "    idx_user = None\n",
    "\n",
    "    idx_email = None\n",
    "\n",
    "    if idx_rev is not None:\n",
    "\n",
    "        rev_hdr = str(header[idx_rev]).strip().lower() if header[idx_rev] else \"\"\n",
    "\n",
    "        if \"response\" in rev_hdr:\n",
    "\n",
    "            idx_rev = None\n",
    "\n",
    "            for i, h in enumerate(header):\n",
    "\n",
    "                h_str = str(h).strip().lower() if h else \"\"\n",
    "\n",
    "                if (\"reviewer\" in h_str) and (\"response\" not in h_str):\n",
    "\n",
    "                    idx_rev = i\n",
    "\n",
    "                    break\n",
    "\n",
    "    for i in range(min(2, len(header))):\n",
    "\n",
    "        h = str(header[i]).strip().lower() if header[i] else \"\"\n",
    "\n",
    "        if idx_user is None and is_name_like_header(h):\n",
    "\n",
    "            idx_user = i\n",
    "\n",
    "        if idx_email is None and is_email_like_header(h):\n",
    "\n",
    "            idx_email = i\n",
    "\n",
    "    if idx_user is None: idx_user = find_col_index(header, [\"user\", \"name\"])\n",
    "\n",
    "    if idx_user is None: idx_user = find_col_index(header, [\"display\", \"name\"])\n",
    "\n",
    "    if idx_user is None: idx_user = find_col_index(header, [\"full\", \"name\"])\n",
    "\n",
    "    if idx_user is None: idx_user = find_col_index(header, [\"name\"])\n",
    "\n",
    "    if idx_email is None: idx_email = find_col_index(header, [\"email\"])\n",
    "\n",
    "    if idx_email is None: idx_email = find_col_index(header, [\"mail\"])\n",
    "\n",
    "    if idx_rev is None: idx_rev = find_col_index(header, [\"manager\"])\n",
    "\n",
    "    if idx_rev is None or idx_res is None:\n",
    "\n",
    "        return None, \"invalid\"\n",
    "\n",
    "    return {\n",
    "\n",
    "        \"idx_rev\": idx_rev, \"idx_res\": idx_res, \"idx_det\": idx_det,\n",
    "\n",
    "        \"idx_user\": idx_user, \"idx_email\": idx_email\n",
    "\n",
    "    }, \"detected\"\n",
    "\n",
    "\n",
    "\n",
    "def read_excel_rows(excel_bytes: bytes, reviewer_name: str, file_name: str, folder_url: str, app_col_map=None):\n",
    "\n",
    "    wb = load_workbook(BytesIO(excel_bytes), read_only=True)\n",
    "\n",
    "\n",
    "\n",
    "    # 1. Smart Tab Selection\n",
    "\n",
    "    sheet_name = wb.sheetnames[0]\n",
    "\n",
    "    for sn in wb.sheetnames:\n",
    "\n",
    "        if \"user listing\" in sn.lower(): sheet_name = sn; break\n",
    "\n",
    "    ws = wb[sheet_name]\n",
    "\n",
    "\n",
    "\n",
    "    # 2. Read Headers\n",
    "\n",
    "    rows_iter = ws.iter_rows(values_only=True)\n",
    "\n",
    "    try:\n",
    "\n",
    "        header = next(rows_iter)\n",
    "\n",
    "    except StopIteration:\n",
    "\n",
    "        return [], None, \"empty-sheet\"\n",
    "\n",
    "\n",
    "\n",
    "    # 3. Column Mapping\n",
    "\n",
    "    col_map, map_source = resolve_column_map(header, app_col_map=app_col_map)\n",
    "\n",
    "    if not col_map:\n",
    "\n",
    "        return [], None, map_source\n",
    "\n",
    "    idx_rev = col_map[\"idx_rev\"]\n",
    "\n",
    "    idx_res = col_map[\"idx_res\"]\n",
    "\n",
    "    idx_det = col_map[\"idx_det\"]\n",
    "\n",
    "    idx_user = col_map[\"idx_user\"]\n",
    "\n",
    "    idx_email = col_map[\"idx_email\"]\n",
    "\n",
    "\n",
    "\n",
    "    results = []\n",
    "\n",
    "\n",
    "\n",
    "    # 4. Iterate Rows\n",
    "\n",
    "    for i, row in enumerate(rows_iter, start=2):\n",
    "\n",
    "        r_rev = row[idx_rev] if idx_rev < len(row) else None\n",
    "\n",
    "        r_res = row[idx_res] if idx_res < len(row) else None\n",
    "\n",
    "        r_det = row[idx_det] if idx_det is not None and idx_det < len(row) else None\n",
    "\n",
    "        r_user = row[idx_user] if idx_user is not None and idx_user < len(row) else None\n",
    "\n",
    "        r_email = row[idx_email] if idx_email is not None and idx_email < len(row) else None\n",
    "\n",
    "\n",
    "\n",
    "        if str(r_rev).strip().lower() != reviewer_name.lower(): continue\n",
    "\n",
    "\n",
    "\n",
    "        val_res = str(r_res).strip() if r_res else \"\"\n",
    "\n",
    "        val_det = str(r_det).strip() if r_det else \"\"\n",
    "\n",
    "\n",
    "\n",
    "        results.append({\n",
    "\n",
    "            \"reviewer\": reviewer_name,\n",
    "\n",
    "            \"user_name\": str(r_user).strip() if r_user else \"\",\n",
    "\n",
    "            \"user_email\": str(r_email).strip() if r_email else \"\",\n",
    "\n",
    "            \"response\": val_res,\n",
    "\n",
    "            \"details\": val_det,\n",
    "\n",
    "            \"is_missing\": (val_res == \"\"),\n",
    "\n",
    "            \"row_number\": i,\n",
    "\n",
    "            \"file_name\": file_name,\n",
    "\n",
    "            \"folder_url\": folder_url\n",
    "\n",
    "        })\n",
    "\n",
    "    return results, col_map, map_source\n",
    "\n",
    "\n",
    "\n",
    "def get_row_stats(txt):\n",
    "\n",
    "    txt = str(txt).lower().strip()\n",
    "\n",
    "    kw_appr = ['approv', 'retain', 'keep', 'confirm', 'yes', 'ok', 'active']\n",
    "\n",
    "    kw_deny = ['denied', 'deny', 'remove', 'delete', 'revok', 'reject', 'no']\n",
    "\n",
    "    kw_chg  = ['change', 'modif', 'updat', 'correct', 'edit', 'adjust']\n",
    "\n",
    "    return {\n",
    "\n",
    "        \"is_appr\": 1 if any(k in txt for k in kw_appr) else 0,\n",
    "\n",
    "        \"is_deny\": 1 if any(k in txt for k in kw_deny) else 0,\n",
    "\n",
    "        \"is_chg\":  1 if any(k in txt for k in kw_chg) else 0\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "\n",
    "# PART 3: SCANNING ENGINE\n",
    "\n",
    "# ==========================================\n",
    "\n",
    "if 'TARGET_APPS' not in globals() or not TARGET_APPS:\n",
    "\n",
    "    print(\"‚ö†Ô∏è Please select Apps in Cell 2 first!\")\n",
    "\n",
    "    TARGET_APPS = []\n",
    "\n",
    "\n",
    "\n",
    "all_responses = []\n",
    "\n",
    "errors = []\n",
    "\n",
    "app_column_map_store = {}\n",
    "\n",
    "\n",
    "\n",
    "print(f\"üöÄ Starting Scan Engine v{CACHE_VERSION} (Fuzzy Column Match)...\")\n",
    "\n",
    "\n",
    "\n",
    "for category, current_app_name, current_path in TARGET_APPS:\n",
    "\n",
    "    try:\n",
    "\n",
    "        raw_folders = list_folders_with_count(site_id, current_path) if 'list_folders_with_count' in globals() else []\n",
    "\n",
    "        if not raw_folders: raw_folders = [{\"name\": \"Error\", \"webUrl\": \"#\"}]\n",
    "\n",
    "\n",
    "\n",
    "        reviewers = [r for r in raw_folders if r['name'].lower() not in EXCLUDED_FOLDERS]\n",
    "\n",
    "        total_revs = len(reviewers)\n",
    "\n",
    "        logger.info(f\"üìÇ App: {current_app_name} | Reviewers: {total_revs}\")\n",
    "\n",
    "        app_schema_key = f\"{category}|{current_app_name}\"\n",
    "\n",
    "        app_col_map = app_column_map_store.get(app_schema_key)\n",
    "\n",
    "\n",
    "\n",
    "        for idx, folder in enumerate(reviewers, 1):\n",
    "\n",
    "            reviewer_name = folder[\"name\"]\n",
    "\n",
    "            folder_url = folder[\"webUrl\"]\n",
    "\n",
    "            folder_path = f\"{current_path}/{reviewer_name}\"\n",
    "\n",
    "            cache_key = f\"{category}|{current_app_name}|{reviewer_name}\"\n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "\n",
    "                files = list_excel_files(site_id, folder_path)\n",
    "\n",
    "                match_candidates = [f for f in files if reviewer_name.lower() in f[\"name\"].lower()]\n",
    "\n",
    "                target_file = match_candidates[0] if match_candidates else (files[0] if files else None)\n",
    "\n",
    "\n",
    "\n",
    "                if not target_file:\n",
    "\n",
    "                    logger.info(f\"  ‚ö†Ô∏è Skip: [{idx}/{total_revs}] {reviewer_name} (no xlsx found)\")\n",
    "\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "                remote_mod = target_file.get(\"lastModifiedDateTime\")\n",
    "\n",
    "                logger.info(f\"  üîé File: [{idx}/{total_revs}] {reviewer_name} | Target:{target_file['name']} | Modified:{remote_mod}\")\n",
    "\n",
    "\n",
    "\n",
    "                cached = local_cache.get(cache_key)\n",
    "\n",
    "                is_hit = False\n",
    "                force_live_recheck = False\n",
    "                cache_pending = False\n",
    "\n",
    "\n",
    "\n",
    "                if USE_CACHE and cached and cached.get('v') == CACHE_VERSION and cached.get('last_mod') == remote_mod and 'rows' in cached and len(cached['rows']) > 0:\n",
    "\n",
    "                    cache_pending = any(r.get('is_missing') for r in cached.get('rows', []))\n",
    "\n",
    "                    if cache_pending:\n",
    "\n",
    "                        force_live_recheck = True\n",
    "\n",
    "                        logger.info(f\"  ‚ôªÔ∏è Cache Recheck: [{idx}/{total_revs}] {reviewer_name} has pending rows; reading live and overwriting cache.\")\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        is_hit = True\n",
    "\n",
    "                        logger.info(f\"  üßä Cache Hit (Completed): [{idx}/{total_revs}] {reviewer_name} | rows:{len(cached['rows'])}\")\n",
    "\n",
    "                else:\n",
    "\n",
    "                    if not USE_CACHE:\n",
    "\n",
    "                        logger.info(f\"  ‚ÑπÔ∏è Cache Bypass: [{idx}/{total_revs}] {reviewer_name} (USE_CACHE=False)\")\n",
    "\n",
    "                    elif not cached:\n",
    "\n",
    "                        logger.info(f\"  ‚ÑπÔ∏è Cache Miss: [{idx}/{total_revs}] {reviewer_name} (no cache key)\")\n",
    "\n",
    "                    elif cached.get('v') != CACHE_VERSION:\n",
    "\n",
    "                        logger.info(f\"  ‚ÑπÔ∏è Cache Miss: [{idx}/{total_revs}] {reviewer_name} (version {cached.get('v')} != {CACHE_VERSION})\")\n",
    "\n",
    "                    elif cached.get('last_mod') != remote_mod:\n",
    "\n",
    "                        logger.info(f\"  ‚ÑπÔ∏è Cache Miss: [{idx}/{total_revs}] {reviewer_name} (modified changed)\")\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        logger.info(f\"  ‚ÑπÔ∏è Cache Miss: [{idx}/{total_revs}] {reviewer_name} (no cached rows)\")\n",
    "\n",
    "\n",
    "\n",
    "                if is_hit:\n",
    "\n",
    "                    audit_snap = cached.get('audit', {})\n",
    "\n",
    "                    c_appr = cached['stats']['Appr']\n",
    "\n",
    "                    c_deny = cached['stats']['Deny']\n",
    "\n",
    "                    c_chg = cached['stats']['Chg']\n",
    "\n",
    "                    c_miss = sum(1 for r in cached['rows'] if r['is_missing'])\n",
    "\n",
    "\n",
    "\n",
    "                    logger.info(f\"  ‚úÖ Read (Cache): [{idx}/{total_revs}] {reviewer_name} (Missing:{c_miss})(A:{c_appr}, D:{c_deny}, C:{c_chg})\")\n",
    "\n",
    "\n",
    "\n",
    "                    for r in cached['rows']:\n",
    "\n",
    "                        r_copy = r.copy()\n",
    "\n",
    "                        st = get_row_stats(r['response'])\n",
    "\n",
    "                        r_copy.update({\n",
    "\n",
    "                            \"Category\": category, \"App_Name\": current_app_name,\n",
    "\n",
    "                            \"Last_Modified\": remote_mod, \"File_Created_Date\": audit_snap.get('created_ts'),\n",
    "\n",
    "                            \"Audit_Log\": audit_snap.get('log'), \"File_Creator\": audit_snap.get('creator'), \"File_Modifier\": audit_snap.get('modifier'),\n",
    "\n",
    "                            \"stats_appr\": st['is_appr'], \"stats_deny\": st['is_deny'], \"stats_chg\": st['is_chg'],\n",
    "\n",
    "                            \"source_is_cache\": True\n",
    "\n",
    "                        })\n",
    "\n",
    "                        all_responses.append(r_copy)\n",
    "\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "                content = download_file(site_id, f\"{folder_path}/{target_file['name']}\")\n",
    "\n",
    "                audit_info = get_file_audit_info(site_id, target_file[\"id\"])\n",
    "\n",
    "\n",
    "\n",
    "                rows, detected_col_map, map_source = read_excel_rows(\n",
    "                    content, reviewer_name, target_file['name'], folder_url, app_col_map=app_col_map\n",
    "                )\n",
    "\n",
    "                if detected_col_map and not app_col_map:\n",
    "\n",
    "                    app_col_map = detected_col_map\n",
    "\n",
    "                    app_column_map_store[app_schema_key] = detected_col_map\n",
    "\n",
    "                    logger.info(\n",
    "                        f\"  üß≠ App Column Map Locked: NameIdx={detected_col_map.get('idx_user')} \"\n",
    "                        f\"EmailIdx={detected_col_map.get('idx_email')} Source={map_source}\"\n",
    "                    )\n",
    "                elif detected_col_map and map_source == \"app-locked\":\n",
    "\n",
    "                    logger.info(\n",
    "                        f\"  üß≠ App Column Map Reused: NameIdx={detected_col_map.get('idx_user')} \"\n",
    "                        f\"EmailIdx={detected_col_map.get('idx_email')}\"\n",
    "                    )\n",
    "                else:\n",
    "\n",
    "                    logger.warning(f\"  ‚ö†Ô∏è Column Mapping Failed: [{idx}/{total_revs}] {reviewer_name}\")\n",
    "\n",
    "\n",
    "\n",
    "                s_appr, s_deny, s_chg, miss_cnt = 0, 0, 0, 0\n",
    "\n",
    "                clean_rows_cache = []\n",
    "\n",
    "                final_created = audit_info.get('created_ts') or target_file.get(\"createdDateTime\")\n",
    "\n",
    "\n",
    "\n",
    "                for r in rows:\n",
    "\n",
    "                    st = get_row_stats(r['response'])\n",
    "\n",
    "                    s_appr += st['is_appr']; s_deny += st['is_deny']; s_chg += st['is_chg']\n",
    "\n",
    "                    if r['is_missing']: miss_cnt += 1\n",
    "\n",
    "\n",
    "\n",
    "                    clean_rows_cache.append({\n",
    "\n",
    "                        \"reviewer\": r['reviewer'], \"user_name\": r.get('user_name', ''), \"user_email\": r.get('user_email', ''),\n",
    "\n",
    "                        \"response\": r['response'], \"details\": r['details'],\n",
    "\n",
    "                        \"is_missing\": r['is_missing'], \"row_number\": r['row_number'],\n",
    "\n",
    "                        \"file_name\": r['file_name'], \"folder_url\": r['folder_url']\n",
    "\n",
    "                    })\n",
    "\n",
    "\n",
    "\n",
    "                    r.update({\n",
    "\n",
    "                        \"Category\": category, \"App_Name\": current_app_name,\n",
    "\n",
    "                        \"Last_Modified\": remote_mod, \"File_Created_Date\": final_created,\n",
    "\n",
    "                        \"Audit_Log\": audit_info['log'], \"File_Creator\": audit_info['creator'], \"File_Modifier\": audit_info['modifier'],\n",
    "\n",
    "                        \"stats_appr\": st['is_appr'], \"stats_deny\": st['is_deny'], \"stats_chg\": st['is_chg'],\n",
    "\n",
    "                        \"source_is_cache\": False\n",
    "\n",
    "                    })\n",
    "\n",
    "\n",
    "\n",
    "                all_responses.extend(rows)\n",
    "\n",
    "\n",
    "\n",
    "                logger.info(\n",
    "                    f\"  ‚úÖ Read (Live): [{idx}/{total_revs}] {reviewer_name} \"\n",
    "                    f\"(Rows:{len(rows)} Missing:{miss_cnt})(A:{s_appr}, D:{s_deny}, C:{s_chg})\"\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "                if rows or force_live_recheck:\n",
    "\n",
    "                    local_cache[cache_key] = {\n",
    "\n",
    "                        \"v\": CACHE_VERSION, \"last_mod\": remote_mod,\n",
    "\n",
    "                        \"stats\": {\"Appr\": s_appr, \"Deny\": s_deny, \"Chg\": s_chg},\n",
    "\n",
    "                        \"audit\": audit_info, \"rows\": clean_rows_cache\n",
    "\n",
    "                    }\n",
    "\n",
    "                    cache_updated = True\n",
    "\n",
    "                    logger.info(\n",
    "                        f\"  üíæ Cache Write: [{idx}/{total_revs}] {reviewer_name} \"\n",
    "                        f\"(Rows:{len(clean_rows_cache)} Missing:{miss_cnt} PendingRecheck:{force_live_recheck})\"\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "\n",
    "                logger.error(f\"  ‚ùå Error {reviewer_name}: {e}\")\n",
    "\n",
    "                errors.append({\"Category\": category, \"App_Name\": current_app_name, \"reviewer\": reviewer_name, \"error\": str(e), \"folder_url\": folder_url})\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e: logger.error(f\"‚ùå App Error: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "if cache_updated:\n",
    "\n",
    "    save_json(CACHE_FILE, local_cache)\n",
    "\n",
    "    logger.info(\"üíæ Cache Updated (v4.2)\")\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "\n",
    "# PART 4: DASHBOARD\n",
    "\n",
    "# ==========================================\n",
    "\n",
    "df = pd.DataFrame(all_responses)\n",
    "\n",
    "widget_store = {}\n",
    "\n",
    "unified_data = {}\n",
    "\n",
    "today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "report_dir = f\"output/{today_str}/report\"\n",
    "\n",
    "os.makedirs(report_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "if not df.empty:\n",
    "\n",
    "    stats = df.groupby([\"Category\", \"App_Name\", \"reviewer\"]).agg(\n",
    "\n",
    "        missing=(\"is_missing\", \"sum\"),\n",
    "\n",
    "        approved=(\"stats_appr\", \"sum\"), denied=(\"stats_deny\", \"sum\"), changed=(\"stats_chg\", \"sum\"),\n",
    "\n",
    "        f_creator=(\"File_Creator\", \"first\"), f_modifier=(\"File_Modifier\", \"first\"), audit=(\"Audit_Log\", \"first\"),\n",
    "\n",
    "        is_cached=(\"source_is_cache\", \"all\")\n",
    "\n",
    "    ).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "    for _, row in stats.iterrows():\n",
    "\n",
    "        key = f\"{row['Category']} > {row['App_Name']}\"\n",
    "\n",
    "        if key not in unified_data:\n",
    "\n",
    "            saved_app = manual_data_store.get(key, {})\n",
    "\n",
    "            unified_data[key] = {\n",
    "\n",
    "                \"Category\": row['Category'], \"App_Name\": row['App_Name'],\n",
    "\n",
    "                \"status_manual\": saved_app.get(\"app_status\", \"Calculated\"), \"note_manual\": saved_app.get(\"app_note\", \"\"),\n",
    "\n",
    "                \"reviewers\": {}, \"stats\": {\"total_users\": 0, \"completed_users\": 0}\n",
    "\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "        node = unified_data[key]\n",
    "\n",
    "        node['stats']['total_users'] += 1\n",
    "\n",
    "        is_done = (row['missing'] == 0)\n",
    "\n",
    "        if is_done: node['stats']['completed_users'] += 1\n",
    "\n",
    "        status_calc = f\"‚ùå Pending: {row['missing']}\"\n",
    "\n",
    "        if is_done: status_calc = \"‚úÖ Cached - Completed\" if row['is_cached'] else \"‚úÖ Completed\"\n",
    "\n",
    "\n",
    "\n",
    "        d_style = \"color:red;font-weight:bold\" if row['denied'] > 0 else \"color:#555\"\n",
    "\n",
    "        node['reviewers'][row['reviewer']] = {\n",
    "\n",
    "            \"status_calc\": status_calc,\n",
    "\n",
    "            \"detail_html\": f\"Appr:{int(row['approved'])} | <span style='{d_style}'>Deny:{int(row['denied'])}</span> | Chg:{int(row['changed'])}\",\n",
    "\n",
    "            \"folder_url\": df[(df['App_Name'] == row['App_Name']) & (df['reviewer'] == row['reviewer'])].iloc[0].get('folder_url', '#')\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def build_dashboard():\n",
    "\n",
    "    container = widgets.VBox()\n",
    "\n",
    "    btn_export = widgets.Button(description=\"üíæ Save Reports\", button_style='success', icon='file-excel')\n",
    "\n",
    "    btn_global = widgets.Button(description=\"üìä Global Report\", button_style='primary')\n",
    "\n",
    "    lbl_out = widgets.Label()\n",
    "\n",
    "\n",
    "\n",
    "    app_widgets = []\n",
    "\n",
    "    for app_key in sorted(unified_data.keys()):\n",
    "\n",
    "        app_data = unified_data[app_key]\n",
    "\n",
    "        pct = int((app_data['stats']['completed_users'] / app_data['stats']['total_users'] * 100)) if app_data['stats']['total_users'] > 0 else 0\n",
    "\n",
    "        w_lbl = widgets.HTML(f\"<b>üìÇ {app_key}</b> &nbsp; <span style='background:#eee; padding:2px 5px; border-radius:4px'>{pct}% Done</span>\", layout=widgets.Layout(width='400px'))\n",
    "\n",
    "        w_stat = widgets.Dropdown(options=[\"Calculated\", \"Force Completed\", \"Action Required\"], value=app_data['status_manual'], layout=widgets.Layout(width='150px'))\n",
    "\n",
    "        widget_store[app_key] = {\"data\": app_data, \"w_stat\": w_stat}\n",
    "\n",
    "\n",
    "\n",
    "        rev_list = widgets.VBox([\n",
    "\n",
    "            widgets.HBox([\n",
    "\n",
    "                widgets.HTML(f\"<a href='{rd['folder_url']}' target='_blank'>{rn}</a>\", layout=widgets.Layout(width='250px')),\n",
    "\n",
    "                widgets.HTML(rd['status_calc'], layout=widgets.Layout(width='200px')),\n",
    "\n",
    "                widgets.HTML(rd['detail_html'])\n",
    "\n",
    "            ]) for rn, rd in app_data['reviewers'].items()\n",
    "\n",
    "        ], layout=widgets.Layout(margin='5px 0 5px 20px', display='none'))\n",
    "\n",
    "\n",
    "\n",
    "        btn_tog = widgets.Button(description=\"‚ûï Show Users\", layout=widgets.Layout(width='100px'))\n",
    "\n",
    "        def create_tog(w):\n",
    "\n",
    "            def on_tog(b):\n",
    "\n",
    "                if w.layout.display == 'none': w.layout.display = 'block'; b.description = \"‚ûñ Hide\"\n",
    "\n",
    "                else: w.layout.display = 'none'; b.description = \"‚ûï Show Users\"\n",
    "\n",
    "            return on_tog\n",
    "\n",
    "        btn_tog.on_click(create_tog(rev_list))\n",
    "\n",
    "        app_widgets.append(widgets.VBox([widgets.HBox([btn_tog, w_lbl, w_stat]), rev_list]))\n",
    "\n",
    "\n",
    "\n",
    "    def export(b):\n",
    "\n",
    "        b.disabled=True; b.description=\"Saving...\"\n",
    "\n",
    "        saved_files = []\n",
    "\n",
    "        for app_key, widget_data in widget_store.items():\n",
    "\n",
    "            app_name = widget_data['data']['App_Name']\n",
    "\n",
    "            category = widget_data['data']['Category']\n",
    "\n",
    "            app_rows = df[(df['Category'] == category) & (df['App_Name'] == app_name)].to_dict('records')\n",
    "\n",
    "\n",
    "\n",
    "            final_data = []\n",
    "\n",
    "            for row in app_rows:\n",
    "\n",
    "                fin_st = widget_data['w_stat'].value\n",
    "\n",
    "                if fin_st == \"Calculated\": fin_st = \"Cached - Completed\" if row.get('source_is_cache') else \"Completed\"\n",
    "\n",
    "\n",
    "\n",
    "                final_data.append({\n",
    "\n",
    "                    \"User Name\": row.get('user_name', ''),\n",
    "\n",
    "                    \"User Email\": row.get('user_email', ''),\n",
    "\n",
    "                    \"Reviewer\": row['reviewer'],\n",
    "\n",
    "                    \"File Name\": row.get('file_name'),\n",
    "\n",
    "                    \"Reviewer Response\": row.get('response'),\n",
    "\n",
    "                    \"Details of Access Change\": row.get('details'),\n",
    "\n",
    "                    \"Final Status\": fin_st,\n",
    "\n",
    "                    \"Row Num\": row.get('row_number'),\n",
    "\n",
    "                    \"Audit Log\": row.get('Audit_Log')\n",
    "\n",
    "                })\n",
    "\n",
    "\n",
    "\n",
    "            if final_data:\n",
    "\n",
    "                safe_name = re.sub(r'[\\\\/*?:\"<>|]', \"\", app_name)\n",
    "\n",
    "                f_path = safe_excel_path(f\"{report_dir}/{safe_name}_{today_str}.xlsx\")\n",
    "\n",
    "                pd.DataFrame(final_data).to_excel(f_path, index=False)\n",
    "                format_export_excel(f_path)\n",
    "\n",
    "                saved_files.append(safe_name)\n",
    "\n",
    "\n",
    "\n",
    "        lbl_out.value = f\"Saved {len(saved_files)} files.\"\n",
    "\n",
    "        b.disabled=False; b.description=\"üíæ Save Reports\"\n",
    "\n",
    "\n",
    "\n",
    "    def export_global(b):\n",
    "\n",
    "        b.disabled = True; b.description = \"Saving...\"\n",
    "\n",
    "        rows = []\n",
    "\n",
    "        for _, r in stats.sort_values(\"App_Name\").iterrows():\n",
    "\n",
    "            rows.append({\n",
    "\n",
    "                \"Category\": r['Category'],\n",
    "\n",
    "                \"App Name\": r['App_Name'],\n",
    "\n",
    "                \"Reviewer\": r['reviewer'],\n",
    "\n",
    "                \"Final Status\": \"Completed\" if r['missing'] == 0 else \"Pending\",\n",
    "\n",
    "                \"Total Approved\": int(r['approved']),\n",
    "\n",
    "                \"Total Denied\": int(r['denied']),\n",
    "\n",
    "                \"Total Changed\": int(r['changed'])\n",
    "\n",
    "            })\n",
    "\n",
    "        f_path = safe_excel_path(f\"{report_dir}/Summary_Report_{today_str}.xlsx\")\n",
    "\n",
    "        pd.DataFrame(rows).to_excel(f_path, index=False)\n",
    "        format_export_excel(f_path)\n",
    "\n",
    "        lbl_out.value = f\"Global report saved.\"\n",
    "\n",
    "        b.disabled = False; b.description = \"üìä Global Report\"\n",
    "\n",
    "\n",
    "\n",
    "    btn_export.on_click(export)\n",
    "\n",
    "    btn_global.on_click(export_global)\n",
    "\n",
    "    container.children = tuple([widgets.HBox([btn_export, btn_global, lbl_out])] + app_widgets)\n",
    "\n",
    "    display(container)\n",
    "\n",
    "\n",
    "\n",
    "if unified_data:\n",
    "\n",
    "    build_dashboard()\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"‚ö†Ô∏è No data found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 6: Email Notification (Merge & Apple Bank Template with SEND ALL) ===\n",
    "import ipywidgets as widgets\n",
    "from urllib.parse import quote\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "# --- 1. Helper Functions ---\n",
    "def get_email(name): \n",
    "    if not name: return \"\"\n",
    "    try:\n",
    "        clean = quote(name.split(\"(\")[0].strip())\n",
    "        url = f\"https://graph.microsoft.com/v1.0/users?$filter=startswith(displayName,'{clean}')&$select=mail,userPrincipalName\"\n",
    "        res = requests.get(url, headers=headers).json().get('value')\n",
    "        if res: return res[0].get('mail') or res[0].get('userPrincipalName')\n",
    "    except: pass\n",
    "    return \"\"\n",
    "\n",
    "def fmt_date_long(iso_date_str):\n",
    "    if not iso_date_str or pd.isna(iso_date_str): return \"Unknown Date\"\n",
    "    try:\n",
    "        dt_str = str(iso_date_str).replace('Z', '').split('.')[0]\n",
    "        dt = datetime.fromisoformat(dt_str)\n",
    "        return dt.strftime(\"%B %d, %Y\")\n",
    "    except: return str(iso_date_str)\n",
    "\n",
    "def calc_due_date_long(iso_date_str):\n",
    "    if not iso_date_str or pd.isna(iso_date_str): return \"ASAP\"\n",
    "    try:\n",
    "        dt_str = str(iso_date_str).replace('Z', '').split('.')[0]\n",
    "        dt = datetime.fromisoformat(dt_str)\n",
    "        due = dt + timedelta(days=14)\n",
    "        return due.strftime(\"%B %d, %Y\")\n",
    "    except: return \"ASAP\"\n",
    "\n",
    "def parse_email_list(raw_text):\n",
    "    if not raw_text:\n",
    "        return []\n",
    "    parts = re.split(r\"[,\\n;]+\", str(raw_text))\n",
    "    return [p.strip() for p in parts if p and p.strip()]\n",
    "\n",
    "# --- 2. Data Preparation ---\n",
    "if 'df' not in globals() or df.empty:\n",
    "    display(widgets.HTML(\"<h4 style='color:red'>‚ö†Ô∏è No data found. Run Cell 5 first.</h4>\"))\n",
    "else:\n",
    "    pending_df = df[df['is_missing'] == True].copy()\n",
    "    targets = pending_df.groupby([\"Category\", \"App_Name\", \"reviewer\", \"folder_url\"]).agg(\n",
    "        missing_count=(\"is_missing\", \"count\"),\n",
    "        file_date_raw=(\"File_Created_Date\", \"min\") \n",
    "    ).reset_index()\n",
    "\n",
    "    notes_db = manual_data_store if 'manual_data_store' in globals() else {}\n",
    "    print(\"üîç Looking up emails for pending reviewers...\")\n",
    "    email_cache = {} \n",
    "    raw_data_list = []\n",
    "    \n",
    "    for _, r in targets.iterrows():\n",
    "        app_key = f\"{r['Category']} > {r['App_Name']}\"\n",
    "        rev_key = r['reviewer']\n",
    "        app_node = notes_db.get(app_key, {})\n",
    "        if app_node.get(\"app_status\") in [\"Force Completed\", \"N/A\"]: continue\n",
    "        rev_override = app_node.get(\"reviewers\", {}).get(rev_key, {}).get(\"override\", \"-\")\n",
    "        if rev_override in [\"Mark Done\", \"Waived\", \"Escalated\"]: continue\n",
    "        \n",
    "        if rev_key not in email_cache: email_cache[rev_key] = get_email(rev_key)\n",
    "        raw_data_list.append({\n",
    "            \"App_Name\": r['App_Name'], \"reviewer\": r['reviewer'], \"missing\": r['missing_count'], \n",
    "            \"folder_url\": r['folder_url'], \"sent_date\": fmt_date_long(r['file_date_raw']),\n",
    "            \"due_date\": calc_due_date_long(r['file_date_raw']), \"email\": email_cache[rev_key]\n",
    "        })\n",
    "    clear_output()\n",
    "\n",
    "    # --- 3. UI Construction ---\n",
    "    current_year = datetime.now().year\n",
    "    default_subj_single = f\"REMINDER - {current_year} {{app_name}} Entitlement Review\"\n",
    "    default_subj_merge = f\"REMINDER - {current_year} Entitlement Reviews Action Required\"\n",
    "    \n",
    "    default_body = (\n",
    "        \"Hi {reviewer_name},<br><br>\"\n",
    "        \"The Information Security team is sending you a reminder to complete the <b>{app_name}</b> entitlement review that was sent to you on <b>{sent_date}</b>.<br><br>\"\n",
    "        \"The review was due on <b>{due_date}</b>. Please complete this review as soon as possible as it is now overdue. Your prompt assistance to this matter is appreciated.<br><br>\"\n",
    "        \"<b>Review Details:</b>\"\n",
    "        \"<ul><li>Pending Items: <b>{missing}</b></li>\"\n",
    "        \"<li>Link: <a href='{link}'>Open Access Review Folder</a></li></ul><br>\"\n",
    "        \"Sincerely,<br>Apple Bank's Information Security Team\"\n",
    "    )\n",
    "\n",
    "    w_merge = widgets.Checkbox(value=True, description=\"<b>üîó Merge Apps by Reviewer</b>\", indent=False)\n",
    "    w_subject_tpl = widgets.Text(value=default_subj_merge, description=\"<b>Subject:</b>\", layout=widgets.Layout(width='98%'))\n",
    "    w_cc_global = widgets.Textarea(\n",
    "        value=\"\",\n",
    "        description=\"<b>Global CC:</b>\",\n",
    "        placeholder=\"manager@applebank.com, team@applebank.com\",\n",
    "        layout=widgets.Layout(width='98%', height='60px')\n",
    "    )\n",
    "    w_reply_to = widgets.Text(\n",
    "        value=\"\",\n",
    "        description=\"<b>Reply-To:</b>\",\n",
    "        placeholder=\"security-team@applebank.com\",\n",
    "        layout=widgets.Layout(width='98%')\n",
    "    )\n",
    "    w_body_tpl = widgets.Textarea(value=default_body.replace(\"<br>\", \"\\n\"), layout=widgets.Layout(width='100%', height='150px'))\n",
    "    btn_refresh = widgets.Button(description=\"üîÑ Refresh List\", button_style='info', layout=widgets.Layout(width='200px'))\n",
    "    \n",
    "    btn_send_all = widgets.Button(description=\"üî• Send All (Batch)\", button_style='danger', layout=widgets.Layout(width='200px'))\n",
    "    \n",
    "    container_rows = widgets.VBox()\n",
    "    row_logic_store = {}\n",
    "\n",
    "    def render_rows(b=None):\n",
    "        global row_logic_store\n",
    "        row_logic_store = {}\n",
    "        container_rows.children = (widgets.Label(\"Loading...\"),)\n",
    "        is_merged = w_merge.value\n",
    "        if is_merged and \"{app_name}\" in w_subject_tpl.value: w_subject_tpl.value = default_subj_merge\n",
    "        elif not is_merged and \"{app_name}\" not in w_subject_tpl.value: w_subject_tpl.value = default_subj_single\n",
    "\n",
    "        df_raw = pd.DataFrame(raw_data_list)\n",
    "        if df_raw.empty: container_rows.children = (widgets.HTML(\"<h3>‚úÖ No pending emails to send!</h3>\"),); return\n",
    "\n",
    "        final_rows = []\n",
    "        if is_merged:\n",
    "            grouped = df_raw.groupby(['reviewer', 'email'])\n",
    "            for (rev, mail), group in grouped:\n",
    "                apps_html = \"<table border='1' style='border-collapse:collapse; width:100%; font-size:12px; border:1px solid #ddd'>\"\n",
    "                apps_html += \"<tr style='background:#f3f3f3'><th>App Name</th><th>Sent Date</th><th>Due Date</th><th>Missing</th><th>Link</th></tr>\"\n",
    "                for _, row in group.iterrows():\n",
    "                    apps_html += f\"<tr><td style='padding:5px'>{row['App_Name']}</td><td style='padding:5px'>{row['sent_date']}</td><td style='padding:5px'>{row['due_date']}</td><td style='padding:5px; text-align:center'>{row['missing']}</td><td style='padding:5px'><a href='{row['folder_url']}'>Open</a></td></tr>\"\n",
    "                apps_html += \"</table>\"\n",
    "                final_rows.append({\"key\": rev, \"reviewer\": rev, \"email\": mail, \"is_merged\": True, \"merged_html\": apps_html,\n",
    "                                   \"ctx\": {\"reviewer_name\": rev, \"app_name\": \"following applications\", \"sent_date\": \"previous dates\", \"due_date\": \"recently\", \"missing\": int(group['missing'].sum()), \"link\": \"#\"}})\n",
    "        else:\n",
    "            for idx, r in df_raw.iterrows():\n",
    "                final_rows.append({\"key\": f\"{r['reviewer']}_{r['App_Name']}\", \"reviewer\": r['reviewer'], \"email\": r['email'], \"is_merged\": False,\n",
    "                                   \"ctx\": {\"reviewer_name\": r['reviewer'], \"app_name\": r['App_Name'], \"sent_date\": r['sent_date'], \"due_date\": r['due_date'], \"missing\": r['missing'], \"link\": r['folder_url']}})\n",
    "\n",
    "        ui_items = []\n",
    "        for item in final_rows:\n",
    "            key = item['key']\n",
    "            email_color = \"#0078d4\" if item['email'] else \"red\"\n",
    "            info_html = (f\"<b>üë§ {item['reviewer']}</b><br><span style='color:{email_color}'>{item['email'] or '(No Email)'}</span><br>\"\n",
    "                         f\"<span style='color:darkorange'>Combine {item['ctx']['missing']} items</span>\") if item['is_merged'] else \\\n",
    "                        (f\"<b>üë§ {item['reviewer']}</b><br>üìÇ {item['ctx']['app_name']}<br><span style='color:{email_color}'>{item['email'] or '(No Email)'}</span>\")\n",
    "\n",
    "            w_chk = widgets.Checkbox(value=True, layout=widgets.Layout(width='30px'))\n",
    "            w_info = widgets.HTML(info_html, layout=widgets.Layout(width='200px'))\n",
    "            tpl_body = w_body_tpl.value.replace(\"\\n\", \"<br>\")\n",
    "            final_preview_html = (\"Hi \" + item['reviewer'] + \",<br><br>The Information Security team is sending you a reminder to complete the entitlement reviews for the following applications:<br><br>\" + item['merged_html'] + \"<br><br>Please complete these reviews as soon as possible. Your prompt assistance to this matter is appreciated.<br><br>Sincerely,<br>Apple Bank's Information Security Team\") if item['is_merged'] else tpl_body.format(**item['ctx'])\n",
    "            \n",
    "            w_preview = widgets.HTML(value=f\"<div style='font-family:sans-serif; font-size:12px; padding:5px; color:#333'>{final_preview_html}</div>\", layout=widgets.Layout(width='100%', height='140px', border='1px solid #eee', overflow_y='auto'))\n",
    "            w_email = widgets.Text(value=item['email'], placeholder=\"Email\", layout=widgets.Layout(width='98%'))\n",
    "            w_btn = widgets.Button(description=\"üöÄ Send\", button_style='warning', layout=widgets.Layout(width='80px'))\n",
    "\n",
    "            def create_sender(k, preview_html, subj_tpl, btn_obj):\n",
    "                def on_send(b):\n",
    "                    if not row_logic_store[k]['w_email'].value: \n",
    "                        btn_obj.description = \"No Email\"; return\n",
    "                    btn_obj.disabled = True; btn_obj.description = \"...\"\n",
    "                    try:\n",
    "                        final_subj = subj_tpl if item['is_merged'] else subj_tpl.format(**item['ctx'])\n",
    "                        url = f\"https://graph.microsoft.com/v1.0/users/{SENDER_EMAIL}/sendMail\"\n",
    "                        to_list = [{\"emailAddress\": {\"address\": row_logic_store[k]['w_email'].value}}]\n",
    "                        cc_list = [{\"emailAddress\": {\"address\": e}} for e in parse_email_list(w_cc_global.value)]\n",
    "                        reply_to_list = [{\"emailAddress\": {\"address\": e}} for e in parse_email_list(w_reply_to.value)]\n",
    "                        message_payload = {\n",
    "                            \"subject\": final_subj,\n",
    "                            \"body\": {\"contentType\": \"HTML\", \"content\": preview_html},\n",
    "                            \"toRecipients\": to_list\n",
    "                        }\n",
    "                        if cc_list:\n",
    "                            message_payload[\"ccRecipients\"] = cc_list\n",
    "                        if reply_to_list:\n",
    "                            message_payload[\"replyTo\"] = reply_to_list\n",
    "                        payload = {\"message\": message_payload}\n",
    "                        r = requests.post(url, headers={**headers, \"Content-Type\": \"application/json\"}, json=payload)\n",
    "                        if r.status_code == 202: \n",
    "                            btn_obj.button_style = 'success'; btn_obj.description = \"Sent\"\n",
    "                            row_logic_store[k]['w_chk'].value = False\n",
    "                        else: \n",
    "                            btn_obj.button_style = 'danger'; btn_obj.description = \"Fail\"\n",
    "                            print(r.text)\n",
    "                    except Exception as e: print(e); btn_obj.button_style = 'danger'\n",
    "                    finally: \n",
    "                        if btn_obj.description != \"Sent\": btn_obj.disabled = False\n",
    "                return on_send\n",
    "            \n",
    "            sender_func = create_sender(key, final_preview_html, w_subject_tpl.value, w_btn)\n",
    "            w_btn.on_click(sender_func)\n",
    "            \n",
    "            row_logic_store[key] = {'w_chk': w_chk, 'w_email': w_email, 'w_btn': w_btn, 'trigger_send': sender_func}\n",
    "            \n",
    "            ui_items.append(widgets.HBox([w_chk, w_info, widgets.VBox([widgets.Label(\"Preview:\"), w_preview], layout=widgets.Layout(flex='1', padding='0 10px')), widgets.VBox([widgets.Label(\"Action:\"), w_email, w_btn], layout=widgets.Layout(width='150px'))], layout=widgets.Layout(border='1px solid #ccc', margin='5px 0', padding='5px', align_items='center')))\n",
    "        container_rows.children = tuple(ui_items)\n",
    "\n",
    "    def trigger_batch_send(b):\n",
    "        b.disabled = True; b.description = \"Sending...\"\n",
    "        count = 0\n",
    "        for k, logic in row_logic_store.items():\n",
    "            if logic['w_chk'].value and logic['w_btn'].description != \"Sent\":\n",
    "                logic['trigger_send'](logic['w_btn'])\n",
    "                count += 1\n",
    "        b.disabled = False; b.description = f\"üî• Send All (Batch) - Done {count}\"\n",
    "\n",
    "    w_merge.observe(render_rows, names='value')\n",
    "    btn_refresh.on_click(render_rows)\n",
    "    btn_send_all.on_click(trigger_batch_send)\n",
    "    \n",
    "    render_rows()\n",
    "    display(widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üìß Email Notification Center</h3>\"), \n",
    "        widgets.HBox([w_merge, btn_refresh, btn_send_all]),\n",
    "        widgets.HTML(\"<hr>\"), \n",
    "        w_subject_tpl, w_cc_global, w_reply_to,\n",
    "        widgets.Label(\"Body Template (Single App Only):\"), w_body_tpl\n",
    "    ], layout=widgets.Layout(background_color='#f0f4f8', padding='10px', border='1px solid #ccc', margin='0 0 10px 0')), container_rows)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
