{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AER - Access Entitlement Review Reporter\n",
    "\n",
    "å¾ SharePoint è®€å–å¯©æ ¸äººå“¡çš„ Excel å›æ‡‰ï¼Œç”¢ç”Ÿç¼ºæ¼å ±å‘Šèˆ‡åˆä½µå ±å‘Šã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: è¨­å®šèˆ‡èªè­‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 13:28:38,423 | INFO | Azure AD èªè­‰æˆåŠŸï¼Œè™•ç† app: 2025 Entitlement Review/Q4/AVIDXCHANGE-TEST\n",
      "2025-12-29 13:28:38,424 | INFO | Log æª”æ¡ˆ: output/aer_20251229_132838.log\n"
     ]
    }
   ],
   "source": [
    "# === è¨­å®šèˆ‡èªè­‰ ===\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from msal import ConfidentialClientApplication\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# === Logging è¨­å®š ===\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "log_file = f\"output/aer_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "\n",
    "logger = logging.getLogger(\"aer\")\n",
    "logger.handlers.clear()  # é¿å…é‡è¤‡åŸ·è¡Œæ™‚ç´¯ç© handler\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "\n",
    "ch = logging.StreamHandler()\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "fh = logging.FileHandler(log_file)\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "# === Azure AD è¨­å®š ===\n",
    "TENANT_ID = os.getenv(\"AZURE_TENANT_ID\")\n",
    "CLIENT_ID = os.getenv(\"AZURE_CLIENT_ID\")\n",
    "CLIENT_SECRET = os.getenv(\"AZURE_CLIENT_SECRET\")\n",
    "\n",
    "# === SharePoint è¨­å®š ===\n",
    "SHAREPOINT_HOST = os.getenv(\"SHAREPOINT_HOST\", \"davidshih.sharepoint.com\")\n",
    "SITE_NAME = os.getenv(\"SITE_NAME\", \"aer\")\n",
    "APP_NAME = \"2025 Entitlement Review/Q4/AVIDXCHANGE-TEST\"\n",
    "BASE_PATH = APP_NAME\n",
    "\n",
    "# === Email è¨­å®š ===\n",
    "SENDER_EMAIL = os.getenv(\"SENDER_EMAIL\")  # e.g., \"noreply@company.com\"\n",
    "\n",
    "# === å–å¾— Access Token ===\n",
    "app = ConfidentialClientApplication(\n",
    "    CLIENT_ID,\n",
    "    authority=f\"https://login.microsoftonline.com/{TENANT_ID}\",\n",
    "    client_credential=CLIENT_SECRET\n",
    ")\n",
    "token_result = app.acquire_token_for_client(scopes=[\"https://graph.microsoft.com/.default\"])\n",
    "\n",
    "if \"access_token\" not in token_result:\n",
    "    logger.error(f\"èªè­‰å¤±æ•—: {token_result.get('error_description', 'Unknown error')}\")\n",
    "    raise Exception(\"Azure AD èªè­‰å¤±æ•—\")\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {token_result['access_token']}\"}\n",
    "logger.info(f\"Azure AD èªè­‰æˆåŠŸï¼Œè™•ç† app: {APP_NAME}\")\n",
    "logger.info(f\"Log æª”æ¡ˆ: {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: SharePoint å‡½æ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 13:28:43,422 | INFO | SharePoint é€£ç·šæˆåŠŸï¼ŒSite ID: davidshih.sharepoint...\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: SharePoint å‡½æ•¸ (Level 2 å‡ç´šç‰ˆ) ===\n",
    "\n",
    "def get_site_id(site_name: str) -> str:\n",
    "    \"\"\"å–å¾— SharePoint site ID\"\"\"\n",
    "    url = f\"https://graph.microsoft.com/v1.0/sites/{SHAREPOINT_HOST}:/sites/{site_name}\"\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"id\"]\n",
    "\n",
    "\n",
    "def list_folders(site_id: str, path: str) -> list[dict]:\n",
    "    \"\"\"åˆ—å‡ºè³‡æ–™å¤¾ä¸‹çš„æ‰€æœ‰å­è³‡æ–™å¤¾ï¼ˆå« webUrlï¼‰\"\"\"\n",
    "    # æ³¨æ„ï¼špath å·²ç¶“æ˜¯ç›¸å°è·¯å¾‘äº†\n",
    "    url = f\"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/root:/{path}:/children\"\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    resp.raise_for_status()\n",
    "    return [\n",
    "        {\"name\": item[\"name\"], \"webUrl\": item.get(\"webUrl\", \"\")}\n",
    "        for item in resp.json().get(\"value\", [])\n",
    "        if item.get(\"folder\")\n",
    "    ]\n",
    "\n",
    "\n",
    "def list_excel_files(site_id: str, folder_path: str) -> list[dict]:\n",
    "    \"\"\"åˆ—å‡ºè³‡æ–™å¤¾ä¸‹çš„ Excel æª”æ¡ˆï¼ˆå›å‚³ id, name, lastModifiedï¼‰\"\"\"\n",
    "    url = f\"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/root:/{folder_path}:/children\"\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    resp.raise_for_status()\n",
    "    \n",
    "    files = []\n",
    "    for item in resp.json().get(\"value\", []):\n",
    "        if item[\"name\"].endswith(\".xlsx\"):\n",
    "            files.append({\n",
    "                \"id\": item[\"id\"],  # <--- é—œéµï¼šæŠ“ ID\n",
    "                \"name\": item[\"name\"],\n",
    "                \"lastModifiedDateTime\": item.get(\"lastModifiedDateTime\"),\n",
    "                \"webUrl\": item.get(\"webUrl\")\n",
    "            })\n",
    "            \n",
    "    # æŒ‰æœ€å¾Œä¿®æ”¹æ™‚é–“æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰\n",
    "    return sorted(files, key=lambda f: f.get(\"lastModifiedDateTime\", \"\"), reverse=True)\n",
    "\n",
    "\n",
    "def download_file(site_id: str, file_path: str) -> bytes:\n",
    "    \"\"\"ä¸‹è¼‰æª”æ¡ˆå…§å®¹\"\"\"\n",
    "    url = f\"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/root:/{file_path}:/content\"\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    resp.raise_for_status()\n",
    "    return resp.content\n",
    "\n",
    "\n",
    "def get_file_audit_log(site_id: str, file_id: str) -> str:\n",
    "    \"\"\"\n",
    "    [æ–°å¢] å–å¾—æª”æ¡ˆç‰ˆæœ¬æ­·å² (Audit Log)\n",
    "    å›å‚³æ ¼å¼: \"æ™‚é–“ - äººå“¡ (å‹•ä½œ)\\næ™‚é–“ - äººå“¡ (å‹•ä½œ)...\"\n",
    "    \"\"\"\n",
    "    url = f\"https://graph.microsoft.com/v1.0/sites/{site_id}/drive/items/{file_id}/versions\"\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        return \"ç„¡æ³•å–å¾—ç‰ˆæœ¬ç´€éŒ„\"\n",
    "\n",
    "    versions = resp.json().get(\"value\", [])\n",
    "    logs = []\n",
    "    \n",
    "    for v in versions:\n",
    "        # æ™‚é–“æ ¼å¼åŒ– (e.g., 2025-12-29T10:00:00Z -> 2025-12-29 10:00:00)\n",
    "        mod_time = v.get(\"lastModifiedDateTime\", \"\")[:19].replace(\"T\", \" \")\n",
    "        \n",
    "        # æŠ“ä¿®æ”¹äºº (å„ªå…ˆæŠ“ User DisplayNameï¼ŒæŠ“ä¸åˆ°å°±æŠ“ Application Name)\n",
    "        user_info = v.get(\"lastModifiedBy\", {}).get(\"user\", {})\n",
    "        app_info = v.get(\"lastModifiedBy\", {}).get(\"application\", {})\n",
    "        \n",
    "        actor = user_info.get(\"displayName\") or app_info.get(\"displayName\") or \"Unknown System\"\n",
    "        \n",
    "        # åˆ¤æ–·æ˜¯å¦ç‚ºæœ€æ–°ç‰ˆæœ¬ (Graph API çš„ç‰ˆæœ¬é€šå¸¸æ˜¯ 1.0, 2.0...)\n",
    "        ver_num = v.get(\"id\", \"\")\n",
    "        \n",
    "        logs.append(f\"{mod_time} - {actor} (v{ver_num})\")\n",
    "        \n",
    "    return \"\\n\".join(logs) # ç”¨æ›è¡Œç¬¦è™Ÿä¸²æ¥ï¼Œæ–¹ä¾¿åœ¨ Excel åŒä¸€æ ¼é¡¯ç¤º\n",
    "\n",
    "\n",
    "# æ¸¬è©¦é€£ç·š\n",
    "try:\n",
    "    site_id = get_site_id(SITE_NAME)\n",
    "    logger.info(f\"SharePoint é€£ç·šæˆåŠŸï¼ŒSite ID: {site_id[:20]}...\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"SharePoint é€£ç·šå¤±æ•—: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Excel è®€å–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 13:28:46,895 | INFO | Excel è®€å–å‡½æ•¸å·²è¼‰å…¥\n"
     ]
    }
   ],
   "source": [
    "# === Excel è®€å–ï¼ˆè™•ç† AutoFilter visible rowsï¼‰===\n",
    "from openpyxl import load_workbook\n",
    "from io import BytesIO\n",
    "\n",
    "# æ¬„ä½åç¨±è¨­å®š\n",
    "COL_REVIEWER = \"Reviewer\"\n",
    "COL_RESPONSE = \"Reviewer's Response\"\n",
    "COL_DETAILS = \"Details of Access change\"\n",
    "\n",
    "\n",
    "def read_visible_rows(excel_bytes: bytes, reviewer_name: str, file_name: str, folder_url: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    è®€å– Excel çš„ visible rowsï¼ˆè€ƒæ…® AutoFilterï¼‰\n",
    "    \n",
    "    Args:\n",
    "        excel_bytes: Excel æª”æ¡ˆçš„ bytes\n",
    "        reviewer_name: å¯©æ ¸äººåç¨±ï¼ˆç”¨æ–¼ fallback éæ¿¾ï¼‰\n",
    "        file_name: æª”æ¡ˆåç¨±ï¼ˆè¿½è¹¤ç”¨ï¼‰\n",
    "        folder_url: SharePoint è³‡æ–™å¤¾ URLï¼ˆå¯é»æ“Šï¼‰\n",
    "    \n",
    "    Returns:\n",
    "        list of ReviewerResponse dict\n",
    "    \"\"\"\n",
    "    wb = load_workbook(BytesIO(excel_bytes))\n",
    "    ws = wb.active\n",
    "    \n",
    "    # æ‰¾å‡ºæ¬„ä½ç´¢å¼•ï¼ˆå‡è¨­ç¬¬ä¸€è¡Œæ˜¯æ¨™é¡Œï¼‰\n",
    "    header_row = [cell.value for cell in ws[1]]\n",
    "    col_map = {str(name).strip(): idx for idx, name in enumerate(header_row) if name}\n",
    "    \n",
    "    # æª¢æŸ¥å¿…è¦æ¬„ä½\n",
    "    reviewer_col = col_map.get(COL_REVIEWER)\n",
    "    response_col = col_map.get(COL_RESPONSE)\n",
    "    details_col = col_map.get(COL_DETAILS)\n",
    "    \n",
    "    if reviewer_col is None or response_col is None:\n",
    "        raise ValueError(f\"æ‰¾ä¸åˆ°å¿…è¦æ¬„ä½ã€‚ç¾æœ‰æ¬„ä½: {list(col_map.keys())}\")\n",
    "    \n",
    "    # æª¢æŸ¥æ˜¯å¦æœ‰ hidden rowsï¼ˆè¡¨ç¤ºæœ‰ AutoFilterï¼‰\n",
    "    has_filter = any(\n",
    "        ws.row_dimensions[i].hidden \n",
    "        for i in range(2, ws.max_row + 1) \n",
    "        if i in ws.row_dimensions\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    for row_idx in range(2, ws.max_row + 1):\n",
    "        # å¦‚æœæœ‰ filterï¼Œè·³éè¢«éš±è—çš„è¡Œ\n",
    "        if has_filter and ws.row_dimensions.get(row_idx) and ws.row_dimensions[row_idx].hidden:\n",
    "            continue\n",
    "        \n",
    "        row = [cell.value for cell in ws[row_idx]]\n",
    "        \n",
    "        # å–å¾—æ¬„ä½å€¼\n",
    "        reviewer = row[reviewer_col] if reviewer_col < len(row) else None\n",
    "        response = row[response_col] if response_col < len(row) else None\n",
    "        details = row[details_col] if details_col is not None and details_col < len(row) else None\n",
    "        \n",
    "        # å¦‚æœæ²’æœ‰ filterï¼Œç”¨æ¬„ä½å€¼éæ¿¾\n",
    "        if not has_filter:\n",
    "            if reviewer is None or str(reviewer).strip().lower() != reviewer_name.lower():\n",
    "                continue\n",
    "        \n",
    "        # åˆ¤æ–·æ˜¯å¦ç¼ºæ¼\n",
    "        is_missing = response is None or str(response).strip() == \"\"\n",
    "        \n",
    "        results.append({\n",
    "            \"reviewer\": reviewer_name,\n",
    "            \"response\": response,\n",
    "            \"details\": details,\n",
    "            \"is_missing\": is_missing,\n",
    "            \"row_number\": row_idx,\n",
    "            \"file_name\": file_name,\n",
    "            \"folder_url\": folder_url\n",
    "        })\n",
    "    \n",
    "    wb.close()\n",
    "    return results\n",
    "\n",
    "\n",
    "logger.info(\"Excel è®€å–å‡½æ•¸å·²è¼‰å…¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: è³‡æ–™æ”¶é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 13:28:50,271 | INFO | æ‰¾åˆ° 3 å€‹å¯©æ ¸äººè³‡æ–™å¤¾\n",
      "2025-12-29 13:28:50,272 | INFO | è™•ç†å¯©æ ¸äºº: Bob O'Brien\n",
      "2025-12-29 13:28:50,604 | INFO |   è®€å–æª”æ¡ˆ: Bob O'Brien_Access_Review_2025Q4.xlsx\n",
      "2025-12-29 13:28:51,493 | INFO |   å®Œæˆ: 3 ç­†è¨˜éŒ„ï¼Œ0 ç­†ç¼ºæ¼\n",
      "2025-12-29 13:28:51,493 | INFO | è™•ç†å¯©æ ¸äºº: Jane Smith\n",
      "2025-12-29 13:28:51,964 | INFO |   è®€å–æª”æ¡ˆ: Jane Smith_Access_Review_2025Q4.xlsx\n",
      "2025-12-29 13:28:52,935 | INFO |   å®Œæˆ: 5 ç­†è¨˜éŒ„ï¼Œ1 ç­†ç¼ºæ¼\n",
      "2025-12-29 13:28:52,936 | INFO | è™•ç†å¯©æ ¸äºº: Joe Petti\n",
      "2025-12-29 13:28:54,222 | INFO |   è®€å–æª”æ¡ˆ: Joe Petti_Access_Review_2025Q4.xlsx\n",
      "2025-12-29 13:28:55,440 | INFO |   å®Œæˆ: 4 ç­†è¨˜éŒ„ï¼Œ2 ç­†ç¼ºæ¼\n",
      "2025-12-29 13:28:55,442 | INFO | \n",
      "=== æ”¶é›†å®Œæˆ ===\n",
      "2025-12-29 13:28:55,442 | INFO | ç¸½è¨ˆ: 12 ç­†è¨˜éŒ„\n",
      "2025-12-29 13:28:55,443 | INFO | ç¼ºæ¼: 3 ç­†\n",
      "2025-12-29 13:28:55,443 | INFO | éŒ¯èª¤: 0 å€‹å¯©æ ¸äºº\n"
     ]
    }
   ],
   "source": [
    "# === Cell 4: è³‡æ–™æ”¶é›† (å« Audit Log) ===\n",
    "import pandas as pd\n",
    "\n",
    "# ç¢ºä¿ BASE_PATH æ˜¯æ­£ç¢ºçš„ç›¸å°è·¯å¾‘ (ä¸å« Shared Documents)\n",
    "# å¦‚æœæ‚¨åœ¨ Cell 1 å·²ç¶“ä¿®å¥½äº†ï¼Œé€™è£¡ç›´æ¥ç”¨å³å¯\n",
    "folders = list_folders(site_id, BASE_PATH)\n",
    "logger.info(f\"æ‰¾åˆ° {len(folders)} å€‹å¯©æ ¸äººè³‡æ–™å¤¾\")\n",
    "\n",
    "all_responses = []\n",
    "errors = []\n",
    "\n",
    "for folder in folders:\n",
    "    reviewer_name = folder[\"name\"]\n",
    "    folder_url = folder[\"webUrl\"]\n",
    "    # çµ„åˆè·¯å¾‘: Base path + Reviewer Folder\n",
    "    folder_path = f\"{BASE_PATH}/{reviewer_name}\"\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"è™•ç†å¯©æ ¸äºº: {reviewer_name}\")\n",
    "        \n",
    "        # åˆ—å‡º Excel æª”æ¡ˆ\n",
    "        excel_files = list_excel_files(site_id, folder_path)\n",
    "        \n",
    "        # æ‰¾åˆ°åŒ…å«å¯©æ ¸äººåå­—çš„ Excel æª”æ¡ˆ\n",
    "        target_files = [f for f in excel_files if reviewer_name.lower() in f[\"name\"].lower()]\n",
    "        \n",
    "        if not target_files:\n",
    "            logger.warning(f\"  æ‰¾ä¸åˆ°åŒ…å« '{reviewer_name}' çš„ Excel æª”æ¡ˆ\")\n",
    "            errors.append({\"reviewer\": reviewer_name, \"error\": \"æ‰¾ä¸åˆ°å¯©æ ¸æª”æ¡ˆ\", \"folder_url\": folder_url})\n",
    "            continue\n",
    "        \n",
    "        # è®€å–æœ€æ–°çš„æª”æ¡ˆ\n",
    "        target_file = target_files[0]\n",
    "        file_name = target_file[\"name\"]\n",
    "        file_id = target_file[\"id\"]\n",
    "        # æ³¨æ„ï¼šè·¯å¾‘è¦ encode è™•ç†ç©ºæ ¼ï¼Œä½† requests æœƒè‡ªå‹•å¹«å¿™ï¼Œé€™è£¡ç›´æ¥ä¸²å­—ä¸²\n",
    "        file_download_path = f\"{folder_path}/{file_name}\"\n",
    "        \n",
    "        logger.info(f\"  è®€å–æª”æ¡ˆ: {file_name}\")\n",
    "        \n",
    "        # ğŸ”¥ [é—œéµå‹•ä½œ] æŠ“å– Audit Log (ç‰ˆæœ¬æ­·å²)\n",
    "        audit_log_str = get_file_audit_log(site_id, file_id)\n",
    "        \n",
    "        # ä¸‹è¼‰å…§å®¹\n",
    "        excel_bytes = download_file(site_id, file_download_path)\n",
    "        \n",
    "        # è§£æ Excel\n",
    "        rows = read_visible_rows(excel_bytes, reviewer_name, file_name, folder_url)\n",
    "        \n",
    "        # æŠŠ Audit Log å¡çµ¦æ¯ä¸€è¡Œ (è®“æ¯ä¸€ç­†è³‡æ–™éƒ½å¸¶æœ‰é€™å€‹æª”æ¡ˆçš„ä¿®æ”¹æ­·å²)\n",
    "        for row in rows:\n",
    "            row[\"Audit_History\"] = audit_log_str\n",
    "            row[\"Last_Modified\"] = target_file[\"lastModifiedDateTime\"]\n",
    "        \n",
    "        all_responses.extend(rows)\n",
    "        \n",
    "        missing_count = sum(1 for r in rows if r[\"is_missing\"])\n",
    "        logger.info(f\"  å®Œæˆ: {len(rows)} ç­†è¨˜éŒ„ï¼Œ{missing_count} ç­†ç¼ºæ¼\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"  è™•ç†å¤±æ•—: {e}\")\n",
    "        # å°å‡º traceback æ–¹ä¾¿é™¤éŒ¯\n",
    "        import traceback\n",
    "        traceback.print_exc() \n",
    "        errors.append({\"reviewer\": reviewer_name, \"error\": str(e), \"folder_url\": folder_url})\n",
    "\n",
    "# è½‰æˆ DataFrame\n",
    "df = pd.DataFrame(all_responses)\n",
    "logger.info(f\"\\n=== æ”¶é›†å®Œæˆ ===\")\n",
    "logger.info(f\"ç¸½è¨ˆ: {len(all_responses)} ç­†è¨˜éŒ„\")\n",
    "logger.info(f\"ç¼ºæ¼: {df['is_missing'].sum() if len(df) > 0 else 0} ç­†\")\n",
    "logger.info(f\"éŒ¯èª¤: {len(errors)} å€‹å¯©æ ¸äºº\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: äº’å‹•å¼ç‹€æ…‹è¡¨æ ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .status-table { border-collapse: collapse; width: 100%; }\n",
       "        .status-table th, .status-table td { border: 1px solid #ddd; padding: 8px; text-align: left; }\n",
       "        .status-table th { background-color: #4CAF50; color: white; }\n",
       "        .status-table a { color: #0066cc; text-decoration: none; }\n",
       "        .status-table a:hover { text-decoration: underline; }\n",
       "    </style>\n",
       "    <h3>å¯©æ ¸ç‹€æ…‹ç¸½è¦½ - 2025 Entitlement Review/Q4/AVIDXCHANGE-TEST</h3>\n",
       "    <table class=\"status-table\">\n",
       "        <tr>\n",
       "            <th>å¯©æ ¸äºº</th>\n",
       "            <th>ç‹€æ…‹</th>\n",
       "            <th>å®Œæˆç‡</th>\n",
       "            <th>ç¼ºæ¼/ç¸½æ•¸</th>\n",
       "        </tr>\n",
       "        \n",
       "        <tr style=\"background-color: #ffcccc;\">\n",
       "            <td><a href=\"https://davidshih.sharepoint.com/sites/aer/Shared%20Documents/2025%20Entitlement%20Review/Q4/AVIDXCHANGE-TEST/Joe%20Petti\" target=\"_blank\">Joe Petti</a></td>\n",
       "            <td>ğŸ”´ æœªå®Œæˆ</td>\n",
       "            <td>50.0%</td>\n",
       "            <td>2 / 4</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr style=\"background-color: #ffcccc;\">\n",
       "            <td><a href=\"https://davidshih.sharepoint.com/sites/aer/Shared%20Documents/2025%20Entitlement%20Review/Q4/AVIDXCHANGE-TEST/Jane%20Smith\" target=\"_blank\">Jane Smith</a></td>\n",
       "            <td>ğŸ”´ æœªå®Œæˆ</td>\n",
       "            <td>80.0%</td>\n",
       "            <td>1 / 5</td>\n",
       "        </tr>\n",
       "        \n",
       "        <tr style=\"background-color: #ccffcc;\">\n",
       "            <td><a href=\"https://davidshih.sharepoint.com/sites/aer/Shared%20Documents/2025%20Entitlement%20Review/Q4/AVIDXCHANGE-TEST/Bob%20O%27Brien\" target=\"_blank\">Bob O'Brien</a></td>\n",
       "            <td>ğŸŸ¢ å®Œæˆ</td>\n",
       "            <td>100.0%</td>\n",
       "            <td>0 / 3</td>\n",
       "        </tr>\n",
       "        \n",
       "    </table>\n",
       "    <p><b>ç¸½è¨ˆ:</b> 3 ä½å¯©æ ¸äºº, 3 ç­†ç¼ºæ¼</p>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === äº’å‹•å¼ç‹€æ…‹è¡¨æ ¼ ===\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def create_status_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"å»ºç«‹äº’å‹•å¼ç‹€æ…‹è¡¨æ ¼ï¼Œè¿”å› summary DataFrame\"\"\"\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        display(HTML(\"<p style='color: red;'>æ²’æœ‰è³‡æ–™å¯é¡¯ç¤º</p>\"))\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # è¨ˆç®—æ¯å€‹å¯©æ ¸äººçš„ç‹€æ…‹\n",
    "    summary = df.groupby([\"reviewer\", \"folder_url\"]).agg(\n",
    "        total=(\"reviewer\", \"count\"),\n",
    "        missing=(\"is_missing\", \"sum\")\n",
    "    ).reset_index()\n",
    "    \n",
    "    summary[\"status\"] = summary.apply(\n",
    "        lambda r: \"ğŸ”´ æœªå®Œæˆ\" if r[\"missing\"] > 0 else \"ğŸŸ¢ å®Œæˆ\", axis=1\n",
    "    )\n",
    "    summary[\"completion\"] = ((summary[\"total\"] - summary[\"missing\"]) / summary[\"total\"] * 100).round(1)\n",
    "    \n",
    "    # å»ºç«‹ HTML è¡¨æ ¼ï¼ˆå¯é»æ“Šé€£çµåˆ° SharePointï¼‰\n",
    "    def make_row(r):\n",
    "        bg_color = \"#ffcccc\" if r[\"missing\"] > 0 else \"#ccffcc\"\n",
    "        return f\"\"\"\n",
    "        <tr style=\"background-color: {bg_color};\">\n",
    "            <td><a href=\"{r['folder_url']}\" target=\"_blank\">{r['reviewer']}</a></td>\n",
    "            <td>{r['status']}</td>\n",
    "            <td>{r['completion']}%</td>\n",
    "            <td>{int(r['missing'])} / {int(r['total'])}</td>\n",
    "        </tr>\n",
    "        \"\"\"\n",
    "    \n",
    "    # æ’åºï¼šæœªå®Œæˆçš„åœ¨å‰\n",
    "    summary_sorted = summary.sort_values([\"missing\", \"reviewer\"], ascending=[False, True])\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <style>\n",
    "        .status-table {{ border-collapse: collapse; width: 100%; }}\n",
    "        .status-table th, .status-table td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
    "        .status-table th {{ background-color: #4CAF50; color: white; }}\n",
    "        .status-table a {{ color: #0066cc; text-decoration: none; }}\n",
    "        .status-table a:hover {{ text-decoration: underline; }}\n",
    "    </style>\n",
    "    <h3>å¯©æ ¸ç‹€æ…‹ç¸½è¦½ - {APP_NAME}</h3>\n",
    "    <table class=\"status-table\">\n",
    "        <tr>\n",
    "            <th>å¯©æ ¸äºº</th>\n",
    "            <th>ç‹€æ…‹</th>\n",
    "            <th>å®Œæˆç‡</th>\n",
    "            <th>ç¼ºæ¼/ç¸½æ•¸</th>\n",
    "        </tr>\n",
    "        {''.join(summary_sorted.apply(make_row, axis=1))}\n",
    "    </table>\n",
    "    <p><b>ç¸½è¨ˆ:</b> {len(summary)} ä½å¯©æ ¸äºº, {int(summary['missing'].sum())} ç­†ç¼ºæ¼</p>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(html))\n",
    "    return summary\n",
    "\n",
    "\n",
    "# é¡¯ç¤ºç‹€æ…‹è¡¨æ ¼\n",
    "summary_df = create_status_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: ç™¼é€æé†’éƒµä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ç™¼é€æé†’éƒµä»¶ ===\n",
    "import ipywidgets as widgets\n",
    "from urllib.parse import quote\n",
    "\n",
    "def get_user_email(display_name: str) -> str | None:\n",
    "    \"\"\"å¾ Azure AD æŸ¥è©¢ä½¿ç”¨è€… email\"\"\"\n",
    "    # URL encode è™•ç†ç‰¹æ®Šå­—å…ƒ\n",
    "    encoded_name = quote(display_name)\n",
    "    user_url = f\"https://graph.microsoft.com/v1.0/users?$filter=displayName eq '{encoded_name}'\"\n",
    "    \n",
    "    resp = requests.get(user_url, headers=headers)\n",
    "    if resp.status_code != 200:\n",
    "        logger.warning(f\"æŸ¥è©¢ä½¿ç”¨è€…å¤±æ•—: {resp.text}\")\n",
    "        return None\n",
    "    \n",
    "    users = resp.json().get(\"value\", [])\n",
    "    if not users:\n",
    "        logger.warning(f\"æ‰¾ä¸åˆ° {display_name} çš„ email\")\n",
    "        return None\n",
    "    \n",
    "    return users[0].get(\"mail\")\n",
    "\n",
    "\n",
    "def send_reminder_email(reviewer_name: str, missing_count: int, folder_url: str, deadline: str = None) -> bool:\n",
    "    \"\"\"ç™¼é€æé†’éƒµä»¶çµ¦å¯©æ ¸äºº\"\"\"\n",
    "    \n",
    "    if not SENDER_EMAIL:\n",
    "        logger.error(\"æœªè¨­å®š SENDER_EMAIL\")\n",
    "        return False\n",
    "    \n",
    "    recipient_email = get_user_email(reviewer_name)\n",
    "    if not recipient_email:\n",
    "        return False\n",
    "    \n",
    "    # ç”¨æŒ‡å®šç™¼é€è€…ï¼ˆApplication èªè­‰ä¸èƒ½ç”¨ /meï¼‰\n",
    "    mail_url = f\"https://graph.microsoft.com/v1.0/users/{SENDER_EMAIL}/sendMail\"\n",
    "    \n",
    "    deadline_text = f\"<p><b>æˆªæ­¢æ—¥æœŸ:</b> {deadline}</p>\" if deadline else \"\"\n",
    "    \n",
    "    mail_body = {\n",
    "        \"message\": {\n",
    "            \"subject\": f\"[æé†’] Access Review å¾…å¯©æ ¸ - {missing_count} ç­†å¾…è™•ç†\",\n",
    "            \"body\": {\n",
    "                \"contentType\": \"HTML\",\n",
    "                \"content\": f\"\"\"\n",
    "                <p>Hi {reviewer_name},</p>\n",
    "                <p>æ‚¨æœ‰ <b>{missing_count}</b> ç­† Access Review è¨˜éŒ„å¾…å¯©æ ¸ã€‚</p>\n",
    "                {deadline_text}\n",
    "                <p>è«‹é»æ“Šä»¥ä¸‹é€£çµå®Œæˆå¯©æ ¸ï¼š</p>\n",
    "                <p><a href=\"{folder_url}\">{folder_url}</a></p>\n",
    "                <br>\n",
    "                <p>è¬è¬ï¼</p>\n",
    "                \"\"\"\n",
    "            },\n",
    "            \"toRecipients\": [{\"emailAddress\": {\"address\": recipient_email}}]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    resp = requests.post(mail_url, headers={**headers, \"Content-Type\": \"application/json\"}, json=mail_body)\n",
    "    \n",
    "    if resp.status_code == 202:\n",
    "        logger.info(f\"å·²ç™¼é€æé†’éƒµä»¶çµ¦ {reviewer_name} ({recipient_email})\")\n",
    "        return True\n",
    "    else:\n",
    "        logger.error(f\"éƒµä»¶ç™¼é€å¤±æ•—: {resp.status_code} - {resp.text}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def create_reminder_ui(summary_df: pd.DataFrame):\n",
    "    \"\"\"å»ºç«‹ç™¼é€æé†’çš„äº’å‹•å¼ UI\"\"\"\n",
    "    \n",
    "    if len(summary_df) == 0:\n",
    "        display(HTML(\"<p>æ²’æœ‰è³‡æ–™</p>\"))\n",
    "        return\n",
    "    \n",
    "    # åªé¡¯ç¤ºæœ‰ç¼ºæ¼çš„å¯©æ ¸äºº\n",
    "    missing_df = summary_df[summary_df[\"missing\"] > 0]\n",
    "    \n",
    "    if len(missing_df) == 0:\n",
    "        display(HTML(\"<p style='color: green;'>âœ… æ‰€æœ‰å¯©æ ¸äººéƒ½å·²å®Œæˆï¼</p>\"))\n",
    "        return\n",
    "    \n",
    "    # å»ºç«‹ checkbox\n",
    "    checkboxes = {}\n",
    "    for _, row in missing_df.iterrows():\n",
    "        name = row[\"reviewer\"]\n",
    "        label = f\"{name} ({int(row['missing'])} ç­†ç¼ºæ¼)\"\n",
    "        checkboxes[name] = widgets.Checkbox(value=False, description=label, style={'description_width': 'initial'})\n",
    "    \n",
    "    # å…¨é¸æŒ‰éˆ•\n",
    "    select_all = widgets.Checkbox(value=False, description=\"å…¨é¸\", style={'description_width': 'initial'})\n",
    "    \n",
    "    def on_select_all_change(change):\n",
    "        for cb in checkboxes.values():\n",
    "            cb.value = change['new']\n",
    "    \n",
    "    select_all.observe(on_select_all_change, names='value')\n",
    "    \n",
    "    # æˆªæ­¢æ—¥æœŸ\n",
    "    deadline_input = widgets.Text(value=\"\", placeholder=\"ä¾‹å¦‚: 2024-01-15\", description=\"æˆªæ­¢æ—¥æœŸ:\")\n",
    "    \n",
    "    # ç™¼é€æŒ‰éˆ•\n",
    "    send_btn = widgets.Button(description=\"ç™¼é€æé†’éƒµä»¶\", button_style=\"warning\")\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_send(b):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            deadline = deadline_input.value.strip() or None\n",
    "            sent_count = 0\n",
    "            for name, cb in checkboxes.items():\n",
    "                if cb.value:\n",
    "                    row = missing_df[missing_df[\"reviewer\"] == name].iloc[0]\n",
    "                    if send_reminder_email(name, int(row[\"missing\"]), row[\"folder_url\"], deadline):\n",
    "                        sent_count += 1\n",
    "            print(f\"\\nå·²ç™¼é€ {sent_count} å°æé†’éƒµä»¶\")\n",
    "    \n",
    "    send_btn.on_click(on_send)\n",
    "    \n",
    "    # é¡¯ç¤º UI\n",
    "    display(HTML(\"<h3>ç™¼é€æé†’éƒµä»¶</h3>\"))\n",
    "    display(select_all)\n",
    "    display(widgets.VBox(list(checkboxes.values())))\n",
    "    display(deadline_input)\n",
    "    display(send_btn)\n",
    "    display(output)\n",
    "\n",
    "\n",
    "# å»ºç«‹æé†’ UI\n",
    "create_reminder_ui(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: ç”¢ç”Ÿå ±å‘Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 13:33:14,010 | INFO | âœ¨ å·²ç¾åŒ– Excel æ ¼å¼ (è‡ªå‹•æ›è¡Œ): output/missing_responses_2025 Entitlement Review_Q4_AVIDXCHANGE-TEST_20251229_133313.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-29 13:33:14,024 | INFO | âœ¨ å·²ç¾åŒ– Excel æ ¼å¼ (è‡ªå‹•æ›è¡Œ): output/consolidated_report_2025 Entitlement Review_Q4_AVIDXCHANGE-TEST_20251229_133313.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <h3>å ±å‘Šå·²ç”¢ç”Ÿ (å« Audit æ ¼å¼ç¾åŒ–)</h3>\n",
       "    <ul>\n",
       "        <li>ç¼ºæ¼å ±å‘Š: <code>output/missing_responses_2025 Entitlement Review_Q4_AVIDXCHANGE-TEST_20251229_133313.xlsx</code></li>\n",
       "        <li>åˆä½µå ±å‘Š: <code>output/consolidated_report_2025 Entitlement Review_Q4_AVIDXCHANGE-TEST_20251229_133313.xlsx</code></li>\n",
       "    </ul>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Cell 7: ç”¢ç”Ÿå ±å‘Š (å«æ ¼å¼ç¾åŒ–) ===\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Alignment, PatternFill\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "safe_app_name = APP_NAME.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "\n",
    "def format_excel_layout(file_path: str):\n",
    "    \"\"\"\n",
    "    [ç¾åŒ–å‡½æ•¸] è‡ªå‹•èª¿æ•´ Excel æ ¼å¼ï¼š\n",
    "    1. é–‹å•Ÿ 'Audit_History' å’Œ 'details' çš„è‡ªå‹•æ›è¡Œ (Wrap Text)\n",
    "    2. èª¿æ•´æ¬„å¯¬ï¼Œé¿å…å…§å®¹æ“ åœ¨ä¸€èµ·\n",
    "    3. å°‡å…§å®¹è¨­ç‚ºé ä¸Šå°é½Š (Vertical Top)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        wb = load_workbook(file_path)\n",
    "        ws = wb.active\n",
    "        \n",
    "        # å®šç¾©è¦è™•ç†çš„æ¬„ä½åç¨±\n",
    "        wrap_columns = [\"Audit_History\", \"Details of Access change\", \"details\"]\n",
    "        \n",
    "        # æ‰¾å‡ºé€™äº›æ¬„ä½åœ¨å“ªä¸€åˆ— (Column Index)\n",
    "        col_indices = {}\n",
    "        header_row = next(ws.iter_rows(min_row=1, max_row=1, values_only=True))\n",
    "        for idx, col_name in enumerate(header_row):\n",
    "            if col_name in wrap_columns:\n",
    "                col_indices[idx + 1] = col_name # Excel index starts from 1\n",
    "        \n",
    "        # è¨­å®šæ¨£å¼\n",
    "        align_style = Alignment(wrap_text=True, vertical='top')\n",
    "        \n",
    "        # èª¿æ•´æ¬„å¯¬ (ç¨å¾®æ‹‰å¯¬ä¸€é»çµ¦ Audit Log ç”¨)\n",
    "        for col_idx in col_indices:\n",
    "            col_letter = ws.cell(row=1, column=col_idx).column_letter\n",
    "            ws.column_dimensions[col_letter].width = 50 \n",
    "        \n",
    "        # é€è¡Œå¥—ç”¨æ ¼å¼\n",
    "        for row in ws.iter_rows(min_row=2): # è·³éæ¨™é¡Œåˆ—\n",
    "            for col_idx in col_indices:\n",
    "                cell = row[col_idx - 1] # list index starts from 0\n",
    "                cell.alignment = align_style\n",
    "                \n",
    "        wb.save(file_path)\n",
    "        logger.info(f\"âœ¨ å·²ç¾åŒ– Excel æ ¼å¼ (è‡ªå‹•æ›è¡Œ): {file_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Excel æ ¼å¼ç¾åŒ–å¤±æ•— (ä½†ä¸å½±éŸ¿æª”æ¡ˆå…§å®¹): {e}\")\n",
    "\n",
    "\n",
    "# === ä¸»è¦é‚è¼¯ ===\n",
    "if len(df) > 0:\n",
    "    # å®šç¾©è¼¸å‡ºçš„æ¬„ä½é †åº\n",
    "    export_cols = [\n",
    "        \"reviewer\", \"response\", \"details\", \"is_missing\", \n",
    "        \"Audit_History\", \"Last_Modified\", \n",
    "        \"row_number\", \"file_name\", \"folder_url\"\n",
    "    ]\n",
    "    \n",
    "    # 1. ç¼ºæ¼å ±å‘Š\n",
    "    missing_df = df[df[\"is_missing\"]].copy()\n",
    "    missing_file_xlsx = f\"output/missing_responses_{safe_app_name}_{timestamp}.xlsx\"\n",
    "    \n",
    "    available_cols = [c for c in export_cols if c in missing_df.columns]\n",
    "    missing_df[available_cols].to_excel(missing_file_xlsx, index=False)\n",
    "    format_excel_layout(missing_file_xlsx) # <--- å‘¼å«ç¾åŒ–å‡½æ•¸\n",
    "    \n",
    "    # 2. åˆä½µå ±å‘Š\n",
    "    consolidated_file_xlsx = f\"output/consolidated_report_{safe_app_name}_{timestamp}.xlsx\"\n",
    "    \n",
    "    available_cols = [c for c in export_cols if c in df.columns]\n",
    "    df[available_cols].to_excel(consolidated_file_xlsx, index=False)\n",
    "    format_excel_layout(consolidated_file_xlsx) # <--- å‘¼å«ç¾åŒ–å‡½æ•¸\n",
    "    \n",
    "    display(HTML(f\"\"\"\n",
    "    <h3>å ±å‘Šå·²ç”¢ç”Ÿ (å« Audit æ ¼å¼ç¾åŒ–)</h3>\n",
    "    <ul>\n",
    "        <li>ç¼ºæ¼å ±å‘Š: <code>{missing_file_xlsx}</code></li>\n",
    "        <li>åˆä½µå ±å‘Š: <code>{consolidated_file_xlsx}</code></li>\n",
    "    </ul>\n",
    "    \"\"\"))\n",
    "\n",
    "else:\n",
    "    logger.warning(\"æ²’æœ‰è³‡æ–™å¯ç”¢ç”Ÿå ±å‘Š\")\n",
    "    display(HTML(\"<p style='color: orange;'>æ²’æœ‰è³‡æ–™å¯ç”¢ç”Ÿå ±å‘Š</p>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: éŒ¯èª¤å ±å‘Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === éŒ¯èª¤å ±å‘Š ===\n",
    "\n",
    "if errors:\n",
    "    error_df = pd.DataFrame(errors)\n",
    "    error_file = f\"output/errors_{APP_NAME}_{timestamp}.csv\"\n",
    "    error_df.to_csv(error_file, index=False)\n",
    "    \n",
    "    logger.warning(f\"æœ‰ {len(errors)} å€‹å¯©æ ¸äººè™•ç†å¤±æ•—\")\n",
    "    \n",
    "    # é¡¯ç¤ºéŒ¯èª¤è¡¨æ ¼\n",
    "    def make_error_row(r):\n",
    "        return f\"\"\"\n",
    "        <tr style=\"background-color: #fff3cd;\">\n",
    "            <td><a href=\"{r['folder_url']}\" target=\"_blank\">{r['reviewer']}</a></td>\n",
    "            <td>{r['error']}</td>\n",
    "        </tr>\n",
    "        \"\"\"\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <h3>âš ï¸ è™•ç†éŒ¯èª¤</h3>\n",
    "    <table class=\"status-table\">\n",
    "        <tr>\n",
    "            <th>å¯©æ ¸äºº</th>\n",
    "            <th>éŒ¯èª¤è¨Šæ¯</th>\n",
    "        </tr>\n",
    "        {''.join(error_df.apply(make_error_row, axis=1))}\n",
    "    </table>\n",
    "    <p>éŒ¯èª¤å ±å‘Šå·²å„²å­˜: <code>{error_file}</code></p>\n",
    "    \"\"\"\n",
    "    display(HTML(html))\n",
    "else:\n",
    "    display(HTML(\"<p style='color: green;'>âœ… æ‰€æœ‰å¯©æ ¸äººéƒ½è™•ç†æˆåŠŸï¼</p>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
